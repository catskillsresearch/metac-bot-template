Recent years have seen third-party evaluation of dangerous capabilities become an entrenched and institutionalized norm for all major frontier AI models. Leading industry labs—motivated by regulatory, reputational, and market pressures—consistently subject their highest-capability models to independent external assessments prior to or at release. This process is being reinforced by proactive investment in evaluation infrastructure, as evidenced by initiatives to fund and standardize third-party dangerous capability testing. Regulatory frameworks in major jurisdictions such as the US, UK, and EU are also moving toward formalizing these requirements, with new legislation, policy recommendations, and industry working groups explicitly pushing for independent safety evaluations as a condition of responsible deployment.

The direction of travel is clear: the industry’s most capable actors are aligning on third-party evaluation as both a basic price of entry and a crucial risk mitigation step, with the trend only growing stronger over the past several years due to increasing scrutiny and public attention.

Despite this robust baseline, certain risk factors could disrupt the prevailing pattern. Competitive pressures—particularly in a rapidly evolving, high-stakes environment—may incentivize some players to consider shortcuts, especially if a major actor signals willingness to relax safety standards in response to rivals bypassing third-party evaluation. The entry of new labs from regions with weaker oversight or divergent regulatory norms could also lead to releases without meaningful external assessment, especially if these entrants prioritize speed or secrecy over transparency. Additionally, ambiguity in what constitutes a “third-party evaluation” or the emergence of nominally independent but functionally non-rigorous assessments could open loopholes for actors seeking to circumvent substantive oversight.

There is also the possibility—though less likely—that changes in geopolitical or regulatory environments, such as deregulatory shifts or fragmented enforcement across regions, could create gaps in the global safety net. Smaller or less visible organizations, particularly those operating in jurisdictions lacking strong institutional frameworks, might be able to release models without robust external scrutiny if enforcement lags or definitions are watered down.

Overall, the norm of third-party evaluation for frontier models is entrenched and becoming further institutionalized, significantly reducing the likelihood of release without such assessment. However, nonzero risk persists due to competitive, regulatory, and definitional uncertainties—most notably from potential new entrants, jurisdictional arbitrage, and evolving interpretations of compliance. The probability of an exception occurring remains modest, primarily hinging on outlier scenarios or disruptive shifts in the competitive and regulatory landscape.

### Probability: 15%