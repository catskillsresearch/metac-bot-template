A comprehensive federal law in the United States specifically requiring cybersecurity measures for all actors in possession of "powerful" AI models has not been enacted as of late May 2025. The most significant recent federal legislative action is a proposed 10-year moratorium that would preempt new state and local AI regulations, reflecting a preference for regulatory consolidation rather than immediate imposition of new federal mandates. This moratorium, having passed the House and pending in the Senate, is primarily designed to create a uniform national approach and addresses concerns over a patchwork of state laws, but it does not itself require cybersecurity for powerful AI models.

At the federal level, recent activity is largely limited to agency guidelines, best practices, and sector-specific rules—such as OMB memos, defense procurement guidance, and CISA's best practices for securing AI data. These measures lack the statutory authority and scope to satisfy the criteria of a binding law mandating cybersecurity for all powerful AI models. Meanwhile, state legislatures remain active, with several new laws focusing on transparency, consumer protection, and sectoral bans (e.g., Kansas banning certain foreign AI models on government devices), but these either lack comprehensive model security focus or risk being preempted by the proposed moratorium.

Key forces shaping the current landscape include political gridlock in Congress, strong industry lobbying for delayed or preemptive regulation, and significant technical uncertainty—especially around defining what qualifies as a "powerful" AI model and establishing enforceable cybersecurity standards. The prevailing legislative sentiment is to pause, study, and consolidate rather than act swiftly, with most proposed bills targeting transparency, privacy, or discrimination, not cybersecurity per se.

A substantial legislative shift remains unlikely without a major AI-related cybersecurity incident or other national security crisis that could galvanize bipartisan action and override the present inertia. Federal R&D initiatives and public requests for comment (such as the 2025 National AI R&D Strategic Plan) demonstrate growing interest in AI standards and security at the policy level, yet these are, for now, only advisory and not law.

In summary, while executive agencies and individual states are making incremental moves to address AI security risks, the dominant federal legislative trend through 2025 is toward delaying comprehensive cybersecurity mandates for powerful AI models, focusing instead on preemption, harmonization, and voluntary guidance. Only a dramatic event or rapid shift in political priorities is likely to change this trajectory in the near term.

### Probability: 15%