## Rationale for the Time Between Weak AGI and the First Superintelligent Oracle

The interval between the creation of a weak artificial general intelligence (AGI) and the emergence of the first superintelligent oracle is driven by a combination of accelerating technological trends, expert assessments, and persistent uncertainty surrounding alignment and regulatory challenges.

At present, community and expert forecasting aggregations strongly converge on a median estimate of roughly 19–21 months separating these milestones. This figure is supported by leading forecasting platforms and recent government and strategic reports, which highlight a central tendency in the range of 18–21 months between the first weak AGI and the appearance of a system capable of outperforming humans at all cognitive tasks. The distribution is notably heavy-tailed, with a significant probability both for much faster and much slower transitions.

If the current trend of rapid progress in scaling AI models, investment, and recursive improvement continues, the transition could plausibly be even shorter, given the increasing pace of breakthroughs and the likelihood that early AGI systems will possess self-improvement capabilities. Several industry leaders, including CEOs of major AI companies, have speculated that the time between weak AGI and superintelligence could shrink to as little as a few months, or even weeks, should alignment and technical bottlenecks be overcome swiftly.

However, there are substantial sources of uncertainty that could lengthen the interval considerably. Technical challenges such as alignment, interpretability, and hardware limitations may prove far more complex than anticipated, and global regulatory responses to the emergence of AGI—possibly including moratoriums or severe restrictions—could add years or decades to the timeline between milestones. Historic surveys of AI researchers reflect this ambiguity, with non-negligible probabilities assigned to both very rapid (<6 months) and much slower (>8 years) transitions, depending on how these uncertainties play out.

Unexpected scenarios remain credible at both extremes:
- In a rapid takeoff scenario, a breakthrough in recursive self-improvement or the open release of a powerful AGI allows immediate and unchecked transition to superintelligent oracle capabilities within weeks, bypassing regulatory or alignment obstacles.
- Conversely, technical or social stalling—for instance, failures in alignment, hardware scaling, or the imposition of restrictive global regulation following AGI emergence—could delay superintelligence for many years or even decades.

While the recent acceleration in technological progress lends support to a relatively short interval, the field’s inherent unpredictability and the possibility of hard limits or intentional slowdown impose a broad range of plausible outcomes. As a result, even as the center of expert and community opinion points toward a gap of one to two years, forecasters widely acknowledge the real risk of both abrupt transitions and protracted lags between weak AGI and superintelligent oracle.

### Forecast

10: 2.0
20: 5.0
40: 12.0
60: 24.0
80: 60.0
90: 120.0
11: 2.3
12: 2.6
13: 2.9
14: 3.2
15: 3.5
16: 3.8
17: 4.1
18: 4.4
19: 4.7
21: 5.35
22: 5.7
23: 6.05
24: 6.4
25: 6.75
26: 7.1
27: 7.45
28: 7.8
29: 8.15
30: 8.5
31: 8.85
32: 9.2
33: 9.55
34: 9.9
35: 10.25
36: 10.6
37: 10.95
38: 11.3
39: 11.65
41: 12.6
42: 13.2
43: 13.8
44: 14.4
45: 15.0
46: 15.6
47: 16.2
48: 16.8
49: 17.4
50: 18.0
51: 18.6
52: 19.2
53: 19.8
54: 20.4
55: 21.0
56: 21.6
57: 22.2
58: 22.8
59: 23.4
61: 25.8
62: 27.6
63: 29.4
64: 31.2
65: 33.0
66: 34.8
67: 36.6
68: 38.4
69: 40.2
70: 42.0
71: 43.8
72: 45.6
73: 47.4
74: 49.2
75: 51.0
76: 52.8
77: 54.6
78: 56.4
79: 58.2
81: 66.0
82: 72.0
83: 78.0
84: 84.0
85: 90.0
86: 96.0
87: 102.0
88: 108.0
89: 114.0