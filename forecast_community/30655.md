(a) Time left until outcome: 7 months and 19 days (until December 31, 2025)

(b) Status quo outcome: No major AI lab has yet claimed to have developed AGI, though several leaders have discussed timelines and progress toward AGI.

(c) No outcome scenario: AI labs continue making incremental progress but remain cautious about making definitive AGI claims due to reputational risks, regulatory concerns, and the fuzzy definition of AGI. Leaders like Hassabis and Altman continue to discuss AGI as a near-future goal but avoid declaring they've achieved it in 2025.

(d) Yes outcome scenario: A competitive dynamic emerges between major labs, with one (likely OpenAI, Google DeepMind, or xAI) achieving a significant breakthrough in AI capabilities that they believe constitutes AGI. Under competitive pressure and seeking to establish historical primacy, a CEO like Sam Altman or Demis Hassabis makes a public claim of AGI achievement.

As a professional forecaster, I'll assess the likelihood of a major AI lab claiming to have developed AGI in 2025 based on the available evidence.

## Current Landscape of AGI Development

The AI landscape in mid-2025 shows accelerating progress toward more capable systems. Recently, major advances have been made in AI capabilities across multiple domains, with systems showing improved performance on benchmarks testing reasoning, programming, and scientific knowledge[4]. This progress has led some industry leaders to make increasingly confident statements about AGI timelines.

OpenAI CEO Sam Altman has been particularly bullish, having stated in 2024 that AGI could arrive as soon as 2025, describing it as "just an engineering problem"[1]. More recently, Google DeepMind CEO Demis Hassabis has indicated that AGI could be achieved within a 5-10 year timeframe, suggesting it's no longer a question of "if" but "when"[5]. These statements represent a notable shift in confidence compared to previous years.

## Factors Supporting a 2025 AGI Claim

Several factors increase the likelihood of a major lab making an AGI claim this year:

**1. Competitive Dynamics**

The race to develop AGI has intensified, with multiple labs explicitly targeting it. This competitive environment creates incentives for organizations to stake claims of achievement. The first company to credibly claim AGI development would gain enormous prestige, potential funding advantages, and possibly regulatory influence.

**2. Increasingly Bold Leadership Statements**

Leadership at major labs has grown more confident in public statements about AGI timelines. Particularly notable are Sam Altman's predictions about 2025 and Demis Hassabis's shortened timeline estimates[1][5]. These statements may be preparing the ground for eventual claims.

**3. Technical Progress**

Recent benchmarks show rapid improvement in AI capabilities. The AI Index Report 2025 indicates substantial performance gains on challenging benchmarks, with scores rising 18.8, 48.9, and 67.3 percentage points on MMMU, GPQA, and SWE-bench respectively over just one year[4]. This pace of advancement exceeds what many expected.

## Factors Against a 2025 AGI Claim

Several countervailing factors make a 2025 AGI claim less likely:

**1. Definition Ambiguity and Reputational Risk**

AGI remains a contested concept without universal agreement on what constitutes achievement. Making a premature claim risks significant reputational damage if the system doesn't meet broader expectations of AGI. Most labs would prefer to underclaim rather than overclaim on such a historically significant achievement.

**2. Expert Skepticism**

A substantial majority (76%) of AI researchers believe AGI is "unlikely" to result from simply scaling current methods[5]. This expert skepticism creates a high bar for any claim to be taken seriously by the technical community.

**3. Regulatory and Safety Concerns**

Claiming AGI achievement would likely trigger intense regulatory scrutiny and safety debates. Labs may prefer to avoid these complications by continuing to frame their systems as approaching but not yet achieving AGI, especially given growing calls for stronger AI regulation[5].

**4. Recent History of Cautious Claims**

Despite rapid progress, major labs have historically been relatively conservative in how they characterize their systems' capabilities. Even as capabilities have advanced dramatically since 2022, no major lab has yet formally claimed AGI achievement, suggesting a pattern of caution that may continue.

## Synthesis and Forecast

While the pace of AI advancement has accelerated and leader statements have grown bolder, there remains a significant gap between current capabilities and the full spectrum of human-level capabilities across domains that most definitions of AGI entail.

The most likely scenario is continued progress toward AGI with increasingly confident statements about approaching it, but without a formal claim of achievement in 2025. Labs will likely continue to emphasize specific capabilities rather than make the historically significant claim of having achieved AGI.

However, the likelihood of such a claim is substantially higher than in previous years. If one lab (most likely OpenAI) believes they've made a breakthrough that approximates AGI and faces competitive pressure to establish primacy, they may decide the benefits of claiming AGI outweigh the risks.

Given the evidence and competing factors, I estimate the probability of a major AI lab claiming to have developed AGI in 2025 at:

Probability: 25%