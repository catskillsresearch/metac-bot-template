The Machine Intelligence Research Institute (MIRI) has a long-standing presence in the field of AI safety, with a track record of adapting its strategy to meet evolving challenges. As of 2023, MIRI is undergoing a strategic pivot, shifting focus from purely technical research towards a blend of technical work, communications, and policy engagement. This shift introduces both opportunities and risks for the organization's future.

The growing importance of AI safety as a field works in MIRI's favor. As concerns about the potential risks of advanced AI systems increase, funding and attention in this area are likely to grow. This trend could benefit MIRI, especially if they successfully position themselves at the intersection of technical research, policy, and public communication.

However, MIRI's strategic pivot also introduces significant uncertainties. The organization has acknowledged the possibility of needing to "drastically change plans and scale back ambitions" if funding becomes difficult. This shift may affect their competitiveness for certain grants and donations, particularly those focused on technical AI safety research.

MIRI's financial management provides some buffer against short-term funding challenges. The organization maintains substantial reserves, reportedly sufficient for at least two years of operations. This prudent approach gives MIRI time to adapt and refine its new strategy.

The definition of "researcher" in this context is crucial. MIRI's shift towards communications and policy work could potentially lead to a scenario where they no longer meet the criteria for employing "researchers" as traditionally defined in the AI safety field. However, their stated intention to maintain a core of technical research suggests they are likely to continue employing at least some researchers in the conventional sense.

MIRI's established reputation and network within the AI safety community are significant assets. These relationships and their history of contributions to the field increase the likelihood of continued support and collaboration, even as their focus evolves.

While the risks to MIRI's continued employment of researchers are real and significant, they do not outweigh the factors supporting a positive outcome. The organization's adaptability, financial prudence, and the growing importance of AI safety all suggest that MIRI is more likely than not to continue employing researchers in some capacity by 2030. However, the acknowledged strategic and funding risks mean this outcome is less certain than it might have been in previous years.

### Probability: 65%