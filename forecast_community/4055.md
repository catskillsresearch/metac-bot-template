## Rationale for Whether the First AGI Will Be Based on Deep Learning

Deep learning has become the dominant paradigm in artificial intelligence research since the 2010s, fueled by major advances in neural network architectures, significant investments from leading tech companies, and impressive improvements in task-specific performance. The largest AI labs—such as OpenAI, Google DeepMind, and Anthropic—are heavily committed to scaling deep learning approaches, with each new generation of models demonstrating increasingly sophisticated and general capabilities. Statements from industry leaders and strategic roadmaps from these organizations consistently indicate that, barring a radical shift, deep learning remains the primary path toward AGI in the near future.

The technical success of deep learning is rooted in its ability to process vast datasets and uncover hierarchical representations through multilayered neural networks. This approach has led to breakthroughs in language, vision, and reasoning tasks, and scaling these models has been a reliable route to previously unanticipated emergent capabilities. The ongoing trend is to augment these architectures with mechanisms for memory, attention, and planning—components that often still fundamentally rely on deep learning principles.

However, deep learning is not without significant theoretical and practical limitations. Current systems lack true causal reasoning, common sense understanding, and are inefficient learners compared to humans. They are highly dependent on vast quantities of training data and significant computational resources, and they often struggle to generalize beyond their training distribution. These limitations have spurred active research into alternative paradigms, including symbolic reasoning, neuromorphic computing, program synthesis, and hybrid systems. Some researchers argue that deep learning alone may not be sufficient for achieving general intelligence, highlighting the need for more flexible and data-efficient learning mechanisms.

Given these factors, a plausible path to AGI is through hybrid architectures that build primarily on deep learning foundations while integrating additional components designed to overcome its weaknesses—such as incorporating symbolic reasoning or memory modules. Such hybrid systems may still be recognized by experts as being "based on deep learning" if neural networks remain the dominant architectural principle. The current momentum, infrastructure, and expertise invested in deep learning create strong inertia, making a near-term paradigm shift less likely in the absence of a groundbreaking discovery in competing approaches.

Ultimately, whether the first AGI will be considered "based on deep learning" will be determined by expert consensus, focusing on the degree to which deep learning principles underpin the majority of the system’s architecture and learning mechanisms. While there is uncertainty due to the unknown timeframe for AGI’s arrival and the possibility of disruptive breakthroughs, the weight of current trends, industry investment, expert opinion, and practical progress strongly suggest that deep learning, possibly in combination with supplementary techniques, will form the foundation of the first AGI system.

### Probability: 75%