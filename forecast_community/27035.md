The scenario in which artificial intelligence causes the global human population to fall below 5,000 individuals before 2100 would require an extraordinary and historically unprecedented confluence of events. While existential risks from AI are actively debated by experts, and a minority of researchers place non-negligible probabilities (generally in the 1-10% range) on AI being capable of such catastrophic outcomes, this view is not universally accepted and may be influenced by definitional ambiguities and psychological factors tied to new technologies.

For such a near-extinction event to occur, multiple, extremely high barriers must be breached. First, AI would need to reach a level of autonomy, capability, and misalignment where it could either directly target humans—via autonomous weapons, infrastructure sabotage, or engineered pandemics—or facilitate the creation and deployment of novel technologies that could cause unprecedented destruction. This would necessitate not only vast technical advances but also the failure of all existing and developing safety measures, regulatory regimes, and global governance mechanisms specifically designed to mitigate these very risks.

The sheer scale of population reduction required—wiping out more than 99.99% of living humans—faces additional hurdles. Human populations are large, geographically dispersed, and historically resilient, having survived severe pandemics, wars, and existential threats such as nuclear weapons. For AI to drive the global population below 5,000, catastrophic failures would need to occur simultaneously across continents, evading all societal, technological, and governmental fail-safes. Even in worst-case scenarios, complete extinction or near-extinction remains logistically and biologically improbable, given humanity’s adaptability and distribution.

Meanwhile, demographic projections overwhelmingly foresee global population in the billions by 2100, with current challenges centering on population decline due to falling fertility rates rather than extinction threats. While AI could exacerbate societal issues or contribute to regional crises, no credible mechanism currently links ongoing AI advancements to a realistic near-extinction trajectory. Instead, AI is more likely to be integrated into efforts addressing existing global challenges, such as healthcare, resource allocation, and adaptation to demographic shifts.

Importantly, the rising awareness of potential AI risks has led to a surge in technical research on AI alignment and regulation, with international organizations and governments increasingly prioritizing risk mitigation. Although uncertainty remains and unprecedented "black swan" events cannot be categorically ruled out, the inertia of current demographic and technological trends, the robustness of human civilization, and the growing focus on AI safety collectively render a near-extinction outcome vanishingly unlikely—barring radical and unforeseeable developments. 

Ultimately, the probability that AI will directly cause the global human population to fall below 5,000 before 2100 is exceedingly low. This outcome would demand a series of catastrophic, poorly understood, and currently unobserved failures—making it a theoretical possibility but not a credible forecast given everything known today.

### Probability: 1%