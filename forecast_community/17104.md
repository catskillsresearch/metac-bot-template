(a) Time left until outcome: About 7.5 months (until December 31, 2025)
(b) Status quo outcome: NO - there has not yet been a joint statement by three or more Frontier AI Labs explicitly committing to constrain their AI's capabilities
(c) No outcome scenario: Competitive pressures and commercial incentives continue to prevent labs from making binding commitments to limit their AI capabilities, with collaborations remaining focused on safety processes rather than capability constraints
(d) Yes outcome scenario: A significant AI safety incident or increased regulatory pressure leads frontier labs to jointly commit to specific compute limitations or capability restrictions to prevent more severe government intervention

Based on the search results and current state of affairs as of May 13, 2025, I'll provide my forecast on whether three or more Frontier AI Labs will issue a joint statement committing to constrain their AI's capabilities before 2026.

## Historical Context and Current Trends

Since 2023, we've seen increasing collaboration among Frontier AI Labs on safety issues. The National Security Memorandum (NSM) on Artificial Intelligence from January 2025 outlined aims for the US to lead in developing "safe, secure, and trustworthy AI"[1]. Similarly, the Biden administration's Executive Order from January 2025 set the path for ensuring frontier AI continues to be built in the United States[2].

However, none of these initiatives have resulted in the specific type of joint commitment described in the question criteria. The "Frontier AI Safety Commitments" mentioned in earlier news represented general safety principles rather than concrete capability constraints[5].

## Current Dynamics in the AI Landscape

The AI development landscape in mid-2025 shows:

1. **Accelerating capabilities**: Bank of America analysts note that model sizes are doubling approximately every six months, with total AI capex spending expected to reach $414 billion in 2025, a 44% increase from last year, indicating intense competition and investment.

2. **Growing regulatory attention**: California's Frontier AI Working Group has issued reports on foundation model regulation, focusing on transparency, third-party risk assessment, and adverse event reporting - but not explicit capability constraints.

3. **Increasing concerns about control**: Recent articles mention renewed fears about superintelligent AI, with experts like Nate Soares warning about self-coding AIs that can improve themselves with minimal human oversight.

## Factors Making a Joint Constraint Commitment Unlikely

1. **Commercial incentives remain strong**: The search results indicate major hyperscalers (Google, Microsoft, Meta) are reaffirming or increasing their capex outlooks for AI in 2025, suggesting they're focused on expansion, not constraint.

2. **International competition**: Countries like Korea are explicitly aiming to become "one of the world's three AI powerhouses," indicating that national competition is intensifying rather than converging toward restraint.

3. **Regulatory approaches focus on transparency**: Current regulatory efforts, like California's, emphasize transparency and reporting requirements rather than direct constraints on capabilities.

## Factors That Could Lead to a Joint Constraint Commitment

1. **Growing safety concerns**: Recent articles mention renewed fears about superintelligent AI, which could eventually lead to more concrete actions if these concerns gain wider traction.

2. **Potential for incidents**: As models continue to scale rapidly, the possibility of a concerning incident increases, which could prompt a reactive commitment.

3. **Evolving regulatory pressure**: The California Frontier AI Working Group's reports could eventually lead to more restrictive regulations that labs might preemptively address through voluntary constraints.

## Weighing the Evidence

The primary impediment to such a joint statement is the fundamental tension between competitive incentives and safety concerns. The search results consistently show that AI labs and their major customers are focused on scaling up, not constraining capabilities.

While safety discussions continue, they remain process-oriented rather than capability-limiting. The definition of "constraining capabilities" in the resolution criteria is deliberately narrow, requiring explicit limitations on general capabilities such as compute usage caps or performance restrictions.

The status quo strongly suggests that without a significant external catalyst, such as a major incident or imminent heavy-handed regulation, the commercial incentives will continue to dominate decision-making at Frontier AI Labs.

Probability: 15%