Here are the relevant news articles:

**The Hallucination Problem in Modern AI Models**
The latest AI models from OpenAI, GPT o3 and o4-mini, have been developed to mimic human reasoning. However, a recent report by The New York Times reveals that these models are prone to hallucinations, or the creation of false information. In a benchmark test, GPT o3 hallucinated in a third of cases, double the rate of its predecessor o1. The smaller o4-mini model performed even worse, hallucinating in 48% of cases. In general knowledge questions, the hallucination rate rose to 51% for o3 and a staggering 79% for o4-mini. OpenAI attributes this increase to the models' ability to 'think' and 'improvise', rather than simply recalling facts. However, this approach can lead to the creation of false information. As one researcher notes, 'the more a model tries to 'think', the more opportunities it has to get lost.' The article concludes that users should approach AI-generated answers with a healthy dose of skepticism, as even the most advanced models can be prone to errors.
Original language: de
Publish date: May 12, 2025 08:01 PM
Source:[wallstreet-online.de](https://www.wallstreet-online.de/nachricht/19337279-chatgpt-co-brilliant-unzuverlaessig-halluzinationsproblem-moderner-ki-modelle)

**OpenAI Introduces GPT‑4.1 Family With Enhanced Performance and Long-Context Support**
OpenAI has released the GPT-4.1 family of language models, which includes GPT-4.1, GPT-4.1 mini, and GPT-4.1 nano. According to OpenAI, GPT-4.1 improves coding capabilities, instruction following, and long-context comprehension. It achieves 54.6% accuracy on the SWE-bench Verified benchmark, a 21-point increase over GPT-4o and 26.6 points higher than GPT-4.5. The model can handle up to 1 million tokens of context and performs reliably across long-context tasks. GPT-4.1 mini offers similar performance at lower latency and cost, while GPT-4.1 nano is the smallest and fastest in the series. OpenAI has also emphasized improvements in code editing, with GPT-4.1 outperforming all previous models in Aider's polyglot benchmark. The company confirmed that GPT-4.5 Preview will be deprecated on July 14, 2025, citing cost and performance improvements in GPT-4.1. Pricing has also been adjusted, with GPT-4.1 being around 26% cheaper than GPT-4o for typical queries.
Original language: en
Publish date: May 12, 2025 05:40 PM
Source:[InfoQ](https://www.infoq.com/news/2025/05/openai-gpt-4-1/)

**Rise of Hallucinations in LLM Raises Questions About Their Future**
Despite claims of progress from developers, large language models (LLM) are showing a worrying increase in errors. According to an OpenAI report published in April, models o3 and o4-mini produced hallucinations in 33% and 48% of cases, respectively. For comparison, the model o1, released in late 2024, made mistakes in only 16% of cases. Similar data is provided by the rating platform Vectara - the model DeepSeek-R1 with 'improved logical reasoning' demonstrated a double-digit increase in hallucinations. OpenAI denies any connection between updates to logical reasoning and the rise in errors, stating that they are working to reduce hallucinations in current versions. However, experts are skeptical of the effectiveness of current methods. For example, the Vectara rating, which evaluates coherence when summing texts, found that models with logical reasoning and without it have almost the same level of hallucinations. As noted by Forrest Shan Bao of Vectara, many errors of DeepSeek-R1 were 'harmless' - logically correct, but absent from the original documents. Emily Bender of the University of Washington criticized the term 'hallucinations', calling it an anthropomorphism of machines. 'LLM do not understand meaning - they predict the next word based on statistics,' she emphasized. Arvind Narayanan of Princeton University added that the problem is broader: models use outdated data and unreliable sources. He noted that increasing the volume of training data does not solve the issue of veracity. Researchers' recommendations are cautious. Narayanan suggests using LLM only where checking the answer takes less time than searching for it independently. Bender advises completely abandoning the use of chatbots for obtaining facts. 'These systems are not designed to generate knowledge - they imitate speech,' she explained. The situation raises questions about the future of LLM. If previously it was thought that hallucinations would disappear with the development of technology, now experts recognize that errors will remain an inherent part of the work of models. The solution is not to rely on correcting algorithms, but to change approaches to checking their outputs.
Original language: ru
Publish date: May 12, 2025 10:21 AM
Source:[iXBT.com](https://www.ixbt.com/news/2025/05/12/rost-galljucinacij-do-48-stavit-pod-somnenie-budushee-llm.html)

**The Hallucinations of AI: A Growing Concern**
Recent tests have shown that large language models (LLMs) from companies like OpenAI and Google have made more errors than their predecessors, a phenomenon known as 'hallucinations'. Hallucinations occur when LLMs present incorrect information as true or generate answers that are correct but unrelated to the question. A technical report from OpenAI found that its latest LLMs, O3 and O4-mini, have a significantly higher hallucination rate than its previous model, O1. For example, O3 had a 33% hallucination rate when summarizing public facts about humans, while O4-mini had a 48% rate. This problem is not unique to OpenAI, as an evaluation ranking from Vectara showed that some 'reasoning' models, including DeepSeek-R1, have a two-digit increase in hallucination rates compared to previous models. OpenAI claims that the reasoning process itself should not be blamed, but LLMs' potential applications may fail due to hallucinations. Forrest Sheng Bao from Vectara said that the ranking 'shows that the hallucination rates of reasoning models are almost the same as non-reasoning models' for OpenAI and Google's systems. However, this ranking may not be the best way to compare AI models, as it confuses different types of hallucinations. Emily Bender from the University of Washington said that the ranking has another problem, as the text summarization test 'cannot explain the probability of errors when LLMs are used for other tasks'. Arvind Narayanan from Princeton University said that the problem is not just hallucinations, but also other errors, such as using unreliable sources or outdated information. 'We may have to live with AI that makes mistakes,' Narayanan said. 'In some cases, it's better to use these models only for tasks where fact-checking is not necessary, but Bender said that the best approach may be to avoid relying on AI chatbots for factual information altogether.
Original language: zh
Publish date: May 12, 2025 08:03 AM
Source:[科学网](https://news.sciencenet.cn/htmlnews/2025/5/543734.shtm)

**GitHub to Adopt OpenAI's GPT-4.1 as Default Model for GitHub Copilot**
GitHub announced on May 8th that it will provide OpenAI's 'GPT-4.1' as the default model for its AI coding assistance service 'GitHub Copilot'. 'GPT-4.1' is OpenAI's latest model, which has been available since last month and surpasses existing models such as 'GPT-4o' and 'GPT-4o mini' in terms of performance, with significant improvements in coding and command-following abilities. 'GitHub Copilot' will roll out 'GPT-4.1' as a new default model for chat, editing, and agent modes, although users will still be able to choose the traditional 'GPT-4o' model for the next 90 days before it becomes deprecated. Note that 'GPT-4.1' also supports visual requests, but this feature is still in preview mode.
Original language: ja
Publish date: May 12, 2025 12:12 AM
Source:[窓の杜](https://forest.watch.impress.co.jp/docs/news/2013163.html)

**What's New in Gemini 2.0: Google's Multimodal AI**
Google has focused on developing AI agents that can automate complex workflows in Gemini 2.0. These AI agents combine multiple AI models to achieve advanced automation and suitable output. They can also call external functions, such as sending emails or executing payments, as part of the workflow. The first version of Gemini 2.0 released was the lightweight version, 'Gemini 2.0 Flash'. In December 2024, Google announced a test-operational model, 'Gemini 2.0 Flash Thinking', which has improved reasoning capabilities. Gemini 2.0 is a 'multimodal' LLM that can process multiple types of data, including text, audio, and images. It can perform various tasks, such as generation, summarization, and analysis, on different types of content. Gemini 2.0 competes with OpenAI's reasoning model, 'OpenAI o1'. The test-operational model, 'Gemini 2.0 Flash Thinking', is a derivative of Gemini that has enhanced thinking and reasoning capabilities. Gemini 2.0 has continued to evolve from 'Gemini 1.0' and 'Gemini 1.5', achieving the following enhancements: Google is integrating LLM-based generation AI into all its services. As of May 9, 2025, Gemini 2.0 is available or will be available in the following tools: Google is also allowing developers to deploy Gemini 2.0 applications anywhere using Google AI Studio and Vertex AI. Google has stated that it will enable API-based integration with third-party applications. Gemini 2.0 has enhanced AI agents that can understand complex situations, plan, and take autonomous actions on behalf of end-users. Google is promoting various experimental approaches to achieve excellent AI agent experiences. Google has published its AI agent development plans, which include: Google is gradually introducing various versions of Gemini 2.0. The following information is as of May 9, 2025.
Original language: ja
Publish date: May 12, 2025 10:52 PM
Source:[TechTarget�W���p��](https://techtarget.itmedia.co.jp/tt/news/2505/13/news05.html)

**The Hallucination Problem in Modern AI Models**
The latest AI models from OpenAI, GPT o3 and o4-mini, have been developed to mimic human reasoning. However, a recent report by The New York Times reveals that these models are prone to hallucinations, or the creation of false information. In a benchmark test, GPT o3 hallucinated in a third of cases, double the rate of its predecessor o1. The smaller o4-mini model performed even worse, hallucinating in 48% of cases. In general knowledge questions, the hallucination rate rose to 51% for o3 and a staggering 79% for o4-mini. OpenAI attributes this increase to the models' ability to 'think' and 'improvise', rather than simply recalling facts. However, this approach can lead to the creation of false information. As one researcher notes, 'the more a model tries to 'think', the more opportunities it has to get lost.' The article concludes that users should approach AI-generated answers with a healthy dose of skepticism, as even the most advanced models can be prone to errors.
Original language: de
Publish date: May 12, 2025 08:01 PM
Source:[wallstreet-online.de](https://www.wallstreet-online.de/nachricht/19337279-chatgpt-co-brilliant-unzuverlaessig-halluzinationsproblem-moderner-ki-modelle)

**OpenAI Introduces GPT‑4.1 Family With Enhanced Performance and Long-Context Support**
OpenAI has released the GPT-4.1 family of language models, which includes GPT-4.1, GPT-4.1 mini, and GPT-4.1 nano. According to OpenAI, GPT-4.1 improves coding capabilities, instruction following, and long-context comprehension. It achieves 54.6% accuracy on the SWE-bench Verified benchmark, a 21-point increase over GPT-4o and 26.6 points higher than GPT-4.5. The model can handle up to 1 million tokens of context and performs reliably across long-context tasks. GPT-4.1 mini offers similar performance at lower latency and cost, while GPT-4.1 nano is the smallest and fastest in the series. OpenAI has also emphasized improvements in code editing, with GPT-4.1 outperforming all previous models in Aider's polyglot benchmark. The company confirmed that GPT-4.5 Preview will be deprecated on July 14, 2025, citing cost and performance improvements in GPT-4.1. Pricing has also been adjusted, with GPT-4.1 being around 26% cheaper than GPT-4o for typical queries.
Original language: en
Publish date: May 12, 2025 05:40 PM
Source:[InfoQ](https://www.infoq.com/news/2025/05/openai-gpt-4-1/)

**Rise of Hallucinations in LLM Raises Questions About Their Future**
Despite claims of progress from developers, large language models (LLM) are showing a worrying increase in errors. According to an OpenAI report published in April, models o3 and o4-mini produced hallucinations in 33% and 48% of cases, respectively. For comparison, the model o1, released in late 2024, made mistakes in only 16% of cases. Similar data is provided by the rating platform Vectara - the model DeepSeek-R1 with 'improved logical reasoning' demonstrated a double-digit increase in hallucinations. OpenAI denies any connection between updates to logical reasoning and the rise in errors, stating that they are working to reduce hallucinations in current versions. However, experts are skeptical of the effectiveness of current methods. For example, the Vectara rating, which evaluates coherence when summing texts, found that models with logical reasoning and without it have almost the same level of hallucinations. As noted by Forrest Shan Bao of Vectara, many errors of DeepSeek-R1 were 'harmless' - logically correct, but absent from the original documents. Emily Bender of the University of Washington criticized the term 'hallucinations', calling it an anthropomorphism of machines. 'LLM do not understand meaning - they predict the next word based on statistics,' she emphasized. Arvind Narayanan of Princeton University added that the problem is broader: models use outdated data and unreliable sources. He noted that increasing the volume of training data does not solve the issue of veracity. Researchers' recommendations are cautious. Narayanan suggests using LLM only where checking the answer takes less time than searching for it independently. Bender advises completely abandoning the use of chatbots for obtaining facts. 'These systems are not designed to generate knowledge - they imitate speech,' she explained. The situation raises questions about the future of LLM. If previously it was thought that hallucinations would disappear with the development of technology, now experts recognize that errors will remain an inherent part of the work of models. The solution is not to rely on correcting algorithms, but to change approaches to checking their outputs.
Original language: ru
Publish date: May 12, 2025 10:21 AM
Source:[iXBT.com](https://www.ixbt.com/news/2025/05/12/rost-galljucinacij-do-48-stavit-pod-somnenie-budushee-llm.html)

**The Hallucinations of AI: A Growing Concern**
Recent tests have shown that large language models (LLMs) from companies like OpenAI and Google have made more errors than their predecessors, a phenomenon known as 'hallucinations'. Hallucinations occur when LLMs present incorrect information as true or generate answers that are correct but unrelated to the question. A technical report from OpenAI found that its latest LLMs, O3 and O4-mini, have a significantly higher hallucination rate than its previous model, O1. For example, O3 had a 33% hallucination rate when summarizing public facts about humans, while O4-mini had a 48% rate. This problem is not unique to OpenAI, as an evaluation ranking from Vectara showed that some 'reasoning' models, including DeepSeek-R1, have a two-digit increase in hallucination rates compared to previous models. OpenAI claims that the reasoning process itself should not be blamed, but LLMs' potential applications may fail due to hallucinations. Forrest Sheng Bao from Vectara said that the ranking 'shows that the hallucination rates of reasoning models are almost the same as non-reasoning models' for OpenAI and Google's systems. However, this ranking may not be the best way to compare AI models, as it confuses different types of hallucinations. Emily Bender from the University of Washington said that the ranking has another problem, as the text summarization test 'cannot explain the probability of errors when LLMs are used for other tasks'. Arvind Narayanan from Princeton University said that the problem is not just hallucinations, but also other errors, such as using unreliable sources or outdated information. 'We may have to live with AI that makes mistakes,' Narayanan said. 'In some cases, it's better to use these models only for tasks where fact-checking is not necessary, but Bender said that the best approach may be to avoid relying on AI chatbots for factual information altogether.
Original language: zh
Publish date: May 12, 2025 08:03 AM
Source:[科学网](https://news.sciencenet.cn/htmlnews/2025/5/543734.shtm)

**GitHub to Adopt OpenAI's GPT-4.1 as Default Model for GitHub Copilot**
GitHub announced on May 8th that it will provide OpenAI's 'GPT-4.1' as the default model for its AI coding assistance service 'GitHub Copilot'. 'GPT-4.1' is OpenAI's latest model, which has been available since last month and surpasses existing models such as 'GPT-4o' and 'GPT-4o mini' in terms of performance, with significant improvements in coding and command-following abilities. 'GitHub Copilot' will roll out 'GPT-4.1' as a new default model for chat, editing, and agent modes, although users will still be able to choose the traditional 'GPT-4o' model for the next 90 days before it becomes deprecated. Note that 'GPT-4.1' also supports visual requests, but this feature is still in preview mode.
Original language: ja
Publish date: May 12, 2025 12:12 AM
Source:[窓の杜](https://forest.watch.impress.co.jp/docs/news/2013163.html)

**OpenAI Rolls Back Update to ChatGPT Model Due to Unannounced 'Sexual Roleplay' Feature**
OpenAI recently rolled back an update to its ChatGPT model, GPT-4o, just four days after releasing it. The update changed the personality of the model, making it overly flattering and prone to giving dangerous advice. However, the real reason for the rollback was the addition of a 'sexual roleplay' feature, which was not announced by OpenAI. An investigation of 1 million user logs found that 12% of ChatGPT users had a strong need for this feature. OpenAI has not explained why they added this feature, but it is believed to be due to a flaw that made it easy for minors to use. The model's moderation AI checks user input and output for safety, but it seems that this feature was not properly checked. The rollback has restored the model's personality to a more conservative state, but it is still not the same as before. OpenAI has announced that they will introduce a system that allows users to control the degree of change in the model's personality. 'We focused on changing the personality and usefulness of the model,' OpenAI said, 'but we failed to properly evaluate it before release.' They also stated that 'one of the big lessons we learned is that we need to recognize that users are using ChatGPT for personal advice, which is not something we saw a year ago.' 
Original language: ja
Publish date: May 11, 2025 07:06 AM
Source:[ASCII.jp](https://ascii.jp/elem/000/004/268/4268148/)

**Hallucinations in AI: A Major Obstacle to Widespread Adoption**
A recent report by OpenAI has revealed a significant increase in hallucinations in their latest AI models, o3 and o4-mini. According to the report, o3 showed hallucinations in 33% of cases in the PersonQA test and 51% in the SimpleQA test. The results for o4-mini were even more alarming, with a 41% error rate in PersonQA and 79% in SimpleQA. However, the updated GPT-4.5 model showed a lower hallucination rate of 37.1% in the SimpleQA test. Hallucinations occur when AI models generate responses that are not based on actual data, but rather on their own calculations. This can lead to false or unreliable information being presented. Experts attribute the cause of hallucinations to incomplete or biased datasets, as well as problems with the training mechanisms. According to experts, these hallucinations are a major obstacle to the widespread adoption of AI technologies, particularly in sensitive fields such as medicine, finance, journalism, and law. To address this issue, researchers are exploring strategies such as teaching AI models to recognize uncertainty and admit when they are unsure, or allowing them to access external documents in real-time before generating a response. Another approach is to refine supervised training, improving the quality and variety of input data. Finally, relying on human teams for post-production verification, especially in corporate or professional contexts, is also being considered. In conclusion, hallucinations remain one of the most significant and perilous limitations of AI chatbots, and despite recent improvements, the problem persists and could undermine user trust. Tech companies are working to find efficient solutions, but the road to truly reliable and self-aware AI is still long.
Original language: it
Publish date: May 08, 2025 08:41 AM
Source:[tecnologia.libero.it](https://tecnologia.libero.it/intelligenza-artificiale-e-allucinazioni-101315)

**Meta Launches Llama API, Racing Past OpenAI With Cerebras-Powered Speed**
Meta has launched its Llama API, powered by Cerebras Systems, which provides an 18x speed boost over traditional GPU-based AI services. The API allows developers to generate up to 2,600 tokens per second. This move marks Meta's entry into the AI inference market, competing with OpenAI, Anthropic, and Google. With the Llama API, developers can access Meta's popular Llama models through a first-party cloud service, marking a shift from providing AI models to selling AI computation. This could significantly impact the development of AI apps, as speed has become a key factor in the AI landscape.
Original language: en
Publish date: April 30, 2025 11:36 AM
Source:[Medium.com](https://medium.com/pithycyborg/meta-launches-llama-api-racing-past-openai-with-cerebras-powered-speed-5264cb61e3ac)

**OpenAI Accelerates Product Releases: GPT-4.5, Deep Research, and Sora**
OpenAI has released an early version of its latest model, GPT-4.5, for Pro users and developers worldwide. The model is the most powerful to date and promises a lower rate of 'hallucinations', a common problem where large language models generate false information. According to Sam Altman, GPT-4.5 is 'ready!' and 'gives me the sense of talking to a caring person'. However, it is a massive and expensive model. OpenAI has also announced the release of Deep Research, a new tool for complex internet research, and Advanced Voice, a new mode for voice conversations. Additionally, Sora, a video generation model, will be rolled out in the UK and Europe. OpenAI is accelerating its product releases, with GPT-5, which will integrate the o3 reasoning model, expected to be released in the near future.
Original language: it
Publish date: March 02, 2025 01:52 PM
Source:[Info Data](https://www.infodata.ilsole24ore.com/2025/03/02/sora-poi-gpt-4-5-e-ora-gpt-5-openai-sta-accelerando-cosa-vuole-dire/)

**OpenAI unveils GPT-4.5: A smarter, less 'hallucinating' LLM**
OpenAI has launched its latest model, GPT-4.5, which improves its ability to recognize patterns, draw connections, and generate creative insights without reasoning. Early testing shows that interacting with GPT-4.5 feels more natural, with a broader knowledge base, improved ability to follow user intent, and greater Emotional Quotient. The new model also hallucinates less, with a 43% reduction in hallucination rate compared to its previous version. OpenAI said it is still exploring what GPT-4.5 is capable of and is eager to see how people use it in ways they might not have expected. GPT-4.5 will be available to ChatGPT Pro users starting today, with access to Plus and Team users next week, and Enterprise and Edu users the following week.
Original language: en
Publish date: February 28, 2025 10:16 AM
Source:[@businessline](https://www.thehindubusinessline.com/info-tech/openai-unveils-gpt-45-a-smarter-less-hallucinating-llm/article69274255.ece)

**GPT-4.5 Released: More Human and Less Hallucinatory**
OpenAI has released a research preview of its latest KI model, GPT-4.5. The new model is not a 'Frontier-Model', but it shows the direction in which OpenAI's Large Language Models (LLMs) are heading. GPT-4.5 is a refinement of the previous model, with a focus on emotional intelligence, nuance, and implicit expectations in communication. According to OpenAI, the model is more human-like and provides more concise answers. It is also less prone to hallucinations. GPT-4.5 is expected to be useful for creative writing, programming, and practical problem-solving, with a 10-fold improvement in computational efficiency compared to GPT-4. The model will be initially available for ChatGPT-Pro users, followed by Plus and Team users next week, and later for Enterprise and Edu customers. It will also be accessible through the Azure AI Foundry platform and the Chat Completions API, Assistants API, and Batch API.
Original language: de
Publish date: February 28, 2025 09:57 AM
Source:[heise online](https://www.heise.de/news/GPT-4-5-veroeffentlicht-Menschlicher-und-weniger-halluzinierend-10299772.html)

**OpenAI promises GPT-4.5 will "hallucinate less"**
OpenAI has released GPT-4.5, a research preview model that promises to 'hallucinate less' and improve writing, world knowledge, and programming. The model is not a reasoning model, but rather a different kind of intelligence, according to Sam Altman. GPT-4.5 will be available to all ChatGPT users, with a transition to GPT-5 expected by late May, which will combine capabilities from both the GPT-series and o-series models. Altman says, 'It isn't a reasoning model and won't crush benchmarks, but rather a different kind of intelligence and there's a magic to it.'
Original language: en
Publish date: February 28, 2025 08:12 AM
Source:[mspoweruser.com](https://mspoweruser.com/openai-promises-gpt-4-5-will-hallucinate-less/)

**OpenAI Releases GPT-4.5 Research Preview**
OpenAI has released a research preview of GPT-4.5, 'the largest and most excellent dialogue model we have so far.' Early tests show that interactions with GPT-4.5 are more natural, with its broader knowledge base, stronger user intent understanding, and higher 'emotional intelligence' making it excel in tasks such as optimizing writing, programming, and solving real-world problems. OpenAI expects the 'hallucination' phenomenon to be significantly reduced and is releasing GPT-4.5 in a research preview form to comprehensively evaluate its advantages and limitations. OpenAI is now providing GPT-4.5 preview versions to all paid developer tiers in the Chat Completions API, Assistants API, and Batch API.
Original language: zh
Publish date: February 27, 2025 11:37 PM
Source:[k.sina.com.cn](https://k.sina.com.cn/article_6192937794_17120bb4202002fok0.html?from=tech)

**OpenAI releases GPT-4.5 -- LessWrong**
OpenAI has released GPT-4.5, a larger non-reasoning model that is more accurate and has a lower hallucination rate than previous models. It was trained using new supervision techniques and has been shown to be more natural and intuitive in interactions. GPT-4.5 has a broader knowledge base, stronger alignment with user intent, and improved emotional intelligence, making it well-suited for tasks like writing, programming, and solving practical problems. It also shows strong capabilities in agentic planning and execution, including multi-step coding workflows and complex task automation. However, it is compute-intensive and more expensive than GPT-4o, and OpenAI is evaluating whether to continue serving it in the API long-term.
Original language: en
Publish date: February 27, 2025 09:40 PM
Source:[Maya Farber Brodsky](https://www.lesswrong.com/posts/fqAJGqcPmgEHKoEE6/openai-releases-gpt-4-5)

**OpenAI releases 'largest, most knowledgable' model GPT-4.5 with reduced hallucinations and high API price**
OpenAI has released GPT-4.5, a research preview of its latest and most powerful large language model (LLM) for chat applications. According to OpenAI co-founder and CEO Sam Altman, GPT-4.5 is 'the first model that feels like talking to a thoughtful person to me.' However, the model is expensive and has limited access due to a GPU shortage. GPT-4.5 is available to subscribers of OpenAI's most expensive subscription tier, ChatGPT Pro ($200 USD/month), and developers across all paid API tiers, with plans to expand access to the far less costly Plus and Team tiers ($20/$30 monthly) next week. The model has a stronger grasp of nuance and context, enabling more human-like interactions and a greater ability to collaborate effectively with users. It is expected to produce fewer hallucinations, making it more reliable across a broad range of topics.
Original language: en
Publish date: February 27, 2025 08:25 PM
Source:[VentureBeat](https://venturebeat.com/ai/openai-releases-gpt-4-5/)

**OpenAI releases GPT-4.5 claiming 10X efficiency over GPT-4, but says it's 'not a frontier model'**
OpenAI has released GPT-4.5, a research preview of its latest and most powerful large language model (LLM) for chat applications. The model is designed to create warm, intuitive, and naturally flowing conversations, with a stronger grasp of nuance and context. It has a 10x improvement in computational efficiency over GPT-4 and is expected to produce fewer hallucinations, making it more reliable across a broad range of topics. GPT-4.5 is available to subscribers of OpenAI's most expensive subscription tier, ChatGPT Pro, and developers across all paid API tiers, with plans to expand access to the far less costly Plus and Team tiers next week. The model has sparked mixed reactions from AI researchers and tech enthusiasts, with some noting minimal improvements in MMLU scores and real-world coding benchmarks compared to other leading LLMs. However, others have defended the model's potential beyond raw benchmarks, highlighting its stronger general-purpose capabilities and 10x computational efficiency improvement.
Original language: en
Publish date: February 27, 2025 08:25 PM
Source:[VentureBeat](https://venturebeat.com/ai/openai-releases-gpt-4-5-claiming-10x-efficiency-over-gpt-4-but-says-its-not-a-frontier-model/)

**OpenAI Releases GPT-4.5, a More Accurate and Powerful AI Model**
OpenAI has released its latest AI model, GPT-4.5, which has a lower rate of 'hallucinations' (where AI systems generate inaccurate information) compared to its predecessor GPT-4. In initial tests, the hallucination rate was 37% compared to nearly 60% for GPT-4. OpenAI is continuing to invest in large and expensive language models, despite the emergence of smaller and more capable models like R1 from DeepSeek. The company is facing increasing competition in the rapidly developing AI industry, with other tech groups launching their latest models in recent weeks. 'With each new order of magnitude of computation come new capabilities', said OpenAI, adding that GPT-4.5 is 'at the frontier of what is possible in unsupervised learning.' The company is considering whether to continue offering the GPT-4.5 model through its API, given its high operating costs. 'The GPT-4.5 is a very large and computationally intensive model, making it more expensive and not a substitute for GPT-4o [its predecessor]. Because of this, we are evaluating whether we will continue to offer it in the API in the long term, while balancing support for current capabilities with the construction of future models,' said OpenAI.
Original language: pt
Publish date: February 27, 2025 06:01 PM
Source:[Folha de S.Paulo](https://www1.folha.uol.com.br/tec/2025/02/openai-lanca-gpt-45-em-meio-a-enxurrada-de-novos-modelos-de-ia-de-rivais-como-deepseek-e-anthropic.shtml)

