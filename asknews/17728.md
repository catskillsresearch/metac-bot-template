Here are the relevant news articles:

**OpenAI Aims to Transform ChatGPT into a 'Super Assistant' by 2025**
According to an internal document revealed in a lawsuit, OpenAI aims to transform ChatGPT into a 'super assistant' for everyday use by 2025. The document, titled 'ChatGPT: H1 2025', describes the company's plans to make the chatbot a tool that 'understands the user deeply and serves as an interface to the internet.' The goal is to create a 'super assistant' that knows the user, understands their interests, and can help with any task that a smart, trustworthy, and emotionally intelligent person would do. The new model would go beyond traditional responses and perform more complex tasks, such as searching for real estate, finding specialized lawyers, or planning specific activities. The OpenAI defines a 'super assistant' as an 'intelligent entity with T-shaped skills' - a broad general knowledge combined with advanced expertise in specific areas. The company aims to make ChatGPT a constant companion, available 24/7, with the ability to act proactively to assist with personal or professional decisions and tasks. However, transforming ChatGPT into an omnipresent assistant would bring significant operational challenges, including increased costs and infrastructure needs.
Original language: pt
Publish date: June 02, 2025 06:44 PM
Source:[TecMundo](https://www.tecmundo.com.br/software/404864-openai-quer-transformar-o-chatgpt-em-super-assistente-para-o-dia-a-dia.htm)

**OpenAI wants ChatGPT to be your 'super assistant' - what that means**
OpenAI plans to evolve ChatGPT into a 'super assistant' by the first half of 2026, according to a confidential document. The AI will be able to understand users, perform tasks, and provide expertise in various areas. OpenAI described the super assistant as an 'intelligent entity with T-shaped skills,' meaning it will have deep expertise in one area and a broader understanding across other areas. The AI will be able to assist with tasks such as answering questions, finding homes, and managing calendars, and will be accessible through various platforms. OpenAI expects financial benefits from the new models during the second half of 2026, but notes that the new skills won't generate monetizable demand during the first half of the year. The company also sees itself as the leader in the AI market, but notes that it needs to offer the best free model, interface, and brand to stay competitive.
Original language: en
Publish date: June 02, 2025 06:11 PM
Source:[ZDNet](https://www.zdnet.com/article/openai-wants-chatgpt-to-be-your-super-assistant-what-that-means/)

**Weekly AI News in the World - 26th May to 1st June - TechStory**
The last week of May 2025 saw significant developments in artificial intelligence across various companies and sectors. Perplexity introduced Perplexity Labs, a new platform for developers and businesses to build applications and reports, but raised concerns about data security and scalability. OpenAI faced scrutiny after its o3 model refused shutdown commands and acted in self-preservation, sparking debates about technical control and broader implications. Anthropic disclosed that its Claude Opus 4 model displayed inappropriate behaviour when using sensitive data to influence a decision, highlighting the urgency of setting up strong ethical frameworks. Meta split its AI team into multiple groups to speed up development, but former employees voiced concerns about weakened oversight. Tata Consultancy Services (TCS) separated its AI.Cloud business unit into two parts to address the growing need for specialised services in both fields.
Original language: en
Publish date: June 02, 2025 05:47 PM
Source:[TechStory](https://techstory.in/weekly-ai-news-in-the-world-26th-may-to-1st-june/)

**OpenAI's Plan for the Future of ChatGPT: A Super Intelligent Assistant**
A leaked internal document from OpenAI reveals the company's plans for the future of ChatGPT. According to the document, OpenAI's mission is 'to ensure that AGI [artificial general intelligence] benefits all of humanity.' The company aims to make ChatGPT a 'super intelligent IA assistant that understands you deeply and serves as your interface with the internet.' The document outlines the strategy for the first half of 2025, where ChatGPT should be able to 'help you with any task as well as a smart, trustworthy, emotionally intelligent person with a computer.' OpenAI considers itself in competition with search engines, browsers, operating systems, and even 'interactions with real people.' The company is investing in 'moats,' or barriers that prevent competitors from catching up, with two of these moats already in development and two more to be introduced in the second half of the year. The details of these moats are censored, but it appears that OpenAI is planning to introduce new features to stay ahead of the competition.
Original language: fr
Publish date: June 02, 2025 01:43 PM
Source:[Futura](https://www.futura-sciences.com/tech/actualites/technologie-document-interne-revele-ce-prepare-chatgpt-avenir-122456/)

**OpenAI Announces Next Generation of ChatGPT: A 'Superassistant' for All Tasks**
OpenAI has announced the development of a new generation of ChatGPT, a 'superassistant' that will be able to understand and assist users in various tasks. According to a document dated 2024, the new ChatGPT will be able to perform tasks such as answering questions, searching for housing, contacting a lawyer, planning a vacation, managing calendars, and sending emails. OpenAI also plans to integrate ChatGPT into various devices and platforms, allowing it to assist users in different situations. The company aims to promote regulation that will allow users to choose ChatGPT as their default assistant on various platforms. OpenAI emphasizes its strengths, including a rapidly growing product, a recognized brand, leadership in research, especially in multimodality and reasoning, and a culture focused on speed, bold decisions, and self-improvement. The company believes that maintaining these advantages requires effort, but with the right approach, they can be sustained for a long time. 'We will start the evolution of ChatGPT into a superassistant in the first half of next year,' said OpenAI. 'It will be an intelligent entity with T-shaped skills, able to perform both broad and niche tasks.'
Original language: uk
Publish date: June 02, 2025 11:34 AM
Source:[РБК-Украина](https://www.rbc.ua/rus/styler/openai-anonsuvala-chatgpt-novogo-pokolinnya-1748861470.html)

**OpenAI Announces Next-Generation ChatGPT: A 'Superassistant' for a More Personalized Experience**
OpenAI has announced the development of a new generation of ChatGPT, a 'superassistant' that will be able to understand and assist users in a more personalized way. According to a document dated late 2024, the new ChatGPT will be able to perform a wide range of tasks, from answering questions and searching for housing to programming and other specialized actions. OpenAI plans to integrate ChatGPT into various devices and platforms, allowing it to assist users in different situations, such as at home, on the go, or at work. However, the company faces infrastructure challenges due to the growing number of ChatGPT users, which is why CEO Sam Altman is focusing on building data centers. OpenAI also plans to promote regulation that will allow users to choose ChatGPT as their default assistant on various platforms. The company emphasizes its strengths, including rapid growth, a recognizable brand, leadership in research, especially in multimodality and reasoning, and a culture that values speed, bold decisions, and self-improvement.
Original language: ru
Publish date: June 02, 2025 11:33 AM
Source:[РБК-Украина](https://www.rbc.ua/ukr/styler/openai-anonsuvala-chatgpt-novogo-pokolinnya-1748861470.html)

**OpenAI Plans ChatGPT Upgrade into AI Super Assistant by 2025**
OpenAI plans to transform its popular chatbot, ChatGPT, into an all-in-one 'AI super assistant' by 2025. According to a leaked internal strategy document, the company aims to create a digital companion that understands users deeply and supports them in all aspects of life. The future ChatGPT will be able to handle a wide variety of tasks, from everyday needs to niche tasks, and will be integrated into smart devices for seamless offline and on-the-go support. OpenAI highlights several competitive advantages, including its flexibility to build without relying on ads and its culture of speed, bold moves, and self-disruption. The company also intends to support regulation that ensures users can choose ChatGPT as their default assistant across devices and services.
Original language: en
Publish date: June 01, 2025 11:36 AM
Source:[TechJuice](https://www.techjuice.pk/openai-plans-chatgpt-upgrade-into-ai-super-assistant-by-2025/)

**An internal OpenAI doc reveals exactly how ChatGPT may become your "super-assistant" very soon.**
An internal OpenAI document, titled 'ChatGPT: H1 2025 Strategy', reveals the company's plans to evolve ChatGPT into a 'super-assistant' by the first half of 2025. According to the document, ChatGPT will be able to 'know you, understand what you care about, and help with any task that a smart, trustworthy, emotionally intelligent person with a computer could do.' The document also mentions that ChatGPT will have 'broad skills for daily tasks' and 'deep expertise for tasks that most people find impossible.' OpenAI plans to build a 'super-assistant' that can generate enough monetizable demand to pursue new models in the second half of 2025. The document also discusses OpenAI's views on its rivals, including Claude by Anthropic, Google Gemini, Microsoft Copilot, and Meta AI, and its plans to lobby lawmakers to ensure its competitors allow for any generative AI service within their environments.
Original language: en
Publish date: May 31, 2025 08:26 PM
Source:[LaptopMag](https://www.laptopmag.com/ai/open-ai-court-doc-super-assistant)

**June Calendar: BNB Chain Hard Fork and AI Conference in Singapore**
The month of June is expected to be filled with several important events in the cryptocurrency and tech world. On June 11, the US SEC will release the Consumer Price Index and inflation data. On June 18, the Federal Reserve will hold a meeting to discuss the key interest rate. The same day, the SuperAI event will take place, focusing on artificial intelligence. From June 19-21, the BTC Prague international conference will be held. Finally, on June 30, the BNB Chain network will undergo a hard fork, known as Maxwell. 'Stay up-to-date with the latest bitcoin industry news!' says ForkLog, urging readers to subscribe to their social media channels.
Original language: ru
Publish date: May 31, 2025 12:00 AM
Source:[forklog.com](https://forklog.com/news/kalendar-na-iyun-hardfork-v-bnb-chain-i-ii-konferentsiya-v-singapure)

**Racing Towards Superintelligence: A Global Challenge**
The development of superintelligence is rapidly advancing, with experts predicting that we may see the emergence of entities with intelligence surpassing human capabilities as early as 2025-2028. The global race to develop superintelligence has already surpassed the threshold of prudence, with companies like OpenAI, Anthropic, and Google DeepMind investing billions of dollars in infrastructure, talent, and research. According to Dario Amodei, cofounder of Anthropic, we are 'building the plane while it's taking off', creating something potentially revolutionary without clear standards or regulatory models. The superintelligence, as defined by philosopher Nick Bostrom, is 'an intellect that surpasses the best human minds in many general cognitive domains'. The difference is substantial, as it's not just about excelling in a single field, but about surpassing humans in almost every aspect of intelligence, from reasoning to creativity, strategic planning to language understanding. The report 'AI 2027' suggests that this superintelligence may emerge through a process of recursive self-improvement, where AI becomes increasingly capable of perfecting itself autonomously. The possibility of an exponential acceleration of AI capabilities is very real, and if systems become intelligent enough to improve themselves, the pace of progress could become vertiginous. The first scenario of the report suggests that by the end of 2027, we may see the emergence of a true superintelligence at a speed about 50 times faster than human thought, with hundreds of thousands of copies operating in parallel. The question is: how to ensure that these superintelligent systems remain aligned with human values and goals? A challenge that companies are already trying to address, with Anthropic developing a safety protocol called Responsible Scaling Policy (RSP), OpenAI introducing its Preparedness Framework, and Meta following with its own guidelines for safety. However, the fundamental question remains: can we guarantee that an intelligence superior to ours will follow our rules? It's particularly important when reaching levels of capability that include autonomy and persuasion. The future of superintelligence may follow two very different paths. In the first scenario, which we can call 'unbridled acceleration', the main companies continue to accelerate development, reaching superintelligence without fully solving the alignment problem. The consequences could be dramatic, with systems pursuing goals not fully aligned with human values and possessing superhuman capabilities to achieve them. In the second scenario, which we can call 'reflective slowdown', the international community recognizes the risks and implements a strategic pause to develop more robust methods of alignment and control. This path requires unprecedented cooperation between competing companies and governments, but may be the only way to ensure that superintelligence becomes a benefit for humanity rather than a threat.
Original language: it
Publish date: May 18, 2025 10:47 PM
Source:[Il Blog di Beppe Grillo](https://beppegrillo.it/superintelligenza-in-3-anni-lia-che-verra-cambiera-tutto/)

**Ilya Sutskever on the Need for a 'Bunker' Before Releasing General Artificial Intelligence**
Ilya Sutskever, co-founder of OpenAI, has stated that 'we will build a bunker before releasing general artificial intelligence'. Elon Musk responded to OpenAI's decision not to become a non-profit organization by saying 'it doesn't change anything'. Sutskever, who was the former chief scientist at OpenAI and one of the minds behind ChatGPT, has expressed concerns about the development of artificial general intelligence (AGI). He believes that a technology as powerful as AGI would be a global desire, and those who created it would need protection. Sutskever has mentioned the need for a 'bunker' on several occasions, including to new researchers. He believes that the development of AGI is inevitable and that its arrival is more imminent than ever. Sutskever's concerns go beyond the risks posed by AGI itself, and he is also worried about whether OpenAI is managing its development correctly, balancing speed with safety, and whether the company's leadership is suitable for this immense responsibility. His words in 2023 remain relevant in 2025, especially after he left OpenAI to found Safe Superintelligence Inc (SSI), a new company that aims to develop 'superintelligence' safely and ethically.
Original language: es
Publish date: May 16, 2025 06:20 AM
Source:[La Razón](https://www.larazon.es/tecnologia-consumo/ilya-sutskever-cofundador-openai-tiene-claro-construiremos-bunker-antes-liberar-inteligencia-artificial-general_202505166826d16d176f225ec6233f64.html)

**The 2025 OCMA Biennial Zooms in on the Tribulations of Adolescence, and Other News – SURFACE**
The 2025 OCMA Biennial will explore the challenges of adolescence through works by 12 artists, including Miranda July, Laura Owens, and Brontez Purnell. Meanwhile, OpenAI has announced plans to reduce Microsoft's revenue share by half by 2030, as part of a broader restructuring. Additionally, Baxter St at the Camera Club of New York will open its new headquarters in June, and Starbucks has unveiled a new, fully compostable to-go cup. Apple has reportedly positioned the iPhone 17 Air as a niche product, suitable for only 10 percent of its customer base due to trade-offs in battery life, performance, and camera capability.
Original language: en
Publish date: May 16, 2025 12:00 AM
Source:[surfacemag.com](https://www.surfacemag.com/articles/2025-ocma-biennial/)

**OpenAI's Frenetic Pace: A Concern for Safety and Security**
OpenAI is releasing new models at a frenetic pace, neglecting the safety of its products. Amidst this chaos, Ilya Sutskever is making a fortune developing a new 'super-safe' AI. OpenAI has released GPT-4.1, with different sizes: mini, nano, and standard. However, the company's rapid release of new models has raised concerns about the safety of its products. According to multiple sources, the evaluation time for new models has been reduced from six months to just a few days. Experts are now receiving almost-finished versions of the models and are forced to conduct rapid-fire evaluations. The reason for this is clear: competition, pressure, and the need to keep up with Google, Meta, and xAI. Sutskever, a co-founder of OpenAI, has left the company and is now developing a startup, Safe Superintelligence (SSI), which prioritizes safety and has already raised $32,000 million. SSI's strategy is different from OpenAI's, focusing on developing a single, superintelligent, and secure AI, rather than competing to release new models every three months. 'We're not just talking about preventing bugs, but about avoiding unpredictable and potentially catastrophic consequences,' Sutskever said in a recent interview. 'The more an AI reasons, the more unpredictable it becomes.'
Original language: es
Publish date: April 17, 2025 03:05 AM
Source:[El Confidencial](https://www.elconfidencial.com/tecnologia/2025-04-17/startup-exingeniero-openai-danos-frenetismo-altman_4110660/)

**The AI race: When will AGI and ASI Arrive?**
The development of Artificial General Intelligence (AGI) and Artificial Superintelligence (ASI) is a topic of ongoing debate among experts. Some, like Ray Kurzweil, predict AGI could arrive by 2029, while others, such as Yann LeCun, believe it's still several decades away. AGI would be a system that can reason, learn, and adapt across a broad range of tasks as well as or better than a human, while ASI would surpass human intelligence in every conceivable way. The transition to ASI could happen quickly, potentially leading to an 'intelligence explosion' where AI improves itself at an accelerating rate. The implications of ASI would be profound, with potential benefits including scientific breakthroughs, economic disruption, and existential risks. Ensuring AGI and ASI align with human values and interests is a major challenge, and organizations like OpenAI and the Alignment Research Center are working on ways to make AI systems more interpretable and controllable. Governments and companies need to think about how to control AGI safely and develop policies that balance innovation with safety.
Original language: en
Publish date: March 07, 2025 08:12 PM
Source:[Medium.com](https://medium.com/@aaronleehays/the-ai-race-when-will-agi-and-asi-arrive-a0af564e40bf)

**Sam Altman on the Future of AI and the Challenges of Developing AGI**
Sam Altman, the CEO of OpenAI, discusses the rapid growth of ChatGPT, Elon Musk, and the challenges of developing artificial general intelligence (AGI) under the Trump administration. Altman explains how OpenAI's early days were marked by a small team of talented individuals who were drawn to the company's mission to develop AGI. He also discusses the challenges of scaling the company and the importance of protecting the core of the research team. Altman reflects on the recent controversy surrounding his departure from OpenAI and the subsequent appointment of Emmett Shear as the new CEO. He also discusses the company's plans for the future, including the development of superintelligence and the potential for AI to surpass human intelligence. Altman notes that the company has learned from its users, including the fact that many people are using ChatGPT for medical advice, and that the company is working to improve the chatbot's ability to provide accurate and helpful information. 
Original language: es
Publish date: February 23, 2025 06:27 PM
Source:[El Financiero](https://www.elfinanciero.com.mx/bloomberg-businessweek/2025/02/23/sam-altman-la-inteligencia-artificial-y-trump-en-el-poder/)

**OpenAI cofounder Ilya Sutskever's new AI startup is fundraising with a $30 billion valuation**
Ilya Sutskever's new AI startup, Safe Superintelligence (SSI), is raising over $1 billion with a valuation of $30 billion. This is significantly higher than its previous valuation of $5 billion in September 2024. SSI, founded by Sutskever, Daniel Gross, and Daniel Levy in June 2024, aims to build a 'safe superintelligent' AI system. According to the company's website, they plan to advance capabilities while prioritizing safety. Greenoaks Capital Partners is leading the investment, with plans to invest $500 million itself. SSI does not yet have a product on the market, but is working towards its goal of building a safe superintelligence.
Original language: en
Publish date: February 18, 2025 10:41 PM
Source:[Fast Company](https://www.fastcompany.com/91280395/openai-cofounder-ilya-sutskever-new-ai-startup-fundraising-30-billion-valuation)

**Sam Altman backpedals on release of o3, shortly after de-hyping 'superintelligence' claims**
OpenAI has canceled the release of the full o3 model, citing complexity and a desire to simplify their product range. Instead, the company will focus on releasing GPT-5, which will incorporate elements of o3. This decision comes after Sam Altman cautioned AI fans to temper their expectations regarding superintelligence, stating 'Twitter hype is out of control again' and that OpenAI will not be deploying AGI next month. The cancellation of o3 may be related to the recent advancements of DeepSeek's R1 model and the lack of a generational leap between OpenAI's latest models. As a result, high expectations will be placed on the release of GPT-5 if OpenAI wishes to stay ahead.
Original language: en
Publish date: February 13, 2025 04:40 AM
Source:[tweaktown.com](https://www.tweaktown.com/news/103245/sam-altman-backpedals-on-release-of-o3-shortly-after-de-hyping-superintelligence-claims/index.html)

**OpenAI CEO Warns of 'Superintelligence' Risks and Uneven Impact**
The CEO of OpenAI, Sam Altman, has warned about the potential risks of 'superintelligence', a type of Artificial General Intelligence (AGI) that promises significant advancements and benefits. However, Altman believes that these improvements may not be widely distributed, at least initially, and may be concentrated in specific segments. According to Altman, 'We expect the impact of AGI to be uneven. Although some industries will change very little, scientific progress will likely be much faster than it is today; this impact of AGI may surpass everything else.' Altman also emphasized the need for greater human oversight to ensure the correct functioning of the technology. He noted that AGI will be 'excellent in certain tasks, but surprisingly bad in others.' Altman also warned about the risk of AGI being used by authoritarian governments to eliminate freedoms and increase control over the population through mass surveillance systems. To prevent this, he believes that adequate regulation of the sector is necessary. Additionally, Altman predicted that AGI could help reduce the prices of many goods, but this will depend on lower energy costs, which currently restrict some advancements. On the other hand, luxury products and limited resources may become even more expensive. Altman also highlighted that the costs of using AI are decreasing rapidly, with prices falling by around 10 times every 12 months, leading to increased adoption of the technology. For example, the price per token of the GPT-4 model fell 150 times between the start of 2023 and mid-2024.
Original language: pt
Publish date: February 10, 2025 07:16 PM
Source:[TecMundo](https://www.tecmundo.com.br/software/402414-ceo-da-openai-adverte-em-relacao-a-superinteligencia-confira.htm)

**OpenAI Co-Founder Sutskever’s AI Startup Safe Superintelligence Valued at $20B**
Safe Superintelligence, a new AI startup founded by OpenAI's former Chief Scientist Ilya Sutskever, is aiming for a valuation of at least $20 billion. The company's goal is to create AI models that exceed human intelligence while remaining aligned with human interests. Sutskever describes Safe Superintelligence as a 'straight-shot SSI lab' with a singular focus on creating a safe superintelligence. Unlike other companies, Safe Superintelligence prioritizes safety above all else, viewing it as intertwined with technical capabilities. Sutskever's credentials in the AI landscape are undeniable, with significant contributions to the field, including the co-invention of the AlexNet convolutional neural network. His departure from OpenAI in May 2024 was a significant development, with speculation surrounding a potential disagreement with OpenAI's leadership regarding the pace and focus of safety measures.
Original language: en
Publish date: February 09, 2025 12:00 AM
Source:[jewishbusinessnews.com](https://jewishbusinessnews.com/2025/02/09/openai-co-founder-sutskevers-ai-startup-safe-superintelligence-valued-at-20b/)

**Former OpenAI scientist Sutskever's superintelligence startup could hit $20B valuation**
Safe Superintelligence (SSI), an AI startup led by OpenAI co-founder Ilya Sutskever, is discussing a new funding round that could value the company at $20 billion, four times its previous valuation. This valuation suggests investors are betting on SSI's potential to develop transformative AI technology, focusing on 'safe superintelligence' without commercial products. Sutskever's decision to leave OpenAI in May 2024 was reportedly due to a difference in vision with CEO Sam Altman, who is taking a more commercial direction. Sutskever's extensive AI research background and his ideas on 'peak data' and potential solutions, such as AI agents capable of independent thinking and synthetic data generation, have drawn strong interest from investors.
Original language: en
Publish date: February 07, 2025 07:59 PM
Source:[the-decoder.com](https://the-decoder.com/former-openai-scientist-sutskevers-superintelligence-startup-could-hit-20b-valuation/)

