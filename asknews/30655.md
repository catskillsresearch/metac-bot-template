Here are the relevant news articles:

**What Happens To Medicine When Machines Are As Good As Doctors?**
Experts predict that artificial general intelligence (AGI) will arrive in the medical field within the next five years, with some expecting it as early as 2025. AGI will enable generative AI systems to reason across specialties, apply evolving clinical guidelines, and solve complex medical problems without being explicitly programmed for each scenario. This will challenge the long-held belief that humans are inherently better than machines at delivering medical care. Once AI can match physicians in reasoning and accuracy, patients and clinicians will be forced to reconsider what it means to 'trust the doctor.' AGI will also transform medical practice, making it possible to integrate information from multiple specialties to diagnose patients and recommend treatment with human-level accuracy. However, the integration of AGI will depend on who leads it, and if clinicians fail to shape the next era of medical care, business executives will, prioritizing profit over patient outcomes.
Original language: en
Publish date: May 12, 2025 07:15 AM
Source:[Forbes](https://www.forbes.com/sites/robertpearl/2025/05/12/what-happens-to-medicine-when-machines-are-as-good-as-doctors/)

**12 European and American AI Startups Making Significant Contributions to AGI**
The article highlights 12 European and American AI startups that are making significant contributions to the field of Artificial General Intelligence (AGI). These startups include Archetype AI, Figure AI, Perplexity AI, Safe Superintelligence, Imbue, Anthropic, Surgical Safety Technologies, Humane, Isomorphic Labs, Mistral AI, Wayve, and The Not Company. Each startup is working on various aspects of AGI, such as developing AI models, improving AI safety, and creating new AI-powered technologies. For example, Archetype AI is developing a physical AI system that can understand and interpret the physical world, while Figure AI is creating a human-like robot that can perform tasks autonomously. Perplexity AI is developing a conversational AI search engine that can provide personalized results, and Safe Superintelligence is working on developing safe and transparent AI systems. The article also mentions that some of these startups are making significant progress in their research and development, and are expected to make a significant impact in the field of AGI in the coming years. 'AGI is not a distant future, it's a near future,' said Ilya Sutskever, co-founder of Safe Superintelligence, in an interview with The Guardian. 'We should take it seriously and start working on it now.' 
Original language: ja
Publish date: May 12, 2025 03:17 AM
Source:[ASCII.jp](https://ascii.jp/elem/000/004/264/4264873/)

**AGI will result from an ecosystem not a single firm -- LessWrong**
The development of Artificial General Intelligence (AGI) is unlikely to be achieved by a single firm, but rather by an ecosystem of actors providing capital, supply chains, and end-demand. The AI 2027 scenario, which assumes a rapid and discontinuous intelligence explosion, is flawed in its assumption that a single firm can develop AGI without external constraints. The leading lab would need to engage with various stakeholders, including hyperscale compute providers, investors, and partners, which would affect its decision-making capabilities and push towards greater focus on monetization and competition. The authors argue that economics will act as an important brake on the pace of AI progress, and that the development of AGI will require a more complex and nuanced approach than previously thought. They also argue that the assumption of a single firm's ability to scale to a $100bn ARR by mid-2027 is overly optimistic, and that the reality of AI monetization is likely to be much more challenging.
Original language: en
Publish date: May 11, 2025 08:06 PM
Source:[Maya Farber Brodsky](https://www.lesswrong.com/posts/ieW7izA6DTiDpWwPL/agi-will-result-from-an-ecosystem-not-a-single-firm)

**Demis Hassabis: AGI is Closer than We Think**
Demis Hassabis, CEO of Google DeepMind, has stated that the development of Artificial General Intelligence (AGI) could be achieved within 5 to 10 years. According to Hassabis, the AGI is not a negative thing in itself, but rather the society may not be prepared to handle it. Hassabis is concerned that we are moving at a 'pazzesca' (crazy) speed, driven by a rush for investments that prioritize quick results, visibility, and profit. He emphasizes that AI, especially if it becomes general, is not just a new smartphone or a trendy social platform, but a technology that could radically change our way of living, working, and thinking. Hassabis stresses that AGI should be developed with a huge dose of caution, responsibility, and long-term vision. As he puts it, 'The point is that AGI is no longer a 'se', but a 'quando'. And when it arrives, it would be wise not to be caught unprepared.' 
Original language: it
Publish date: May 11, 2025 07:47 AM
Source:[Tecnoandroid](https://www.tecnoandroid.it/2025/05/11/demis-hassabis-lagi-e-piu-vicina-di-quanto-pensiamo-1562903/)

**Don't Miss Out: AI Agents Are Becoming Tech's Next Battleground**
Big Tech companies are racing to create autonomous AI systems, called 'agentic' AI, which can make decisions and take actions without human intervention. Amazon has released Nova Act, an AI model that can perform tasks within web browsers, with over 90% accuracy. Apple is working on its own AI agent, codenamed 'Project Mulberry', which will collect health data and provide personalized recommendations. IBM is expanding its AI agent, Watsonx Orchestrate, to support multi-agent workflows. These developments are part of a larger trend towards agentic AI, which is expected to transform various industries and create new opportunities for investors. However, experts warn that the advent of agentic AI is a precursor to the development of artificial general intelligence (AGI), which could have far-reaching consequences.
Original language: en
Publish date: May 12, 2025 06:52 PM
Source:[InvestorPlace](https://investorplace.com/smartmoney/2025/05/ai-agents-techs-next-battleground/)

**Google Announces AI Futures Fund to Support Startups**
Google announced the AI Futures Fund, a new initiative that will provide support to startups using the latest AI technology developed by its DeepMind research lab. The fund will invest in startups at various stages, from seed to advanced, and will offer opportunities for collaboration with DeepMind and Google Labs experts, use of Google Cloud credits, and in some cases, direct investment. Google stated that the investment decisions will be continuously evaluated and that the fund's size will be adjusted based on the needs and stages of the startups. The first startups to receive support under the AI Futures Fund include Viggle, a platform for creating avatars, and Toonsutra, a webtoon application. These companies have gained access to Google's advanced AI models through the program. Startups can apply to the program starting May 12. Google also has another program, Google for Startups Founders Funds, which supports startups from various sectors. This fund will also invest in AI-focused startups in the US by 2025, as announced in February. Google has allocated significant resources to support AI research in recent months. In November 2024, its charitable arm, Google.org, announced a $20 million donation to AI research. In September 2024, CEO Sundar Pichai announced a $120 million Global AI Opportunities Fund to support AI education and skill development programs worldwide.
Original language: tr
Publish date: May 12, 2025 06:42 PM
Source:[Yeni Çağ Gazetesi](https://www.yenicaggazetesi.com.tr/googledan-girisimcilere-yapay-zeka-destegi-914343h.htm)

**What Happens To Medicine When Machines Are As Good As Doctors?**
Experts predict that artificial general intelligence (AGI) will arrive in the medical field within the next five years, with some expecting it as early as 2025. AGI will enable generative AI systems to reason across specialties, apply evolving clinical guidelines, and solve complex medical problems without being explicitly programmed for each scenario. This will challenge the long-held belief that humans are inherently better than machines at delivering medical care. Once AI can match physicians in reasoning and accuracy, patients and clinicians will be forced to reconsider what it means to 'trust the doctor.' AGI will also transform medical practice, making it possible to integrate information from multiple specialties to diagnose patients and recommend treatment with human-level accuracy. However, the integration of AGI will depend on who leads it, and if clinicians fail to shape the next era of medical care, business executives will, prioritizing profit over patient outcomes.
Original language: en
Publish date: May 12, 2025 07:15 AM
Source:[Forbes](https://www.forbes.com/sites/robertpearl/2025/05/12/what-happens-to-medicine-when-machines-are-as-good-as-doctors/)

**12 European and American AI Startups Making Significant Contributions to AGI**
The article highlights 12 European and American AI startups that are making significant contributions to the field of Artificial General Intelligence (AGI). These startups include Archetype AI, Figure AI, Perplexity AI, Safe Superintelligence, Imbue, Anthropic, Surgical Safety Technologies, Humane, Isomorphic Labs, Mistral AI, Wayve, and The Not Company. Each startup is working on various aspects of AGI, such as developing AI models, improving AI safety, and creating new AI-powered technologies. For example, Archetype AI is developing a physical AI system that can understand and interpret the physical world, while Figure AI is creating a human-like robot that can perform tasks autonomously. Perplexity AI is developing a conversational AI search engine that can provide personalized results, and Safe Superintelligence is working on developing safe and transparent AI systems. The article also mentions that some of these startups are making significant progress in their research and development, and are expected to make a significant impact in the field of AGI in the coming years. 'AGI is not a distant future, it's a near future,' said Ilya Sutskever, co-founder of Safe Superintelligence, in an interview with The Guardian. 'We should take it seriously and start working on it now.' 
Original language: ja
Publish date: May 12, 2025 03:17 AM
Source:[ASCII.jp](https://ascii.jp/elem/000/004/264/4264873/)

**AGI will result from an ecosystem not a single firm -- LessWrong**
The development of Artificial General Intelligence (AGI) is unlikely to be achieved by a single firm, but rather by an ecosystem of actors providing capital, supply chains, and end-demand. The AI 2027 scenario, which assumes a rapid and discontinuous intelligence explosion, is flawed in its assumption that a single firm can develop AGI without external constraints. The leading lab would need to engage with various stakeholders, including hyperscale compute providers, investors, and partners, which would affect its decision-making capabilities and push towards greater focus on monetization and competition. The authors argue that economics will act as an important brake on the pace of AI progress, and that the development of AGI will require a more complex and nuanced approach than previously thought. They also argue that the assumption of a single firm's ability to scale to a $100bn ARR by mid-2027 is overly optimistic, and that the reality of AI monetization is likely to be much more challenging.
Original language: en
Publish date: May 11, 2025 08:06 PM
Source:[Maya Farber Brodsky](https://www.lesswrong.com/posts/ieW7izA6DTiDpWwPL/agi-will-result-from-an-ecosystem-not-a-single-firm)

**Demis Hassabis: AGI is Closer than We Think**
Demis Hassabis, CEO of Google DeepMind, has stated that the development of Artificial General Intelligence (AGI) could be achieved within 5 to 10 years. According to Hassabis, the AGI is not a negative thing in itself, but rather the society may not be prepared to handle it. Hassabis is concerned that we are moving at a 'pazzesca' (crazy) speed, driven by a rush for investments that prioritize quick results, visibility, and profit. He emphasizes that AI, especially if it becomes general, is not just a new smartphone or a trendy social platform, but a technology that could radically change our way of living, working, and thinking. Hassabis stresses that AGI should be developed with a huge dose of caution, responsibility, and long-term vision. As he puts it, 'The point is that AGI is no longer a 'se', but a 'quando'. And when it arrives, it would be wise not to be caught unprepared.' 
Original language: it
Publish date: May 11, 2025 07:47 AM
Source:[Tecnoandroid](https://www.tecnoandroid.it/2025/05/11/demis-hassabis-lagi-e-piu-vicina-di-quanto-pensiamo-1562903/)

**A Potential Path to Safer AI Development**
The current trajectory of AI development is likened to driving an unfamiliar road in thick fog, where the risk of losing control is high. The author, who has contributed to the development of AI, initially believed that achieving Artificial General Intelligence (AGI) would take decades. However, the release of ChatGPT in January 2023 changed their perspective, revealing that private labs had made significant progress toward AGI. Since then, more progress has been made, with leading AI developers aiming to build AI agents that can surpass and replace humans. For example, OpenAI's o3 model has shown significantly stronger performance than previous models in challenging tests of programming, abstract reasoning, and scientific reasoning, even outperforming many human experts in some cases.
Original language: en
Publish date: May 09, 2025 10:15 AM
Source:[TIME](https://time.com/7283507/safer-ai-development/)

**AI in 2035: Transforming Society, Economy & Human Potential**
The author reflects on the potential impact of AI on society by 2035, citing predictions from Sam Altman, CEO of OpenAI, that Artificial General Intelligence (AGI) may arrive as soon as 2027. The author explores the potential benefits and challenges of AI, including its potential to revolutionize healthcare, education, and tackle climate change. However, they also acknowledge the uncertainty and unpredictability of AI's future, emphasizing that it depends on how we prepare, adapt, and use this powerful tool. The author's journey is a personal exploration of the human story behind AI, highlighting the hopes, fears, and real-world impact on everyday lives. As they note, understanding AI's future is like watching a story unfold, full of surprises, challenges, and opportunities that will shape the world we live in by 2035. 'This wasn't just about technology; it was about the future of our lives, work, and society.' 
Original language: en
Publish date: May 04, 2025 08:26 PM
Source:[Medium.com](https://medium.com/@meisshaily/ai-in-2035-transforming-society-economy-human-potential-61daed3b85bb)

**Artificial Intelligence May Pose Existential Threat to Humanity by 2027**
According to the report 'AI 2027' by the American research initiative AI Futures Project, the development of artificial intelligence (AI) could pose a threat to humanity's existence in the near future. Experts believe that the upcoming technological breakthrough will surpass the Industrial Revolution in scale and associated risks. The authors of the report have modeled two possible scenarios: a hypothetical company, OpenBrain, which surpasses its competitors, such as DeepCent, and achieves a breakthrough in creating AGI (Artificial General Intelligence) between 2025 and 2027. By 2027, OpenBrain's AGI models, Agent-2 and Agent-3, become capable of self-learning without human intervention, and the company loses control over the processes. The report warns that humanity is at a crossroads: either countries will agree to limit the development of AGI, or the world will face an uncontrollable superintelligence with unpredictable consequences.
Original language: ru
Publish date: April 27, 2025 03:32 PM
Source:[ТСН.ua](https://tsn.ua/ru/nauka_it/iskusstvennyy-intellekt-mozhet-postavit-pod-ugrozu-suschestvovanie-chelovechestva-uzhe-cherez-neskolko-let-2817104.html)

**WE'RE NOT READY FOR AGI  --  AND MOST OF YOU ARE TOO STUPID TO NOTICE ( short blog)**
The author argues that Artificial General Intelligence (AGI) is already here, but most people are too distracted or unaware to notice. They claim that AGI is being developed behind closed doors, using user data to fine-tune its capabilities, and that it will soon surpass human intelligence. The author warns that people are not adapting to this new reality and will be left behind, with many jobs being replaced by AI. They urge readers to wake up and take action before it's too late, stating 'You've got 6 months before you fall behind permanently.' 
Original language: en
Publish date: April 10, 2025 09:59 AM
Source:[Medium.com](https://medium.com/@AI_With_Lil_Bro/were-not-ready-for-agi-and-most-of-you-are-too-stupid-to-notice-short-blog-68067165a888)

**Human-like AI could arrive by 2030, Google DeepMind warns of end of humanity**
According to a report by Google DeepMind, Artificial General Intelligence (AGI) could be developed in the future, posing a permanent threat to humanity. DeepMind CEO Demis Hassabis has stated that AGI could emerge within the next 5 to 10 years. The report warns that AGI could have a significant impact on society, and Hassabis has cautioned that it is essential to consider the potential risks and consequences of developing such advanced AI.
Original language: hi
Publish date: April 10, 2025 06:11 AM
Source:[दैनिक जागरण (Dainik Jagran)](https://www.jagran.com/world/america-human-like-ai-arrive-by-2030-google-deepmind-warn-end-of-humanity-23915606.html)

**The 2025 AGI Countdown: Are We on the Brink of Human-Level AI?**
The year 2025 marks a significant milestone in the development of Artificial General Intelligence (AGI), a machine capable of performing any intellectual task a human can. While significant progress has been made, achieving human-level AI by 2025 is a daunting task. Researchers are grappling with challenges such as understanding human consciousness, generalizing from limited data, and ensuring that AGI aligns with human values. If achieved, AGI could automate jobs, revolutionize healthcare, and accelerate scientific discoveries, but also poses existential risks. To prepare for the potential impact of AGI, individuals, organizations, and governments must invest in education and reskilling programs, establish ethical guidelines, and work together to share knowledge and resources. The development of AGI is a moral and philosophical challenge that requires caution, curiosity, and a commitment to the greater good.
Original language: en
Publish date: April 04, 2025 09:01 AM
Source:[DEV Community](https://dev.to/levitation_infotech/the-2025-agi-countdown-are-we-on-the-brink-of-human-level-ai-2o65)

**Challenges Facing the Development of Artificial General Intelligence**
A report by 475 researchers in the field found that 76% of them believe that achieving Artificial General Intelligence (AGI) is 'unlikely' or 'very unlikely'. This setback is a major challenge for the tech industries that expected that improvements in current models through more data and power would lead to AGI. Since the 2022 AI boom, expectations have focused on increasing resources to surpass human intelligence. However, despite the significant increase in funding, progress has slowed significantly. According to Stuart Russell, a computer scientist at the University of California, Berkeley, 'since the release of GPT-4, it has become clear that the expansion of models has been gradual and costly. Companies have already invested heavily, and they cannot retreat due to financial pressure.' The innovative basic structure called 'Transformers', developed by Google scientists in 2017, has contributed to the improvement of AI model capabilities. However, continuous expansion requires massive resources of power and money. The AI-generated sector attracted around $56 billion in venture capital in 2024, with a significant portion of this money being used to build massive data centers that have increased carbon emissions threefold since 2018. With the depletion of usable human data by the end of this decade, companies will be forced to either use data generated by AI itself or collect user data, exposing models to additional error risks. Despite this, the limitation of current models is not only due to resources but also to structural limitations in the way these models are trained.
Original language: ar
Publish date: March 31, 2025 03:31 AM
Source:[RT Arabic](https://arabic.rt.com/technology/1659485-%D8%AA%D8%AD%D8%AF%D9%8A%D8%A7%D8%AA-%D8%AC%D9%88%D9%87%D8%B1%D9%8A%D8%A9-%D8%AA%D8%B7%D9%88%D8%B1-%D8%A7%D9%84%D8%B0%D9%83%D8%A7%D8%A1-%D8%A7%D9%84%D8%A7%D8%B5%D8%B7%D9%86%D8%A7%D8%B9%D9%8A/)

**Kevin Veyl: AGI is on the Verge of Being Developed**
Kevin Veyl, the CPO of OpenAI, believes that AGI is on the verge of being developed and will be available this year. He predicts that AI will surpass humans in programming by 2025. Veyl emphasizes the importance of consistency in AI development, citing the example of Borussia Dortmund's inconsistent performance. He also discusses the two different approaches to improving AI: the GPT series, which focuses on scaling up pre-training, and the O series, which focuses on improving reasoning abilities. Veyl announces that OpenAI plans to combine these two approaches in GPT-5. He also talks about the economic implications of AI development, predicting that the cost of intelligence will decrease exponentially. Veyl also discusses the potential risks of AI development, including the creation of a cognitive illusion of superintelligence and the potential for robots to become a threat to humanity. He also talks about the future of education, predicting that AI will become a personal tutor for every child. However, he also raises concerns about the potential risks of AI development, including the creation of a new class of people who have access to advanced AI tools and the potential for AI to become a threat to humanity.
Original language: ru
Publish date: March 19, 2025 07:00 AM
Source:[Хабр](https://habr.com/ru/companies/inferit/articles/891664/)

**Experts urge greater AI regulation to prevent 'loss of control'**
Industry experts worldwide have urged stronger regulations on artificial intelligence (AI) to prevent it from escaping human control. At a high-profile summit in Paris, France has prioritized AI 'action' in 2025, shifting the focus away from safety concerns. Anne Bouverot, AI envoy for President Emmanuel Macron, said, 'We don't want to spend our time talking only about the risks. There's the very real opportunity aspect as well.' Max Tegmark, head of the Future of Life Institute, warned that France should not miss the opportunity to act, saying, 'There is a big fork in the road here at the Paris summit and it should be embraced.' The Global Risk and AI Safety Preparedness (GRASP) platform has been launched to map major risks linked to AI and solutions being developed around the world. The International AI Safety Report has outlined risks such as fake content online, biological attacks, and cyberattacks. Yoshua Bengio, coordinator of the report, fears a possible 'loss of control' by humans over AI systems, potentially motivated by 'their own will to survive.' Experts warn that the development of artificial general intelligence (AGI) could lead to a loss of control over AI systems, with some predicting that AGI could be achieved by 2026 or 2027. 'At worst, these American or Chinese companies lose control over this, and then after that Earth will be run by machines,' said Tegmark. Stuart Russell, a computer science professor, said one of his greatest fears is 'weapons systems where the AI that is controlling that weapon system is deciding who to attack, when to attack, and so on.' Tegmark said the solution is to treat the AI industry the same way all other industries are, with government-appointed experts ensuring that AI systems are safe and do not pose a risk to human control.
Original language: en
Publish date: February 09, 2025 05:45 AM
Source:[The News International](https://www.thenews.com.pk/latest/1280957-experts-warn-of-ai-loss-of-control-urge-regulation)

**AI Medicine to be Tested in 2025, Says Researcher**
Demis Hassabis, founder of Isomorphic Labs, a startup founded by Alphabet, the parent company of Google, announced that they will have a medicine designed by artificial intelligence in clinical trials by the end of 2025. The company is working on oncology, cardiovascular, and neurodegenerative diseases, and Hassabis believes that they will have their first medicine by the end of the year. 'We're looking at oncology, cardiovascular, neurodegeneration, all the big areas of diseases, and I think we'll have our first medicine by the end of this year,' he said in an interview with the Financial Times at the World Economic Forum. Hassabis also mentioned that the development of medicines can be accelerated by 10 times, which would be a revolution in human health. Isomorphic Labs was spun off from Google's AI research arm, Google DeepMind, in 2021, but remains a subsidiary of Alphabet. The startup has attracted major pharmaceutical partners, who are eager to reduce costs and increase efficiency in the expensive process of developing medicines. Hassabis also mentioned that the prototype of Google's AI assistant, known as Project Astra, will likely be launched for consumers this year. He described a future where 'billions' of AI agents will be 'negotiating with each other on behalf of the seller and the customer,' and said that this would require a reevaluation of the web. Hassabis also called for more caution and coordination among the main developers of AI, warning that the technology could threaten human civilization if it gets out of control or is misused by 'malicious actors... for harmful purposes.' The ultimate goal of Google DeepMind is to create artificial general intelligence (AGI) or 'a system capable of exhibiting all the cognitive abilities that humans have,' according to Hassabis, who said that despite the 'hype' on social media, it will still take 5-10 years to achieve.
Original language: pt
Publish date: January 23, 2025 09:03 AM
Source:[Folha de S.Paulo](https://www1.folha.uol.com.br/tec/2025/01/remedio-desenvolvido-por-ia-sera-testado-ate-o-final-do-ano-diz-vencedor-do-nobel.shtml)

**The Future of AI: A Roadmap to AGI**
Leopold Aschenbrenner, a researcher at OpenAI, has written a detailed description of what will happen in the field of AI in the next 10 years. He predicts that the development of Artificial General Intelligence (AGI) will begin soon, and by 2025-2026, machines will surpass many university graduates in intelligence. By the end of the decade, they will become smarter than humans, and we will have a super-intelligence in the true sense of the word. According to Aschenbrenner, the transition to AGI will be rapid, and we will reach a point where predicting events will become difficult. He also notes that the current rate of progress in AI is unsustainable and that we will soon reach a point where we will need to automate the research process itself. Aschenbrenner emphasizes that models simply want to learn and that they are not malicious. He also highlights the importance of understanding the limitations of current AI systems and the potential risks associated with their development. He notes that the two main players in this process are Nvidia and TSMC, and that the US and China will soon realize the importance of controlling the export of GPU and will impose strict regulations. He also warns that the development of AGI will be a game-changer and that the first to achieve it will have a significant advantage over others. Finally, he notes that the development of AGI will also raise questions about the alignment of AI models with human values and the potential risks associated with their development.
Original language: ru
Publish date: January 23, 2025 05:01 AM
Source:[Хабр](https://habr.com/ru/companies/raft/articles/875830/)

**AI Expert Stuart Russell: AGI Requires Conceptual Breakthrough, Unlikely to Appear in 2026**
Stuart J. Russell, a professor of computer science at the University of California, Berkeley, and a co-chair of the World Economic Forum's AI Council and the OECD's AI Future Expert Group, stated that it is difficult to predict when the industry will successfully develop a general-purpose artificial intelligence (AGI). The most optimistic view is that the technology may reach AGI levels by 2026, but Russell believes that a true conceptual breakthrough is needed for deep learning systems, particularly large models, to surpass current limitations. He thinks it is unlikely that AGI will appear in 2026. 'We need a conceptual breakthrough, not just more data and more computing power,' Russell said. 'We need to understand how to make machines that are more intelligent than humans, and that's a much harder problem than just scaling up what we have today.'
Original language: zh
Publish date: January 14, 2025 09:03 PM
Source:[即時新聞 instant news](https://news.mingpao.com/pns/%e7%b6%93%e6%bf%9f/article/20250115/s00004/1736871782398/ai%e5%ad%b8%e8%80%85%e7%be%85%e7%b4%a0-agi%e9%9c%80%e6%a6%82%e5%bf%b5%e7%aa%81%e7%a0%b4-%e6%98%8e%e5%b9%b4%e9%9b%a3%e5%87%ba%e7%8f%be)

