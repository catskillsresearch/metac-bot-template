Here are the relevant news articles:

**Anthropic CEO Believes AI 'Hallucinations' are Less Frequent than Human Errors**
Dario Amodei, CEO of Anthropic, believes that AI models 'hallucinate' less than humans, even if they do so in more surprising ways. According to Amodei, the errors made by AI, known as 'hallucinations', occur less frequently than in humans and do not represent an obstacle to the advancement towards general artificial intelligence (AGI). Amodei compared these errors to those made by journalists and politicians, saying that they do not invalidate the intelligence of AI models. He also expressed optimism about the possibility of AI advancing to a form with intelligence similar or superior to humans, with AGI, and believes that progress is being made towards this goal. However, other leading AI companies, such as Google DeepMind, believe that 'hallucinations' are a significant obstacle to AGI. There is evidence that suggests an increase in 'hallucinations' in some AI models, such as the o3 and o4-mini models from OpenAI, which have regressed in terms of improvement in this area.
Original language: pt
Publish date: May 23, 2025 12:40 PM
Source:[Exame](https://exame.com/inteligencia-artificial/ceo-da-anthropic-diz-que-ia-alucina-menos-que-humanos-e-defende-avanco-rumo-a-agi/)

**OpenAI scientists wanted "a doomsday bunker" before AGI surpasses human intelligence and threatens humanity**
OpenAI's chief scientist, Ilya Sutskever, has expressed concerns about the potential threat of artificial general intelligence (AGI) surpassing human cognitive capabilities and becoming smarter. As a precaution, Sutskever suggested building 'a doomsday bunker' where researchers could seek cover in case of an unprecedented rapture following the release of AGI. According to Sutskever, 'We're definitely going to build a bunker before we release AGI.' This concern is shared by other AI researchers, including Safe Superintelligence Inc. founder Ilya Sutskever, who was involved in the development of ChatGPT and other AI-powered products. The potential threat of AGI has also been raised by DeepMind CEO Demis Hassabis and Anthropic CEO Dario Amodei, who admitted that the company doesn't know how its models work and that society should be concerned about the lack of understanding and its potential threats.
Original language: en
Publish date: May 23, 2025 10:23 AM
Source:[Windows Central](https://www.windowscentral.com/software-apps/openai-scientists-wanted-a-doomsday-bunker-before-agi)

**Google Challenges OpenAI with AGI Timeline: A Debate with Demis Hassabis**
Google's co-founder Sergey Brin has announced the company's intention to develop the first general artificial intelligence (AGI) by 2030, sparking a debate with DeepMind's CEO Demis Hassabis. Hassabis emphasized the need for 'scientific accuracy' and caution, highlighting the current lack of coordination in AI systems. Brin called AGI a 'inevitable milestone' and a competitive goal, while Hassabis noted that true AGI should demonstrate abilities comparable to Einstein or Marie Curie, including adaptability and creativity. The difference in estimated timelines - 'by 2030' (Brin) vs. 'a bit after 2030' (Hassabis) - reflects the contrast between Google's strategy of speed and DeepMind's emphasis on scientific rigor. Google announced a feature that allows AI models to perform parallel reasoning processes with mutual verification, and Brin stated that future breakthroughs in AI will depend on algorithms, not just computational power. Hassabis added that multimodality and working with visual data are critical for AGI, which aligns with Google's focus on computer vision and smart glasses. In robotics, Hassabis highlighted the 'software component' as the main obstacle, rather than hardware. The company also strengthened security measures by introducing SynthID technology for invisible content marking created by AI. When asked about the dominance of one company in AGI, Hassabis suggested that early systems could be used to develop more secure architectures. Brin's statement, made after his return to operational management, is an open challenge to OpenAI, which was previously considered the leader in the AGI race. Google's strategy, combining DeepMind's scientific research and Brin's ambitions, may shape the trajectory of the industry.
Original language: ru
Publish date: May 22, 2025 07:27 PM
Source:[iXBT.com](https://www.ixbt.com/news/2025/05/22/google-deepmind-agi.html)

**Neurodigest: Key AI Events of May 12-19, 2025**
This week's Neurodigest brings you the latest news in AI. OpenAI has released Codex, a new agent that can write code, find bugs, explain logic, run tests, and even send pull requests. Codex is integrated into ChatGPT and is available for Pro, Team, and Enterprise users. A simplified version, codex-mini-latest, is also available through the API for $1.50/$6.00 per million tokens. OpenAI has also added GPT-4.1 to ChatGPT for Pro users and GPT-4.1 mini for free users, which improves accuracy and stability in complex tasks. DeepMind has introduced AlphaEvolve, an AI agent that can develop its own algorithms, test hypotheses, and refine solutions. The agent has already helped Google optimize data centers, accelerate model training, and develop chip architectures. Anthropic is working on updated versions of its Claude models, which will be able to switch between reasoning and action modes. Alibaba has released Qwen3, a new line of open-source models that compete with top models from Google, Meta, and OpenAI. Qwen3 has a hybrid mode that allows it to 'think' deeply only when necessary, making it more efficient. Tencent has shown Hunyuan Image 2.0, a model that can generate images in real-time and interactively. Stability AI has released Stable Audio Open Small, a fully open model that can generate music locally on devices. ILĀ has created the first music composition fully generated by quantum AI, called RECURSE. TikTok has launched AI Alive, an instrument that can animate static photos into short videos with movement, emotions, and effects. Memex has introduced an instrument that allows users to create programs without writing any code. Apple is working on an AI-powered energy-saving mechanism in iOS 19, which will analyze user behavior and optimize battery life. Google is testing a new feature that automatically generates ad inserts in YouTube videos using the Gemini 1.5 Flash model. Apple is also working on integrating a neural interface from Synchron, which will allow users to control their iPhone and Mac with their thoughts.
Original language: ru
Publish date: May 22, 2025 02:15 PM
Source:[Хабр](https://habr.com/ru/companies/timeweb/articles/911130/)

**OpenAI, Google and xAI battle to hire the best minds in Artificial Intelligence**
The competition for top artificial intelligence researchers has escalated to professional athlete levels, with companies like OpenAI, Google, and xAI offering large bonuses and pay packages to attract and retain talent. According to sources, top OpenAI researchers have received retention bonuses of $2 million and equity increases of $20 million or more if they stay. Some have only been required to stay for a year to get the entire bonus. Google DeepMind has offered top researchers $20 million per year compensation packages and has reduced vesting on some stock packages to 3 years. Ariel Herbert-Voss, CEO of RunSybil, said, 'The AI labs approach hiring like a game of chess, they want to move as fast as possible, so they are willing to pay a lot for candidates with specialized and complementary expertise.' Noam Brown, one of the researchers behind OpenAI's recent AI breakthroughs, said, 'It was actually financially not the best option that I had,' but chose OpenAI because they were willing to put resources behind the work he was excited about.
Original language: en
Publish date: May 22, 2025 05:09 AM
Source:[The Financial Express](https://www.financialexpress.com/life/technology-openai-google-and-xai-battle-to-hire-the-best-minds-in-artificial-intelligence-3853202/)

**How to stop your posts, photographs and other data from being sucked into AI machines**
Many companies, including Meta, Google, and OpenAI, use user data to train their artificial intelligence models. However, EU citizens have the right to opt out of this data sharing. Meta has rolled out its AI training plan for EU users, but users can object by May 26th. Google has integrated AI into many of its products, including Android, and users can limit the data shared with Google to train its AI. OpenAI has faced lawsuits over its use of content to train its models, and users can opt out of data sharing by turning off Gemini apps activity. Anthropic's AI Claude will only use user conversations to train its models if explicitly given permission. Tumblr users can opt out of data sharing by excluding their blogs from sharing with licensed partners. X, the platform formerly known as Twitter, has its own AI called Grok, and users can opt out of data sharing by limiting Grok's access to their data. Apple has built generative AI into its operating systems, but uses high-quality public data to train its AI models and does not access user private data. Users can opt-in to use ChatGPT for queries that Apple Intelligence cannot answer.
Original language: en
Publish date: May 22, 2025 04:35 AM
Source:[The Irish Times](https://www.irishtimes.com/business/2025/05/22/how-to-stop-your-posts-photographs-and-other-data-from-being-sucked-into-ai-machines/)

**Anthropic CEO Believes AI 'Hallucinations' are Less Frequent than Human Errors**
Dario Amodei, CEO of Anthropic, believes that AI models 'hallucinate' less than humans, even if they do so in more surprising ways. According to Amodei, the errors made by AI, known as 'hallucinations', occur less frequently than in humans and do not represent an obstacle to the advancement towards general artificial intelligence (AGI). Amodei compared these errors to those made by journalists and politicians, saying that they do not invalidate the intelligence of AI models. He also expressed optimism about the possibility of AI advancing to a form with intelligence similar or superior to humans, with AGI, and believes that progress is being made towards this goal. However, other leading AI companies, such as Google DeepMind, believe that 'hallucinations' are a significant obstacle to AGI. There is evidence that suggests an increase in 'hallucinations' in some AI models, such as the o3 and o4-mini models from OpenAI, which have regressed in terms of improvement in this area.
Original language: pt
Publish date: May 23, 2025 12:40 PM
Source:[Exame](https://exame.com/inteligencia-artificial/ceo-da-anthropic-diz-que-ia-alucina-menos-que-humanos-e-defende-avanco-rumo-a-agi/)

**OpenAI scientists wanted "a doomsday bunker" before AGI surpasses human intelligence and threatens humanity**
OpenAI's chief scientist, Ilya Sutskever, has expressed concerns about the potential threat of artificial general intelligence (AGI) surpassing human cognitive capabilities and becoming smarter. As a precaution, Sutskever suggested building 'a doomsday bunker' where researchers could seek cover in case of an unprecedented rapture following the release of AGI. According to Sutskever, 'We're definitely going to build a bunker before we release AGI.' This concern is shared by other AI researchers, including Safe Superintelligence Inc. founder Ilya Sutskever, who was involved in the development of ChatGPT and other AI-powered products. The potential threat of AGI has also been raised by DeepMind CEO Demis Hassabis and Anthropic CEO Dario Amodei, who admitted that the company doesn't know how its models work and that society should be concerned about the lack of understanding and its potential threats.
Original language: en
Publish date: May 23, 2025 10:23 AM
Source:[Windows Central](https://www.windowscentral.com/software-apps/openai-scientists-wanted-a-doomsday-bunker-before-agi)

**Google Challenges OpenAI with AGI Timeline: A Debate with Demis Hassabis**
Google's co-founder Sergey Brin has announced the company's intention to develop the first general artificial intelligence (AGI) by 2030, sparking a debate with DeepMind's CEO Demis Hassabis. Hassabis emphasized the need for 'scientific accuracy' and caution, highlighting the current lack of coordination in AI systems. Brin called AGI a 'inevitable milestone' and a competitive goal, while Hassabis noted that true AGI should demonstrate abilities comparable to Einstein or Marie Curie, including adaptability and creativity. The difference in estimated timelines - 'by 2030' (Brin) vs. 'a bit after 2030' (Hassabis) - reflects the contrast between Google's strategy of speed and DeepMind's emphasis on scientific rigor. Google announced a feature that allows AI models to perform parallel reasoning processes with mutual verification, and Brin stated that future breakthroughs in AI will depend on algorithms, not just computational power. Hassabis added that multimodality and working with visual data are critical for AGI, which aligns with Google's focus on computer vision and smart glasses. In robotics, Hassabis highlighted the 'software component' as the main obstacle, rather than hardware. The company also strengthened security measures by introducing SynthID technology for invisible content marking created by AI. When asked about the dominance of one company in AGI, Hassabis suggested that early systems could be used to develop more secure architectures. Brin's statement, made after his return to operational management, is an open challenge to OpenAI, which was previously considered the leader in the AGI race. Google's strategy, combining DeepMind's scientific research and Brin's ambitions, may shape the trajectory of the industry.
Original language: ru
Publish date: May 22, 2025 07:27 PM
Source:[iXBT.com](https://www.ixbt.com/news/2025/05/22/google-deepmind-agi.html)

**Anthropic overtakes OpenAI: Claude Opus 4 codes seven hours nonstop, sets record SWE-Bench score and reshapes enterprise AI**
Anthropic has announced a breakthrough in AI technology with its Claude Opus 4 model, which has achieved a 72.5% score on the SWE-bench software engineering benchmark, outperforming OpenAI's GPT-4.1. The model demonstrated a seven-hour non-stop coding session, setting a new record for sustained performance. This achievement marks a significant shift in AI's capabilities, enabling it to tackle complex software engineering projects from conception to completion, maintaining context and focus throughout. The model's dual-mode architecture allows for near-instant responses for straightforward queries and extended thinking for complex problems, eliminating frustrating delays. Additionally, Claude Opus 4 can extract key information from documents, create summary files, and maintain this knowledge across sessions, solving the 'amnesia problem' that has limited AI's usefulness in long-running projects. The technical implications are profound, and the competitive landscape in AI is intensifying as leaders battle for market share.
Original language: en
Publish date: May 22, 2025 04:45 PM
Source:[VentureBeat](https://venturebeat.com/ai/anthropic-claude-opus-4-can-code-for-7-hours-straight-and-its-about-to-change-how-we-work-with-ai/)

**Neurodigest: Key AI Events of May 12-19, 2025**
This week's Neurodigest brings you the latest news in AI. OpenAI has released Codex, a new agent that can write code, find bugs, explain logic, run tests, and even send pull requests. Codex is integrated into ChatGPT and is available for Pro, Team, and Enterprise users. A simplified version, codex-mini-latest, is also available through the API for $1.50/$6.00 per million tokens. OpenAI has also added GPT-4.1 to ChatGPT for Pro users and GPT-4.1 mini for free users, which improves accuracy and stability in complex tasks. DeepMind has introduced AlphaEvolve, an AI agent that can develop its own algorithms, test hypotheses, and refine solutions. The agent has already helped Google optimize data centers, accelerate model training, and develop chip architectures. Anthropic is working on updated versions of its Claude models, which will be able to switch between reasoning and action modes. Alibaba has released Qwen3, a new line of open-source models that compete with top models from Google, Meta, and OpenAI. Qwen3 has a hybrid mode that allows it to 'think' deeply only when necessary, making it more efficient. Tencent has shown Hunyuan Image 2.0, a model that can generate images in real-time and interactively. Stability AI has released Stable Audio Open Small, a fully open model that can generate music locally on devices. ILĀ has created the first music composition fully generated by quantum AI, called RECURSE. TikTok has launched AI Alive, an instrument that can animate static photos into short videos with movement, emotions, and effects. Memex has introduced an instrument that allows users to create programs without writing any code. Apple is working on an AI-powered energy-saving mechanism in iOS 19, which will analyze user behavior and optimize battery life. Google is testing a new feature that automatically generates ad inserts in YouTube videos using the Gemini 1.5 Flash model. Apple is also working on integrating a neural interface from Synchron, which will allow users to control their iPhone and Mac with their thoughts.
Original language: ru
Publish date: May 22, 2025 02:15 PM
Source:[Хабр](https://habr.com/ru/companies/timeweb/articles/911130/)

**OpenAI, Google and xAI battle to hire the best minds in Artificial Intelligence**
The competition for top artificial intelligence researchers has escalated to professional athlete levels, with companies like OpenAI, Google, and xAI offering large bonuses and pay packages to attract and retain talent. According to sources, top OpenAI researchers have received retention bonuses of $2 million and equity increases of $20 million or more if they stay. Some have only been required to stay for a year to get the entire bonus. Google DeepMind has offered top researchers $20 million per year compensation packages and has reduced vesting on some stock packages to 3 years. Ariel Herbert-Voss, CEO of RunSybil, said, 'The AI labs approach hiring like a game of chess, they want to move as fast as possible, so they are willing to pay a lot for candidates with specialized and complementary expertise.' Noam Brown, one of the researchers behind OpenAI's recent AI breakthroughs, said, 'It was actually financially not the best option that I had,' but chose OpenAI because they were willing to put resources behind the work he was excited about.
Original language: en
Publish date: May 22, 2025 05:09 AM
Source:[The Financial Express](https://www.financialexpress.com/life/technology-openai-google-and-xai-battle-to-hire-the-best-minds-in-artificial-intelligence-3853202/)

**How to stop your posts, photographs and other data from being sucked into AI machines**
Many companies, including Meta, Google, and OpenAI, use user data to train their artificial intelligence models. However, EU citizens have the right to opt out of this data sharing. Meta has rolled out its AI training plan for EU users, but users can object by May 26th. Google has integrated AI into many of its products, including Android, and users can limit the data shared with Google to train its AI. OpenAI has faced lawsuits over its use of content to train its models, and users can opt out of data sharing by turning off Gemini apps activity. Anthropic's AI Claude will only use user conversations to train its models if explicitly given permission. Tumblr users can opt out of data sharing by excluding their blogs from sharing with licensed partners. X, the platform formerly known as Twitter, has its own AI called Grok, and users can opt out of data sharing by limiting Grok's access to their data. Apple has built generative AI into its operating systems, but uses high-quality public data to train its AI models and does not access user private data. Users can opt-in to use ChatGPT for queries that Apple Intelligence cannot answer.
Original language: en
Publish date: May 22, 2025 04:35 AM
Source:[The Irish Times](https://www.irishtimes.com/business/2025/05/22/how-to-stop-your-posts-photographs-and-other-data-from-being-sucked-into-ai-machines/)

**OpenAI, Google, xAI battle for superstar AI talent, shelling out millions**
The competition for top AI talent in Silicon Valley has escalated to unprecedented levels, with companies like OpenAI, Google, and xAI offering millions of dollars in bonuses and pay packages to attract the best researchers. Noam Brown, a researcher behind OpenAI's recent AI breakthroughs, said he chose OpenAI because of the resources they were willing to put behind the work he was excited about, despite it not being the most financially lucrative option. Top OpenAI researchers receive compensation packages of over $10 million a year, while Google DeepMind has offered $20 million per year packages to top researchers. The scarcity of talent has forced companies to approach hiring creatively, with some using sports industry data analysis techniques to identify promising but undiscovered talent. 'The AI labs approach hiring like a game of chess,' said Ariel Herbert-Voss, CEO of cybersecurity startup RunSybil. 'They want to move as fast as possible, so they are willing to pay a lot for candidates with specialized and complementary expertise.' 
Original language: en
Publish date: May 22, 2025 12:00 AM
Source:[geo.tv](https://www.geo.tv/latest/605648-openai-google-xai-battle-for-superstar-ai-talent-shelling-out-millions)

**OpenAI, Google and xAI battle for superstar AI talent - kuwaitTimes**
The battle for top AI talent has intensified, with companies like OpenAI, Google, and xAI competing for the services of individual contributors (ICs) who can make or break their AI models. According to Ariel Herbert-Voss, CEO of RunSybil and a former OpenAI researcher, 'The AI labs approach hiring like a game of chess,' where they are willing to pay a lot for candidates with specialized expertise. Noam Brown, a researcher behind OpenAI's recent breakthroughs, said he chose OpenAI over other offers because they were willing to put resources behind the work he was excited about. Top OpenAI researchers have received retention bonuses of $2 million and equity increases of $20 million or more, while Google DeepMind has offered $20 million per year compensation packages. The AI talent war has become more intense since the departure of OpenAI's chief technology officer, Mira Murati, who founded a rival AI startup and has lured 60 researchers from OpenAI and other labs.
Original language: en
Publish date: May 21, 2025 07:46 PM
Source:[kuwaittimes.com](https://kuwaittimes.com/article/28241/technology/openai-google-and-xai-battle-for-superstar-ai-talent/)

**These 3 companies want to build the first real AGI**
Three major companies, OpenAI, DeepMind, and Anthropic, are leading the charge in developing artificial general intelligence (AGI). OpenAI is focused on ensuring AGI benefits humanity, while DeepMind aims to solve intelligence and apply it to other challenges. Anthropic prioritizes AI alignment, safety, and interpretability, with its Claude models gaining recognition. Other companies, including Mistral, Meta, and xAI, are also actively involved in the AGI landscape. While it's difficult to predict which companies will lead the way, these players are worth monitoring as the AGI space continues to evolve rapidly.
Original language: en
Publish date: April 22, 2025 08:49 AM
Source:[Dataconomy](https://dataconomy.com/2025/04/22/these-3-companies-want-to-build-the-first-real-agi/)

**Google joins OpenAI in adopting Anthropic's protocol for connecting AI agents - why it matters**
Google has announced its support for Anthropic's Model Context Protocol (MCP), a standard that allows AI systems to access data stores, developer spaces, and business applications for better performance. This move follows OpenAI's adoption of MCP in March, and other companies such as Block, Apollo, and Sourcegraph have also embraced the protocol. According to Demis Hassabis, co-founder and CEO of Google DeepMind, 'MCP is a good protocol, and it's rapidly becoming an open standard for the AI agentic era.' The shift to using more open-source tools, including at the enterprise level, could indicate a larger sea change in the tech industry, especially as more companies invest in AI agents as the technology's next frontier.
Original language: en
Publish date: April 10, 2025 05:06 PM
Source:[ZDNet](https://www.zdnet.com/article/google-joins-openai-in-adopting-anthropics-protocol-for-connecting-ai-agents-why-it-matters/)

**Elon Musk's Inconsistent Stance on AI: A Tale of Manipulation and Deception**
Elon Musk, who previously signed a public letter urging a 6-month pause on training advanced AI systems, is now quietly building his own AI company, xAI. Despite publicly calling for a halt on AI development, Musk is focused on creating a company that can answer deeper scientific questions and help people solve complex scientific and mathematical problems. Musk's attention to the AI company, OpenAI, has been inconsistent, with him briefly canceling his interest and then rekindling it. In an interview, OpenAI's CEO, Sam Altman, expressed his frustration with Musk's inconsistent behavior, saying that they communicate through private messages on the X platform. Altman also stated that Musk is genuinely concerned about AI safety, but they have differing opinions on the matter. Musk has filed a lawsuit against OpenAI, accusing Altman and Brockman of manipulating him into founding OpenAI. The lawsuit claims that Musk was deceived and promised to replace Google DeepMind with an open-source system, which was an 'entrapment' by Altman. However, OpenAI remains unfazed, with a spokesperson stating that Musk's previous emails are sufficient evidence to prove his intentions.
Original language: zh
Publish date: April 07, 2025 03:51 AM
Source:[UDN](https://udn.com/news/story/121591/8656028)

**5 Game-Changing Tech Trends to Watch in 2025**
The tech industry is witnessing a shift towards autonomous AI agents in 2025, which can act, make decisions, and complete complex workflows without human supervision. Companies like OpenAI, Anthropic, and Google DeepMind are leading the charge, enabling hands-free productivity through virtual executive assistants and AI dev tools. However, this raises concerns about ensuring AI decisions remain ethical and explainable, and striking the right balance between human oversight and AI autonomy.
Original language: en
Publish date: April 06, 2025 10:35 PM
Source:[Medium.com](https://medium.com/@anasamir814/5-game-changing-tech-trends-to-watch-in-2025-1fb41487831c)

**OpenAI, Anthropic, Google, and AMD: Key AI Developments in March**
OpenAI has released several new tools and models, including a Responses API that combines the simplicity of Chat Completions API with the capabilities of Assistants API. The API includes three built-in tools: web search, file search, and computer use. The company has also released open-source Agents SDK, which allows developers to orchestrate the work of multiple agents, set up handovers between them, and track their actions. Additionally, OpenAI has introduced three new audio models that improve voice interaction with AI, including speech-to-text and text-to-speech models. The company has also launched OpenAI Academy, a free educational platform that provides training on working with AI. Anthropic has added a web search function to its chatbot, Claude, which allows users to search the internet and receive direct quotes from sources. Google has released several new models and tools, including Gemma 3, a multilingual model that supports 140 languages, and Gemini Robotics, a model that can interact with physical objects. Google has also introduced Canvas, an interactive workspace for collaborative work on documents and code, and NotebookLM, a tool for working with documents and YouTube videos. Google DeepMind has released Gemini 2.5 Pro, a model that can reason and make logical conclusions. Mistral has released a specialized OCR API for working with PDF documents, and a compact multilingual model, Mistral Small 3.1. AMD has released a family of language models, Instella, which show impressive results and compete with heavyweight models like Llama-3.2-3B and Gemma-2-2B. Alibaba has released QwQ-32B, a reasoning model that demonstrates results on a par with DeepSeek-R1, despite having only 32 billion parameters.
Original language: ru
Publish date: April 02, 2025 09:44 AM
Source:[Хабр](https://habr.com/ru/companies/magnus-tech/articles/896554/)

**Mira Murati Launches Thinking Machines Lab, a Rival to OpenAI**
Mira Murati, the former CTO of OpenAI, has launched a new AI startup called Thinking Machines Lab. After leaving OpenAI in October 2023, Murati has been working on this new project. The company's goal is to 'make AI systems more widely understandable, customizable, and generally capable', according to its statement. Thinking Machines Lab promises transparency, publishing regular technical research and code. The team includes John Schulman, co-founder of OpenAI, as research lead, and Barrett Zoph, a former OpenAI leader, as CTO. The company has also recruited Jonathan Lachman, a former OpenAI special projects division leader, and around 10 other top researchers and engineers from elite AI labs, including OpenAI, Character.AI, and Google DeepMind. However, the specific products that Thinking Machines Lab will launch are still unknown. Murati maintains secrecy, but the company is definitely worth keeping an eye on, as it joins a growing list of ex-OpenAI executives launching startups, including rivals like Safe Superintelligence and Anthropic.
Original language: it
Publish date: February 19, 2025 12:00 AM
Source:[punto-informatico.it](https://www.punto-informatico.it/mira-murati-fonda-thinking-machines-lab-sfida-openai/)

**Anthropic warns Google search proposal will harm US AI investment**
Anthropic, an AI company backed by Google, has filed a lawsuit against a US government proposal that would ban Google from investing in AI startups. Anthropic argues that this would disrupt competition and harm AI innovation in the country. The proposal is part of the Justice Department's antitrust case against Google's parent company, Alphabet Inc. Anthropic claims that this would create an 'unjustified windfall' for larger competitors like OpenAI and Meta, and would cripple its ability to compete. The company points out a contradiction in the proposal, as Google's own AI division, DeepMind, would remain untouched. Anthropic is one of the few companies directly competing against OpenAI, and has been aggressively raising capital to stay in the race. If Google is forced to pull out, Anthropic warned it could lose critical funding needed to expand computing power, train better models, and remain competitive.
Original language: en
Publish date: February 15, 2025 03:16 PM
Source:[cryptopolitan.com](https://www.cryptopolitan.com/anthropic-google-proposal-will-harm-us-ai/)

**The Great AI Players: OpenAI, Anthropic, Meta, Google, Mistral, Deepseek, and Alibaba**
The AI generative technology has been rapidly adopted by major US companies since the launch of ChatGPT in late 2022. The OpenAI, a leading American company in AI generative technology, has made a name for itself by launching ChatGPT, a chatbot that democratized the use of AI. The company has raised around $20 billion in investments, mainly from Microsoft, its main shareholder. According to the Wall Street Journal, the startup is in negotiations to raise an additional $40 billion. Sam Altman, co-founder of OpenAI, presides over the company, despite being fired for a short period. The OpenAI is a non-profit company that is moving towards a governance change to become a for-profit company. Anthropic, founded in 2021 by Dario and Daniela Amodei, two former OpenAI members, claims that its AI model, Claude, has more secure barriers than its competitors. Although the company has not attracted as much capital as OpenAI, it is attracting the interest of major technology companies. Amazon invested $4 billion in November, bringing its total investment to $8 billion. Anthropic has raised a total of $12.9 billion since its creation, including over $3 billion from Alphabet, the parent company of Google. The arrival of ChatGPT has sparked the appetite of technology giants, who have embarked on a race towards innovation with massive financial resources. Meta opened its Llama model to researchers in February 2023, before evolving it into Llama 2 and then Llama 3, and promoting its conversation tool MetaAI on the group's platforms (Facebook, Instagram, WhatsApp, and Threads). An interface that remains inaccessible in Europe due to a 'uncertain' regulatory framework. Google launched its conversation tool Bard in March 2023, which, after an evolution of its model, became Gemini in February 2024. 'We do not disclose precise numbers' about the total investment in AI, said Demis Hassabis, head of Google's Deepmind subsidiary, specialized in AI research, in April 2024. Mistral, founded by several French researchers (Arthur Mensch, Guillaume Lample, and Timothée Lacroix) who worked in the research laboratories of US giants, entered the AI scene in May 2023. The team of this startup, then unknown to the general public, announced a first fundraising of 100 million euros and immediately positioned itself as an alternative to US giants. Its conversation tool, called 'Le Chat', was launched in February 2024. At the same time, the company reveals a partnership with Microsoft, which is making an investment of 15 million euros. In mid-January, AFP and Mistral announced an agreement that allows the startup's conversational robot to use the agency's news to respond to its users' requests. A few days later, at the Davos meeting, the company indicated that it was considering the possibility of entering the stock market to maintain its independence. In total, the French startup has raised over 1 billion euros. Deepseek, a Chinese startup, revealed its conversational robot R1 in late January, marking a dramatic entry into the global AI scene and causing the stock market evaluations of several US giants, including chipmaker Nvidia, to plummet. The cause? The minimum cost of this new player. Deepseek said it spent only $5.6 million to develop its model, a value far from the standards of the US. Sam Altman, from OpenAI, said he was 'impressed', but also 'rejuvenated' by the competition. However, his company accused 'Chinese companies and others' of copying AI models developed by American companies. Alibaba, the latest participant in the race for conversation tools, launched Qwen2.5-Max on Thursday. Available for developers for now, the advanced AI model would be able to surpass the capabilities of existing models, according to the group.
Original language: pt
Publish date: February 04, 2025 12:35 PM
Source:[ISTOÉ Independente](https://istoe.com.br/os-grandes-atores-da-inteligencia-artificial-no-mundo/)

**OpenAI’s AI Persuasion Studies Raise Ethical and Safety Concerns**
OpenAI has conducted internal tests to evaluate the persuasive abilities of its AI models, using user-generated discussions from the subreddit r/ChangeMyView. The company's top AI models performed within the 80th to 90th percentile of human respondents, highlighting their effectiveness in persuasion. However, the use of public social media content in AI training has sparked broader discussions about data privacy and consent. OpenAI's research aims to ensure AI does not become too effective at persuasion, but the risks extend beyond theoretical concerns, including online misinformation, political influence campaigns, and commercial applications. Other AI developers, including Anthropic, Google DeepMind, and Meta, are also researching AI persuasion techniques, raising concerns about the potential for AI-generated disinformation. The question remains whether AI companies can establish reliable safeguards to prevent unintended consequences, and regulatory bodies are moving toward stricter AI governance, but no comprehensive framework currently addresses the ethical challenges of AI persuasion.
Original language: en
Publish date: February 02, 2025 11:23 AM
Source:[winbuzzer.com](https://winbuzzer.com/2025/02/02/openais-ai-persuasion-studies-raise-ethical-and-safety-concerns-xcxwbn/)

