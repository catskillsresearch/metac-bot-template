Here are the relevant news articles:

**US House Passes Bill Including 10-Year AI Regulation Moratorium**
The US House of Representatives has narrowly passed a legislative package that includes a 10-year ban on state laws regulating artificial intelligence. This measure is part of the so-called 'United, Great, and Beautiful' bill (H.R. 1), which also includes provisions on taxation and immigration. The bill was passed with 215 votes against 214, with almost all votes coming from Republicans. If passed, it would be one of the most significant federal steps in US technology policy in recent years. The moratorium is included in a section allocating funds to the Department of Commerce to modernize federal IT systems using commercial AI-based solutions. Supporters argue that the patchwork of state laws on AI would hinder business development and innovation, and that the goal is to give Congress time to create a unified national system. Large technology companies, the US Chamber of Commerce, and market-oriented think tanks like the R Street Institute have welcomed this proposal. However, opponents warn that the moratorium could seriously undermine consumer protection. Democratic representatives like Lori Trahan argue that this measure primarily serves the interests of large technology companies. Civil society groups and attorneys general from several states have also spoken out against the proposal. Even some Republicans in the Senate have expressed opposition. Senator Marsha Blackburn warned during hearings that the moratorium could undermine existing protections, such as the Tennessee Elvis Act (Ensuring Likeness, Voice, and Image Security Act), which was created to protect the voices, images, and personal rights of artists, especially in the era of generative AI. According to Punchbowl, her Republican colleague Josh Hawley has also expressed concern. Critics argue that introducing a moratorium without first establishing national security measures would be irresponsible. The bill is now being sent to the Senate, where its fate remains uncertain. Additionally, the so-called Byrd rule may come into effect, which excludes unrelated budget provisions from bills.
Original language: ru
Publish date: May 24, 2025 04:54 AM
Source:[Хабр](https://habr.com/ru/companies/bothub/news/912366/)

**US Bill Aims to Block AI Regulation for 10 Years**
A controversial bill in the US aims to block any regulation of artificial intelligence (AI) for the next 10 years. The bill, dubbed 'the great and beautiful bill' by the White House, was recently approved by the House of Representatives and is now awaiting Senate review. If passed, it would prevent states from creating safeguards or control systems for AI or automated decision-making systems for a decade. This would effectively freeze any attempt to regulate conversational agents like ChatGPT or Le Chat, as well as efforts to combat algorithmic discrimination or regulate AI use. The bill would also automatically block any existing laws or regulations related to AI, affecting over 60 projects already adopted by states. Critics argue that this would leave consumers unprotected against AI-related risks and prevent states from responding to emerging issues. Supporters claim it would allow American companies to innovate without being hindered by regulations, but opponents see it as a 'dangerous gift to big tech' that would harm consumers. More than 140 civil rights and consumer associations have urged Congress to reject the bill, citing the need for protection against growing AI risks. 'We must not be fooled, the families who came to us begging for action will not be the winners of this proposal,' said Democratic Representative Lori Trahan. 'But you know who will benefit? The big tech CEOs who were sitting behind Donald Trump at his inauguration.'
Original language: fr
Publish date: May 23, 2025 12:10 PM
Source:[01net](https://www.01net.com/?p=1271993)

**US Bill to Regulate AI Sector Sparks Concerns**
A controversial bill in the US, which would regulate the AI sector, has passed the House of Representatives and is now being examined by the Senate. If adopted, it would prevent states from creating safeguards or control systems for AI or automated decision-making systems for 10 years. This would effectively freeze any attempts to regulate conversational agents like ChatGPT or Le Chat, as well as measures to combat algorithmic discrimination and regulate AI use. The bill, known as the AI Act Trump, would also eliminate obstacles to the deployment and exploitation of AI systems, including deepfakes. According to some lawmakers, this would be a 'dangerous gift to large technology companies' that would harm consumers. As one blog article put it, 'This is a grave danger for Americans, as it would leave citizens without protection against any risk associated with AI.' 
Original language: fr
Publish date: May 23, 2025 12:10 PM
Source:[01net.com](https://www.01net.com/actualites/10-ans-sans-reguler-lia-aux-etats-unis-un-projet-de-loi-controverse-en-passe-detre-adopte.html)

**California Assembly Weighs Nation's Broadest AI-Driven Workplace Surveillance Bill: AB 1221 Raises the Bar, and the Stakes, for Employers**
California's Assembly Bill 1221 ('AB 1221') aims to regulate the use of artificial intelligence-enabled monitoring tools in workplaces. The bill would require employers to provide written notice to employees at least 30 days before deploying such tools, outlining the data collected, business purpose, and retention periods. Employers would be prohibited from using facial recognition, gait analysis, emotion detection, and neural-data collection, except for device unlocking or secured area access. The bill also bars employers from using surveillance to infer protected traits and restricts the use of monitoring data in disciplinary actions. Employers would be liable for security breaches and must provide employees with access to their data. Industry groups have criticized the proposal's breadth, while labor advocates see it as essential to prevent 'digital Taylorism' and protect worker privacy. If enacted, the bill would force employers to inventory monitoring technologies, update vendor contracts, and recalibrate internal policies and disciplinary protocols.
Original language: en
Publish date: May 23, 2025 12:55 AM
Source:[JD Supra](https://www.jdsupra.com/legalnews/california-assembly-weighs-nation-s-2861097/)

**U.S. policy moves reflect big tech issues with state AI laws | T...**
The U.S. House of Representatives has passed a tax and domestic policy package that includes a 10-year moratorium on state AI laws, pending federal data privacy legislation. This move reflects the federal administration's policy shift on AI, said Gartner analyst Lydia Clougherty Jones. Big tech vendors have advocated for federal policy to preempt state AI laws, citing the growing patchwork as chaotic. However, Rep. Lori Trahan (D-Mass.) expressed concerns that removing state guardrails will give tech companies 'blanket immunity to abuse our most sensitive data even more.' Trahan argued that Congress should focus on passing a federal data privacy law rather than relying on a state AI law moratorium.
Original language: en
Publish date: May 22, 2025 04:22 PM
Source:[TechTarget](https://www.techtarget.com/searchcio/news/366624575/US-policy-moves-reflect-big-tech-issues-with-state-AI-laws)

**US Plans to Track Location of Every Exported Advanced AI Chip – Overkill?**
The US government plans to introduce legislation that would require manufacturers of high-performance AI processors to embed location tracking technology into their products. This move is aimed at preventing advanced AI components from falling into the hands of China. Companies like Nvidia, AMD, and Intel will have to spend billions to incorporate this technology, and even after that, they will have little control over whom they can sell to. The bill also includes a provision for a one-year study to explore additional protective measures, and annual assessments for three years after the bill becomes law. Critics argue that this move is an overkill and could have long-term consequences on global trade, as well as potentially backfiring on the US by driving the global chip market to China. Krishi Chowdhary, a tech journalist, notes that the US export policy is currently as confusing as it has ever been, with arbitrary tariff rate increases, export bans, and now location tracking. He also points out that China may catch up with the US sooner than expected, as seen with the development of Huawei's 910C GPU Plus, which is now comparable to US-made chips.
Original language: en
Publish date: May 14, 2025 03:52 PM
Source:[techreport.com](https://techreport.com/news/us-ai-chip-export-tracking-overkill/)

**US House Passes Bill Including 10-Year AI Regulation Moratorium**
The US House of Representatives has narrowly passed a legislative package that includes a 10-year ban on state laws regulating artificial intelligence. This measure is part of the so-called 'United, Great, and Beautiful' bill (H.R. 1), which also includes provisions on taxation and immigration. The bill was passed with 215 votes against 214, with almost all votes coming from Republicans. If passed, it would be one of the most significant federal steps in US technology policy in recent years. The moratorium is included in a section allocating funds to the Department of Commerce to modernize federal IT systems using commercial AI-based solutions. Supporters argue that the patchwork of state laws on AI would hinder business development and innovation, and that the goal is to give Congress time to create a unified national system. Large technology companies, the US Chamber of Commerce, and market-oriented think tanks like the R Street Institute have welcomed this proposal. However, opponents warn that the moratorium could seriously undermine consumer protection. Democratic representatives like Lori Trahan argue that this measure primarily serves the interests of large technology companies. Civil society groups and attorneys general from several states have also spoken out against the proposal. Even some Republicans in the Senate have expressed opposition. Senator Marsha Blackburn warned during hearings that the moratorium could undermine existing protections, such as the Tennessee Elvis Act (Ensuring Likeness, Voice, and Image Security Act), which was created to protect the voices, images, and personal rights of artists, especially in the era of generative AI. According to Punchbowl, her Republican colleague Josh Hawley has also expressed concern. Critics argue that introducing a moratorium without first establishing national security measures would be irresponsible. The bill is now being sent to the Senate, where its fate remains uncertain. Additionally, the so-called Byrd rule may come into effect, which excludes unrelated budget provisions from bills.
Original language: ru
Publish date: May 24, 2025 04:54 AM
Source:[Хабр](https://habr.com/ru/companies/bothub/news/912366/)

**The D Brief: USFK to shrink?; House passes spending bill; Big AI in a laptop?; Russia's big security-camera hack; And a bit more.**
The USFK is considering shifting 4,500 troops from South Korea to other locations across the Pacific, including Guam, according to the Wall Street Journal. This move is part of a broader effort to reduce US troop levels in Europe and focus on a possible conflict with China. Meanwhile, the US Army's 25th Infantry Division has been testing new vehicles and drones in the Philippines, with a focus on adapting to the region's challenging terrain and weather conditions. The House has passed a spending bill with $150 billion for defense, and the Trump administration hopes to push $113 billion of that into Pentagon coffers in fiscal year 2026. Additionally, the US military is working on integrating cloud-based AI into local computer tools, and a new bill aims to formalize the Joint Reserve Detachment. The Trump administration is also indefinitely barred from issuing mass layoffs at most major federal agencies, and Booz Allen Hamilton plans to lay off roughly 7% of its workforce. Russian hackers have been targeting logistics firms to learn what the West is shipping to Ukraine, and US intelligence says the efforts began in 2022.
Original language: en
Publish date: May 23, 2025 03:12 PM
Source:[Defense One](https://www.defenseone.com/threats/2025/05/the-d-brief-may-23-2025/405565/)

**US Bill Aims to Block AI Regulation for 10 Years**
A controversial bill in the US aims to block any regulation of artificial intelligence (AI) for the next 10 years. The bill, dubbed 'the great and beautiful bill' by the White House, was recently approved by the House of Representatives and is now awaiting Senate review. If passed, it would prevent states from creating safeguards or control systems for AI or automated decision-making systems for a decade. This would effectively freeze any attempt to regulate conversational agents like ChatGPT or Le Chat, as well as efforts to combat algorithmic discrimination or regulate AI use. The bill would also automatically block any existing laws or regulations related to AI, affecting over 60 projects already adopted by states. Critics argue that this would leave consumers unprotected against AI-related risks and prevent states from responding to emerging issues. Supporters claim it would allow American companies to innovate without being hindered by regulations, but opponents see it as a 'dangerous gift to big tech' that would harm consumers. More than 140 civil rights and consumer associations have urged Congress to reject the bill, citing the need for protection against growing AI risks. 'We must not be fooled, the families who came to us begging for action will not be the winners of this proposal,' said Democratic Representative Lori Trahan. 'But you know who will benefit? The big tech CEOs who were sitting behind Donald Trump at his inauguration.'
Original language: fr
Publish date: May 23, 2025 12:10 PM
Source:[01net](https://www.01net.com/?p=1271993)

**US Bill to Regulate AI Sector Sparks Concerns**
A controversial bill in the US, which would regulate the AI sector, has passed the House of Representatives and is now being examined by the Senate. If adopted, it would prevent states from creating safeguards or control systems for AI or automated decision-making systems for 10 years. This would effectively freeze any attempts to regulate conversational agents like ChatGPT or Le Chat, as well as measures to combat algorithmic discrimination and regulate AI use. The bill, known as the AI Act Trump, would also eliminate obstacles to the deployment and exploitation of AI systems, including deepfakes. According to some lawmakers, this would be a 'dangerous gift to large technology companies' that would harm consumers. As one blog article put it, 'This is a grave danger for Americans, as it would leave citizens without protection against any risk associated with AI.' 
Original language: fr
Publish date: May 23, 2025 12:10 PM
Source:[01net.com](https://www.01net.com/actualites/10-ans-sans-reguler-lia-aux-etats-unis-un-projet-de-loi-controverse-en-passe-detre-adopte.html)

**Texas lawmakers push to regulate AI in government and the tech industry**
Texas lawmakers are pushing to regulate AI in government and the tech industry with House Bill 149, which aims to create guardrails that allow innovation while protecting people from potential harm. The bill would require government agencies to disclose when Texans are interacting with an AI system, ban the capture of biometric identifiers without consent, and prohibit AI systems designed to manipulate human behavior. It would also create a regulatory 'sandbox' for the AI industry to test systems free from certain state rules. Supporters say the bill is necessary to prevent harms like racial profiling, privacy violations, and opaque government decision-making, while critics warn that it could stifle innovation and introduce legal uncertainty. The bill has already cleared the lower chamber and is awaiting a vote by the full Senate.
Original language: en
Publish date: May 23, 2025 10:41 AM
Source:[KPRC](https://www.click2houston.com/news/texas/2025/05/23/texas-lawmakers-push-to-regulate-ai-in-government-and-the-tech-industry/)

**California Assembly Weighs Nation's Broadest AI-Driven Workplace Surveillance Bill: AB 1221 Raises the Bar, and the Stakes, for Employers**
California's Assembly Bill 1221 ('AB 1221') aims to regulate the use of artificial intelligence-enabled monitoring tools in workplaces. The bill would require employers to provide written notice to employees at least 30 days before deploying such tools, outlining the data collected, business purpose, and retention periods. Employers would be prohibited from using facial recognition, gait analysis, emotion detection, and neural-data collection, except for device unlocking or secured area access. The bill also bars employers from using surveillance to infer protected traits and restricts the use of monitoring data in disciplinary actions. Employers would be liable for security breaches and must provide employees with access to their data. Industry groups have criticized the proposal's breadth, while labor advocates see it as essential to prevent 'digital Taylorism' and protect worker privacy. If enacted, the bill would force employers to inventory monitoring technologies, update vendor contracts, and recalibrate internal policies and disciplinary protocols.
Original language: en
Publish date: May 23, 2025 12:55 AM
Source:[JD Supra](https://www.jdsupra.com/legalnews/california-assembly-weighs-nation-s-2861097/)

**U.S. policy moves reflect big tech issues with state AI laws | T...**
The U.S. House of Representatives has passed a tax and domestic policy package that includes a 10-year moratorium on state AI laws, pending federal data privacy legislation. This move reflects the federal administration's policy shift on AI, said Gartner analyst Lydia Clougherty Jones. Big tech vendors have advocated for federal policy to preempt state AI laws, citing the growing patchwork as chaotic. However, Rep. Lori Trahan (D-Mass.) expressed concerns that removing state guardrails will give tech companies 'blanket immunity to abuse our most sensitive data even more.' Trahan argued that Congress should focus on passing a federal data privacy law rather than relying on a state AI law moratorium.
Original language: en
Publish date: May 22, 2025 04:22 PM
Source:[TechTarget](https://www.techtarget.com/searchcio/news/366624575/US-policy-moves-reflect-big-tech-issues-with-state-AI-laws)

**Trump Signs Bill Outlawing 'Revenge Porn'**
US President Donald Trump signed the 'Take It Down Act' into law on Monday, making it a federal crime to post 'revenge porn' -- whether it is real or generated by artificial intelligence. The bill, which passed with bipartisan support, criminalizes non-consensual publication of intimate images and mandates their removal from online platforms. Trump said, 'With the rise of AI image generation, countless women have been harassed with deepfakes and other explicit images distributed against their will. And today we're making it totally illegal.' First Lady Melania Trump described the bill as a 'national victory that will help parents and families protect children from online exploitation.' Critics have voiced concerns that the bill grants authorities increased censorship power, but experts say it is a 'significant step' in addressing the exploitation of AI-generated deepfakes and non-consensual imagery. Renee Cummings, an AI and data ethicist, said, 'Its effectiveness will depend on swift and sure enforcement, severe punishment for perpetrators and real-time adaptability to emerging digital threats.' 
Original language: en
Publish date: May 19, 2025 04:15 PM
Source:[ibtimes.com](https://www.ibtimes.com/trump-signs-bill-outlawing-revenge-porn-3774031)

**US Plans to Track Location of Every Exported Advanced AI Chip – Overkill?**
The US government plans to introduce legislation that would require manufacturers of high-performance AI processors to embed location tracking technology into their products. This move is aimed at preventing advanced AI components from falling into the hands of China. Companies like Nvidia, AMD, and Intel will have to spend billions to incorporate this technology, and even after that, they will have little control over whom they can sell to. The bill also includes a provision for a one-year study to explore additional protective measures, and annual assessments for three years after the bill becomes law. Critics argue that this move is an overkill and could have long-term consequences on global trade, as well as potentially backfiring on the US by driving the global chip market to China. Krishi Chowdhary, a tech journalist, notes that the US export policy is currently as confusing as it has ever been, with arbitrary tariff rate increases, export bans, and now location tracking. He also points out that China may catch up with the US sooner than expected, as seen with the development of Huawei's 910C GPU Plus, which is now comparable to US-made chips.
Original language: en
Publish date: May 14, 2025 03:52 PM
Source:[techreport.com](https://techreport.com/news/us-ai-chip-export-tracking-overkill/)

**Data Diaries - April 2025**
The April 2025 issue of Data Diaries highlights the top stories in data protection, privacy, and cyber security law. The UK government is introducing a Cyber Security and Resilience Bill, which will align UK law with the EU NIS2 Directive. The Bill will also include measures to address ransomware, including a targeted ban on ransomware payments for public sector bodies and critical national infrastructure. The ICO has published its online tracking strategy, which focuses on online advertising and requires companies to provide users with clear information about data processing. The EU AI Act has entered into force, but its requirements are becoming applicable in stages. The Act prohibits certain AI practices and introduces AI literacy requirements. The UK government is considering introducing draft AI legislation in the next 18 months. Meanwhile, the ICO is reviewing the PECR consent requirements to enable a shift towards privacy-preserving online advertising models.
Original language: en
Publish date: April 24, 2025 01:53 PM
Source:[Lexology](https://www.lexology.com/library/detail.aspx?g=ede4bf1b-4d51-49f2-a64e-90c3aa432e5e)

**Proposed HIPAA Security Rule Requires AI Governance**
In 2024, the U.S. experienced the worst year for healthcare data breaches, with 53% of the population's records involved. To combat this, the Department of Health and Human Services (HHS) issued a Notice of Proposed Rulemaking (NPRM) to modify the HIPAA Security Rule, which includes addressing artificial intelligence (AI) systems for the first time. The proposed modifications aim to better protect electronic protected health information (ePHI) and ensure AI systems properly secure ePHI. Regulated entities can prepare for compliance by implementing a robust AI governance program, which includes managing AI risks, securing ePHI in AI training data, prediction models, and algorithm data, and addressing 'offensive AI' threats. 'The growth of AI has led to the concern of mass-scale cyberattacks,' said HHS, 'and it is crucial for regulated entities to consider how AI will use and maintain ePHI to ensure it is being properly secured.'
Original language: en
Publish date: March 12, 2025 05:19 PM
Source:[JD Supra](https://www.jdsupra.com/legalnews/proposed-hipaa-security-rule-requires-4379606/)

**The BR Privacy & Security Download: March 2025**
Several updates on AI and data privacy laws have been made in the US and EU. In the US, the Virginia legislature passed the High-Risk Artificial Intelligence Developer and Deployer Act, which requires developers to use reasonable care to prevent algorithmic discrimination and provide detailed documentation on an AI system's purpose, limitations, and risk mitigation measures. The Connecticut Senate introduced a bill to establish regulations for the development, integration, and deployment of high-risk AI systems. New York Governor Kathy Hochul signed several bills expanding compliance obligations for social media platforms, debt collectors, and dating applications. California reintroduced a bill requiring browsers and mobile operating systems to provide a setting that enables a consumer to send an opt-out preference signal to businesses with which the consumer interacts. In the EU, the first EU AI Act provisions became effective, prohibiting certain types of AI systems deemed to pose an unacceptable risk and rules on AI literacy. A coalition of business groups opposed the proposed updates to the HIPAA Security Rule, arguing that it would impose great financial burdens on the healthcare sector. Amazon is facing a class action lawsuit alleging violations of Washington's My Health My Data Act. NetChoice filed a complaint in federal court in Maryland challenging the Maryland Age-Appropriate Design Code Act as violating the First Amendment. Kochava settled a class action lawsuit alleging it collected and sold precise geolocation data of consumers without their consent. The US District Court for the Western District of Texas granted a preliminary injunction blocking enforcement of Texas' Securing Children Online through Parental Empowerment Act. The California Attorney General agreed to narrow the enforcement of certain parts of AB 587, a social media law. Arkansas Attorney General Tim Griffin sued General Motors and its subsidiary OnStar for allegedly deceiving Arkansans and selling data collected through OnStar from more than 100,000 Arkansas drivers' vehicles to third parties. Health Net and its parent company, Centene Corp., settled with the United States Department of Justice for allegations that Health Net falsely certified compliance with cybersecurity requirements under a U.S. Department of Defense contract. Warby Parker was fined $1.5 million for HIPAA violations. The California Privacy Protection Agency announced that it is seeking a $46,000 penalty against Jerico Pictures, Inc. for allegedly failing to register and pay an annual fee as required by the California Delete Act.
Original language: en
Publish date: March 06, 2025 07:45 PM
Source:[JD Supra](https://www.jdsupra.com/legalnews/the-br-privacy-security-download-march-1996675/)

**AI Regulations: Virginia's AI Act Targets 'High Risk' AI Systems | PYMNTS.com**
Virginia is on the verge of becoming the second US state to enact AI regulations, targeting high-risk AI systems that autonomously make decisions or significantly influence them. The legislation, which will take effect on July 1, 2026, aims to safeguard consumers from algorithmic discrimination in consequential decisions like lending, housing, education, healthcare, and employment. Developers and deployers must ensure that AI systems are transparent, and consumers are informed when AI is used in consequential decisions. However, 19 types of technologies are exempt from this act, including anti-fraud technology and cybersecurity tools. Fines for unintentional violations can reach up to $1,000 per instance, while willful violations can result in fines of up to $10,000 per instance. Meanwhile, New York Governor Kathy Hochul has proposed a requirement for employers to disclose whether AI tools played a role in mass layoffs or office closures, and Estonia has unveiled a national AI education program, AI Leap 2025, which will embed AI technology throughout its educational system.
Original language: en
Publish date: March 05, 2025 07:25 PM
Source:[PYMNTS.com](https://www.pymnts.com/news/artificial-intelligence/2025/ai-regulations-virginias-ai-act-targets-high-risk-ai-systems/)

**Consumer product regulators would get AI assist from House bill**
The Consumer Safety Technology Act, which passed the House last year, aims to provide regulators with AI tools to help identify and prevent dangerous consumer products from entering the market. According to Representative Soto, 'The whole point is, look, the crooks already have artificial intelligence, so the cops on the beat need to have AI, too.' The bill would require the CPSC to use AI to track trends in consumer product injuries, identify hazards, and monitor the retail marketplace for recalled products. The commission would also need to consult with experts in AI, cybersecurity, and consumer safety before delivering a report to Congress within a year. Additionally, the bill directs the Commerce secretary and the Federal Trade Commission to study the use of blockchain technology and tokens.
Original language: en
Publish date: March 04, 2025 12:00 AM
Source:[fedscoop.com](https://fedscoop.com/ai-consumer-product-safety-commission-bill/)

**Spring Cleaning: Legislative Plans for Cybersecurity, Business Data, AI, and e-Evidence**
The Irish Government has published its Legislation Programme for Spring 2025, outlining key legislation to be published or drafted during this period. The Programme includes bills to support EU initiatives in the technology sector, such as the NIS2 Directive, the Data Act, and the AI Act. The National Cyber Security Bill will transpose the NIS2 Directive, which Ireland missed the transposition deadline for. The EU Data Regulation Bill will support innovation and economic growth by creating a harmonised framework on fair access and use of data, aligning with the Data Act. The Regulation of Artificial Intelligence Bill will give full effect to the EU AI Act, designating national competent authorities and providing for penalties for non-compliance. The Criminal Justice (Protection, Preservation of and Access to Data on Information Systems) Bill and the Criminal Justice (International Cooperation Authority) Bill will progress the application of the e-Evidence Package in Ireland.
Original language: en
Publish date: February 24, 2025 12:44 PM
Source:[Lexology](https://www.lexology.com/library/detail.aspx?g=fedf9201-a6be-40ad-ac4f-bdcc98cce8bf)

**Latest developments in AI, cyber security and digital platforms regulations**
The Australian government is driving legislative reform in response to rapid advancements in AI and high-profile privacy breaches. The government has been consulting on issues related to AI deployment and regulation, including the development of a National AI Capability Plan. The plan is expected to draw on EU models and be released by the end of 2025. The government has also announced plans to introduce a 'digital duty of care' for large social media platforms to protect users from harmful content. This duty would require platforms to conduct regular risk assessments, be transparent about the results, and respond to user complaints. The government is also receiving submissions on the subordinate legislation to the Cyber Security Act and the Security of Critical Infrastructure Act 2018. Additionally, the regulatory environment for the privacy of personal information continues to evolve, with recent developments including changes to the Commonwealth Privacy Act and new guidance on privacy issues with the use of AI.
Original language: en
Publish date: February 18, 2025 01:29 PM
Source:[Lexology](https://www.lexology.com/library/detail.aspx?g=283c6ce9-0e6d-4fbc-820c-95ad3e0961c3)

**Artificial Intelligence: A Regulatory Storm Brewing in 2025**
The artificial intelligence (AI) industry is expected to see significant regulatory activity in 2025, particularly in the United States, according to Mark Wiedeworth, a policy and regulation expert. In 2023, California passed 18 new AI laws, but tech companies are pushing back against these regulations, according to TechCrunch. Wiedeworth, a former chief information security officer for California and Colorado, and a former deputy assistant secretary for cybersecurity under President Barack Obama, said, 'In California alone, 12 new AI-related laws have been signed into effect in the past two months.' Wiedeworth emphasized the growing concerns about cybersecurity, saying, 'There are huge concerns about the security of AI.' Hani Friedman, a former dean of the University of California, Berkeley's College of Information and a vocal advocate for AI regulation, said, 'The pressure from big American companies on AI regulations in Western countries is intense. They're trying to kill any legislation or write it to their advantage. It's a ruthless move.' On the other hand, outside the West, companies like Meta and OpenAI have received warm welcomes from many politicians eager to invest in AI. Akrit Vashistha, a senior advisor to the Indian government's AI initiative, said, 'Regulation is not even a conversation.' Mark Zuckerberg, Meta's CEO, told the US Senate in 2023, 'New technologies often bring new challenges, and companies must ensure we build and deploy products responsibly.' Zuckerberg advocated for self-regulation in AI, citing 'we can build in safeguards in these systems.' Sam Altman, CEO of OpenAI, said during a visit to New Delhi, 'Self-regulation is important.' However, he also warned that 'the world shouldn't be left entirely in the hands of companies, given the power of this technology.'
Original language: ar
Publish date: January 27, 2025 12:59 PM
Source:[alyaum.com](https://www.alyaum.com/articles/6576141/%D8%A7%D9%84%D8%A7%D9%82%D8%AA%D8%B5%D8%A7%D8%AF/%D9%85%D8%A7%D9%84-%D9%88%D8%A3%D8%B9%D9%85%D8%A7%D9%84/%D8%A7%D9%84%D8%B0%D9%83%D8%A7%D8%A1-%D8%A7%D9%84%D8%A7%D8%B5%D8%B7%D9%86%D8%A7%D8%B9%D9%8A-%D9%85%D9%86-%D9%8A%D8%B6%D8%B9-%D9%82%D9%88%D8%A7%D9%86%D9%8A%D9%86%D9%87-%D9%88%D9%83%D9%8A%D9%81-%D8%AA%D8%AA%D8%A3%D8%AB%D8%B1-%D8%B4%D8%B1%D9%83%D8%A7%D8%AA-%D8%A7%D9%84%D8%AA%D9%83%D9%86%D9%88%D9%84%D9%88%D8%AC%D9%8A%D8%A7)

**Will states lead the way on AI regulation?**
Mark Weatherford, a cybersecurity expert and former Chief Information Security Officer for California and Colorado, believes that states will lead the way in AI regulation in 2025. He points to California's recent passage of 12 AI-related bills and the introduction of over 400 pieces of AI legislation at the state level. Weatherford thinks that harmonization of regulations across states is necessary to avoid a 'diverse set of regulations' that companies must comply with. He also expects California to pass stricter AI regulations in 2025. On the federal level, Weatherford is less optimistic about major legislation, citing the incoming administration's emphasis on 'less regulation.' However, he believes that regulation is necessary to address the safety and security concerns surrounding AI. Weatherford also discusses the potential of synthetic data to address the quality and bias issues in AI, and the need for legislation to control the use of AI in a way that doesn't violate existing laws. He emphasizes the importance of communicating AI-related issues to non-technologists in a way that they can understand.
Original language: en
Publish date: January 25, 2025 09:37 PM
Source:[TechCrunch](https://techcrunch.com/2025/01/25/will-states-lead-the-way-on-ai-regulation/)

**AI Predictions for 2025: A Cyber Security Expert’s Perspective – Check Point**
As we approach 2025, the rapid evolution of artificial intelligence (AI) is set to dramatically reshape the cyber security landscape. The surge in AI usage will have far-reaching implications for areas such as energy consumption, software development, and ethical and legal frameworks. AI technologies will also be weaponized by cybercriminals and nation state actors, creating new and formidable threats to cyber security. Experts predict that by 2033, the global large language model market will reach $140.8 billion. The rapid adoption of AI technologies is already driving a huge increase in land, water, and energy required to support them. The proliferation of AI is putting immense strain on global energy resources, with data centers requiring land, energy, and water. Experts have sounded a warning bell that the current system is quickly becoming unsustainable. To mitigate this, a shift towards more sustainable power sources and innovative cooling solutions for high-density AI workloads is necessary. Compute technology itself will also become more efficient with advancements in chip design and workload planning. AI is set to revolutionize software programming, but it also poses significant security risks. The barrier for entry for cybercriminals will disappear as they become more sophisticated and widespread, making our digital world far less secure. The threat will fuel the area of responsible AI, where AI vendors build guardrails to prevent weaponization or harmful use of their large language models. In 2025, we will see the emergence of multi-agent AI systems in both cyber-attacks and defense. As AI becomes more pervasive, we will face increasing ethical and regulatory challenges. The EU's AI Act will kick in February 2, 2025, and a new AI regulatory framework is expected to be implemented through the National Defense Authorization Act (NDAA) and other legislative measures. These new laws will force enterprises to exert more control over their AI implementations, and new AI governance platforms will emerge to help them build trust, transparency, and ethics into AI models.
Original language: en
Publish date: January 25, 2025 03:30 AM
Source:[ncnonline.net](https://www.ncnonline.net/ai-predictions-for-2025-a-cyber-security-experts-perspective-check-point/)

