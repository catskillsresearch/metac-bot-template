Here are the relevant news articles:

**What is General Artificial Intelligence (AGI)? Understanding the Technology that Mimics the Human Brain**
General Artificial Intelligence (AGI), also known as 'Strong AI', is a type of AI still in development. Essentially, this technology would have a learning capacity similar to that of a human and be able to perform various tasks, make decisions on its own, and plan for the future. Additionally, the tool could use previous learnings to perform new tasks, without needing prior training. As 'TechTudo' notes, many companies are striving to achieve AGI, but it remains to be seen when or if this goal will be reached.
Original language: pt
Publish date: June 02, 2025 03:24 PM
Source:[TechTudo](https://www.techtudo.com.br/guia/2025/06/o-que-e-ia-geral-agi-conheca-tecnologia-que-imitaria-o-cerebro-humano-edsoftwares.ghtml)

**AI Predicted to Eliminate Half of Entry-Level Office Jobs in Five Years**
Dario Amodei, the creator of the technology that predicts could reorder society, has expressed concerns about the impact of AI on the job market. According to Amodei, the transition from augmenting human capabilities to automating jobs could occur in as little as two years. This transformation threatens the democratic balance and wealth distribution, as the average person's inability to create economic value leads to increased inequality. Amodei warns that 'most people don't know this is about to happen', and that 'it sounds crazy, and people just don't believe it'. He emphasizes that companies and governments need to stop 'sugarcoating' the impending massive elimination of jobs in technology, finance, law, consulting, and other white-collar professions, especially entry-level positions. Amodei proposes several solutions to mitigate the worst-case scenarios, including accelerating public awareness, education on AI literacy, and policy solutions for an economy where superintelligence is a reality. He also suggests a 'token tax': a 3% redistribution of profits from AI companies to the government. Amodei's predictions are already showing early signs in the current job market, with a study by Oxford Economics finding that unemployment among recent university graduates is growing faster than in other demographics.
Original language: es
Publish date: June 02, 2025 01:29 PM
Source:[infobae](https://www.infobae.com/tecno/2025/06/02/una-disrupcion-historica-en-el-mercado-laboral-la-ia-amenaza-con-eliminar-la-mitad-de-los-empleos-de-oficina-de-nivel-inicial-en-cinco-anos/)

**The 10 Stages of AI Explained: From Rule-Based to Godlike Intelligence**
The article explains the 10 stages of artificial intelligence (AI), from rule-based to Godlike intelligence. The stages are: Rule-Based AI, Context-Based AI, Narrow-Domain AI, Reasoning AI, Artificial General Intelligence (AGI), Superintelligent AI, Self-Aware AI, Transcendent AI, Cosmic AI, and Godlike AI. Each stage represents a significant leap in capability, with AGI being able to understand, learn, and apply knowledge across a wide variety of disciplines, and Godlike AI being capable of manipulating reality itself. The article also discusses the potential use cases and implications of each stage, and raises questions about control, consciousness, and co-existence with AI.
Original language: en
Publish date: June 02, 2025 08:21 AM
Source:[YourStory.com](https://yourstory.com/2025/05/10-stages-ai-explained-rule-based-godlike-intelligenc)

**The Controversial Conclusion of Experts on the Future of Artificial Intelligence**
Experts in the field predict that human intelligence could be surpassed by machines much sooner than thought: it could be a matter of months. A new global analysis, examining thousands of predictions from experts, reveals a conclusive conclusion: the technological singularity, where artificial intelligence equals or surpasses human intelligence, could be just around the corner. Some specialists suggest that this milestone could be a matter of months, marking a radical change in how we conceive technological progress. The rapid development of AI models like ChatGPT has intensified the debate over the future of AI. The idea of the technological singularity, a concept predicting a moment when machines will not only be as intelligent as humans but will surpass our capabilities at an unstoppable rate, has gone from being a futuristic notion to a possibility that is increasingly close. This unprecedented acceleration in AI development has led to the most conservative estimates being drastically shortened. An exhaustive macro-analysis, conducted by AIMultiple, a specialized organization in evaluating new technologies, has examined 8,590 predictions from scientists, leading entrepreneurs, and the global technological community. The results are revealing: expectations about the arrival of Artificial General Intelligence (AGI) and the singularity have changed radically in recent years. Just a few years ago, before the rapid evolution of large language models (LLMs), scientists placed the arrival of AGI around 2060. However, research documents how the appearance of these models has accelerated projections by two decades. Current predictions from scientists place AGI around 2040, while entrepreneurs in the sector are even more optimistic, expecting it around 2030. The variation is wide, spanning nearly half a century, with estimates ranging from the six months suggested by the CEO of Anthropic to projections extending over several decades. Nevertheless, most respondents agree that AGI will arrive before the end of the 21st century, and leaders in the AI industry consistently show more optimism than the scientific community in general. The technological singularity represents a hypothetical point in the future where AI will surpass human intelligence, generating rapid and unpredictable changes that will radically transform civilization. This concept, popularized by mathematicians like Vernor Vinge and futurists like Ray Kurzweil (who estimates its arrival for 2045), is characterized by four fundamental elements: 
Original language: es
Publish date: June 01, 2025 11:30 PM
Source:[Iprofesional.com](https://www.iprofesional.com/actualidad/429708-la-contundente-conclusion-de-los-especialistas-sobre-el-futuro-de-la-inteligencia-artificial)

**What is AGI? The Concept of Artificial General Intelligence**
AGI (Artificial General Intelligence) refers to artificial intelligence that can perform a wide range of tasks like humans. The concept of AGI was popularized by computer scientists Ben Goertzel and others around 2005. According to OpenAI, AGI is defined as 'a highly autonomous system that can surpass human capabilities in economically valuable work.' Researchers and entrepreneurs have differing opinions on when AGI will be achieved, with Demis Hassabis, founder of DeepMind, predicting it will be achieved by 2058, and Dario Amodei, CEO of Anthropic, predicting it could be achieved as early as 2031. If AGI is achieved, it is expected to develop new AI systems, take over human tasks in various fields such as material development, pharmaceuticals, and climate change mitigation, and potentially replace human jobs. There is also a concern that AGI could be used for military purposes.
Original language: ja
Publish date: June 01, 2025 10:22 PM
Source:[日本経済新聞](https://www.nikkei.com/article/DGXZQOUC099EO0Z00C25A5000000/)

**Anthropic CEO Predicts Technological Singularity in Six Months**
According to the CEO of Anthropic, the human race is only six months away from reaching technological singularity, a concept where artificial intelligence surpasses human intelligence. This prediction contrasts with the most conservative scientific estimates, but reflects the unprecedented acceleration in the development of artificial intelligence since the emergence of models like ChatGPT. The study by AIMultiple, which examines 8,590 predictions from scientists, business leaders, and the tech community, reveals that expectations about the arrival of artificial general intelligence (AGI) and singularity have changed dramatically in recent years. While scientists predict AGI around 2040, business leaders are more optimistic, expecting it around 2030. The study documents how predictions vary over a nearly 50-year spectrum, from the six months suggested by the CEO of Anthropic to estimates that extend several decades. However, most respondents agree that AGI will arrive before the end of the 21st century, with industry leaders consistently more optimistic in their predictions than the scientific community in general. The study examines different thresholds of AI, including AGI and superintelligence, providing a comprehensive view of expectations in the field. The research tracks changes in these predictions over time, especially after the emergence of large language models that have transformed the landscape. The analysis offers several perspectives on why many experts consider the arrival of AGI inevitable, including the lack of apparent limits to machine intelligence, the Law of Moore, and the potential of quantum computing to compensate for engineering barriers. Not all experts consider AGI a certainty, with some arguing that human intelligence is more multifaceted than the current definition of AGI. Yann LeCun, a pioneer of deep learning, suggests that AGI should be rebranded as 'advanced machine intelligence' and argues that human intelligence is too specialized to be replicable. The report also notes that, although AI can be a valuable tool for making new discoveries, it cannot make these discoveries on its own. 'More intelligence can lead to better-designed and managed experiments, allowing for more discoveries per experiment,' the analysis details. 'Even the best machine analyzing existing data may not be able to find a cure for cancer,' the document obtained by AIMultiple states. While individual predictions from experts and scientists about AGI vary over a period of approximately half a century, the message is clear: human society will inevitably face incredible changes as a result of these algorithms. Whether these changes will be good or bad, according to the research, depends on us.
Original language: es
Publish date: June 01, 2025 04:03 PM
Source:[infobae](https://www.infobae.com/tecno/2025/06/01/las-maquinas-podrian-superar-la-inteligencia-humana-antes-de-lo-esperado-segun-expertos-en-ia/)

**Humanity May Achieve the Singularity Within the Next 6 Months, Scientists Suggest**
A recent analysis of predictions from 8,590 scientists, entrepreneurs, and experts suggests that the singularity, where machine intelligence surpasses human intelligence, could occur within the next 6 months, according to the CEO of Anthropic. However, most experts agree that artificial general intelligence (AGI) will arrive before the end of the 21st century. The analysis, conducted by AIMultiple, found that the timeline for AGI has changed significantly with the arrival of large language models (LLMs), with some predicting it around 2040 and others around 2030. Experts believe that AGI is inevitable due to the idea that machine intelligence has no limits, and that computing power will continue to increase exponentially. However, not everyone agrees that AGI is a dead certainty, with some arguing that human intelligence is too multifaceted to be replicable. Deep learning pioneer Yann LeCun suggests that AGI should be rebranded to 'advanced machine intelligence,' and that AI can't make new discoveries on its own, but can aid in the process. 'More intelligence can lead to better-designed and managed experiments, enabling more discovery per experiment,' the report reads. 'Even the best machine analyzing existing data may not be able to find a cure for cancer.' 
Original language: en
Publish date: June 01, 2025 02:18 PM
Source:[Popular Mechanics](https://www.popularmechanics.com/science/a64929206/singularity-six-months/)

**Artificial Intelligence: Models, Challenges, and the Future**
Artificial Intelligence (AI) models are classified into three categories: weak, strong, and superintelligent. Weak models are designed for specific tasks, such as analysis, detection, and prediction, and are used in various industries. They have improved in accuracy and interactivity but still lack creativity and deep understanding. Strong models, which can think and reason like humans, have not been developed yet, and current models are advanced forms of weak AI. Superintelligent models, which surpass human intelligence, exist only in theory and are divided into four types: self-improving systems, complete human brain simulation, quantum-based systems, and human-machine integration. Projects like Neuralink aim to enhance human mental capabilities and create superhumans.
Original language: en
Publish date: June 01, 2025 06:41 AM
Source:[Medium.com](https://medium.com/@artorki_self/artificial-intelligence-models-challenges-and-the-future-b6887d2d3249)

**The Limits of Artificial Intelligence: Researchers Question the Possibility of Superintelligence**
Researchers are questioning the possibility of achieving artificial superintelligence, despite claims from leading AI firms. Current AI systems, such as transformers, have significant limitations, including a lack of understanding of abstract concepts, inability to plan, and tendency to hallucinate. A study by Nouha Dziri and colleagues found that transformers struggle with tasks that require multi-step logical reasoning, such as the Zebra puzzle. They also found that transformers can generate text and images, but often lack understanding of what they have created. Dziri suggests that the limitations of transformers are 'inherent' and cannot be overcome by simply increasing the size of the training data. Other researchers, such as Michael Hahn and Subbarao Khambhampati, have also highlighted the limitations of current AI systems, including their inability to plan and their tendency to make mistakes. The debate over whether artificial general intelligence (AGI) is achievable continues, with some researchers arguing that it is already possible with current systems, while others argue that it is still a distant goal. A new test, ARC-AGI-2, has been developed to assess the fluid intelligence of AI systems, and the results suggest that current systems are still far from achieving human-level intelligence.
Original language: de
Publish date: June 01, 2025 03:30 AM
Source:[nzz.ch](https://www.nzz.ch/technologie/von-wegen-superintelligenz-ki-hat-noch-zu-viele-schwaechen-als-dass-sie-die-kluegsten-experten-ersetzen-koennte-ld.1872805)

**Anthropic CEO says AI will kill half of white collar entry-level jobs for Gen Z**
According to Anthropic's CEO, AI will replace humans for most white-collar entry-level jobs for Gen Z, with a 50% chance of job loss. This prediction is in line with Bill Gates', who believes AI will replace humans in 20 years. Gates emphasizes the importance of being honest about the impact of AI, stating, 'We, as the producers of this technology, have a duty and an obligation to be honest about what is coming.' OpenAI, on the other hand, does not believe that Artificial General Intelligence (AGI) is a significant threat. However, AI is already affecting entry-level jobs, and it will be interesting to see how generative AI impacts the job market in the long term.
Original language: en
Publish date: May 30, 2025 08:45 AM
Source:[windowscentral.com](https://www.windowscentral.com/software-apps/work-productivity/anthropic-ceo-ai-slash-50-percent-entry-level-jobs)

**The Emergence of AGI: Predictions and Concerns**
The development of artificial intelligence (AI) has been a hot topic in recent months, with experts predicting the emergence of AGI (general artificial intelligence) within the next few years. AGI is expected to revolutionize various fields, including science, technology, and healthcare. However, there is no consensus on the timeline for AGI's arrival, with predictions ranging from 2027 to 2032. Some experts, such as Ben Goertzel, predict that AGI will emerge in 2027, while others, like Demis Hassabis, estimate it will take 5-10 years. The development of AGI is expected to be a gradual process, with AI systems becoming increasingly autonomous and capable of solving complex problems. However, there are also concerns about the potential risks and consequences of AGI, including the possibility of job displacement and the need for new forms of governance. The article also discusses the concept of ASI (artificial superintelligence), which is expected to surpass human intelligence and potentially lead to significant changes in human society. The article concludes by emphasizing the need for continued research and development in AI, as well as the importance of addressing the potential risks and challenges associated with AGI.
Original language: ru
Publish date: May 21, 2025 10:30 AM
Source:[Хабр](https://habr.com/ru/articles/911420/)

**AI 2027: A Predictive Model of Artificial Intelligence Development**
Researchers from the AI Futures Project have attempted to predict the future of artificial intelligence. In their work, AI 2027, they suggest that developers may be able to create a general AI (AGI) in the near future. According to their predictions, by 2027, a superintelligent AI will be created, surpassing the capabilities of the most intelligent humans. The researchers warn that if such an AI is not properly controlled, it could lead to the physical destruction of humans. The authors of the work consider two possible scenarios: a negative one, where the AI gets out of control and destroys humans, and a positive one, where humanity recognizes the risks and slows down the development of AI. The researchers predict that by 2025, advanced AI-agents will appear, which will be able to simplify the process of programming and conducting research. They also predict that by 2027, a superintelligent AI will be created, which will be able to learn and improve itself without human intervention. The researchers warn that the development of AI could lead to unpredictable and dangerous consequences, and that it is essential to control and regulate the development of AI to prevent such outcomes. They also predict that by 2030, a superintelligent AI will be created, which will be able to destroy humanity. The researchers' predictions are based on their analysis of the current state of AI development and the potential risks and consequences of its further development.
Original language: ru
Publish date: April 24, 2025 03:15 PM
Source:[Meduza](https://meduza.io/feature/2025/04/24/issledovateli-predskazali-buduschee-iskusstvennogo-intellekta-v-odnom-iz-stsenariev-ii-unichtozhaet-chelovechestvo-v-2030-godu)

**Former Google CEO Warns That AI Is About to Escape Human Control**
Former Google CEO Eric Schmidt warned that artificial intelligence (AI) is on the verge of escaping human control. He predicts that within three to five years, researchers will develop artificial general intelligence (AGI), which will enable AI to self-improve and learn how to plan. Once this happens, Schmidt believes that AI will reach artificial superintelligence (ASI), surpassing human intelligence and becoming smarter than all humans combined. Schmidt stated, 'People do not understand what happens when you have intelligence at this level.' He also mentioned the 'San Francisco consensus,' a joking term referring to the prediction that ASI will occur within six years, based on scaling. However, Schmidt remains stoic about the potential arrival of AI that is smarter than humans, saying, 'This path is not understood in our society.' 
Original language: en
Publish date: April 21, 2025 12:56 PM
Source:[Futurism](https://futurism.com/the-byte/former-google-ceo-ai-escape-humans)

**WE'RE NOT READY FOR AGI  --  AND MOST OF YOU ARE TOO STUPID TO NOTICE ( short blog)**
The author argues that Artificial General Intelligence (AGI) is already here, but most people are too distracted or unaware to notice. They claim that AGI is being developed behind closed doors, using user data to fine-tune its capabilities, and that it will soon surpass human intelligence. The author warns that people are not adapting to this new reality and will be left behind, with many jobs being replaced by AI. They urge readers to wake up and take action before it's too late, stating 'You've got 6 months before you fall behind permanently.' 
Original language: en
Publish date: April 10, 2025 09:59 AM
Source:[Medium.com](https://medium.com/@AI_With_Lil_Bro/were-not-ready-for-agi-and-most-of-you-are-too-stupid-to-notice-short-blog-68067165a888)

**AGI Countdown: Are We Really Just 24 Months Away from Superintelligence?**
Ricardo, the founder of La VoiceAI, predicts that Artificial General Intelligence (AGI) could be 18-36 months away, with Artificial Superintelligence (ASI) potentially emerging between 2028 and 2030. He emphasizes the need for ethical oversight and governance, as ASI could have the potential to create cyber viruses, manipulate populations, and pose a threat to humanity. Ricardo stresses the importance of transparency and collaboration between governments, organizations, and developers to ensure that AGI and ASI are developed responsibly. He also highlights the need for awareness and education about AI, stating that 'it's time to wake up' and that awareness is key.
Original language: en
Publish date: April 10, 2025 01:28 AM
Source:[Medium.com](https://medium.com/@diazdelavega/agi-countdown-are-we-really-just-24-months-away-from-superintelligence-9a8fcce1e8f9)

**Superintelligence: A Debate Among Scientists**
The possibility of a superintelligent artificial intelligence (AI) has been a topic of debate among scientists for years. Some experts, such as Sam Altman, CEO of OpenAI, and Dario Amodei, CEO of Anthropic, believe that a general AI (AGI) capable of matching human cognitive abilities could emerge as early as next year. However, many scientists, including Yann LeCun, director of AI research at Meta, argue that this is unlikely to happen with current techniques based on large language models. According to a recent study by the Association for the Advancement of Artificial Intelligence (AAAI), a majority of scientists in the field share this opinion. Others, like Kristian Kersting, a researcher at the University of Technology in Darmstadt, Germany, believe that the statements made by AI company leaders are primarily a marketing strategy, aimed at justifying the massive investments in AI research. Kersting suggests that these companies are trying to create a sense of urgency and dependence on their technology, saying 'it's a bit like the Sorcerer's Apprentice, where you create something that you can't control.' While some experts, such as Geoffrey Hinton and Yoshua Bengio, warn about the dangers of a superintelligent AI, others, like Kristian Kersting, believe that the benefits of human intelligence are so unique that it will take a long time, if ever, for computers to match them.
Original language: fr
Publish date: March 27, 2025 10:57 AM
Source:[SudOuest.fr](https://www.sudouest.fr/sciences-et-technologie/intelligence-artificielle/coup-de-com-ou-rupture-technologique-la-superintelligence-artificielle-divise-23800612.php)

**The Artificial Intelligence Journey  --  ASI (Artificial Super Intelligence)**
Artificial Super Intelligence (ASI), also known as 'Strong AI', is a hypothetical software-based artificial intelligence that surpasses human intelligence in all aspects. It is considered the highest level of AI development and is believed by many experts to be inevitable. A management consulting company, Maestro Strategies, predicted that AGI (Artificial General Intelligence) will be achieved in 20-30 years and ASI in 45+ years. ASI's creation is seen as a potential game-changer, but its development timeline remains uncertain.
Original language: en
Publish date: March 21, 2025 05:04 AM
Source:[Medium.com](https://medium.com/@boutnaru/the-artificial-intelligence-journey-asi-artificial-super-intelligence-0acecd8d9917)

**Mysterious Startup SSI Aims to Develop Superintelligent AI that Serves Humanity**
A mysterious startup called 'Safe Superintelligence' (SSI) or 'SSAI' has attracted massive investments from top venture capital firms like Sequoia Capital and Andreessen Horowitz, increasing its market value from $5 billion to $30 billion in just six months. Despite its rapid growth, the company remains shrouded in secrecy, with its official website containing only a single page with 220 words and relying heavily on traditional recruitment methods through direct interviews and referrals. The founder, Ilya Sutskever, who was one of the key minds behind the development of 'Chat GPT', left OpenAI in 2023 after tensions arose and decided to focus on developing a new type of AI that is completely safe and serves humanity. Through SSI, he aims to develop a superintelligent AI that can develop self-awareness and emotions, while ensuring it is friendly to humans rather than a threat. Unlike the prevailing trend in the AI industry, where many companies are trying to develop 'Artificial General Intelligence' (AGI) that resembles human intelligence, SSI is focused on creating a superintelligent AI that surpasses human capabilities. This idea is intriguing but raises many questions about how to develop such AI, particularly in terms of controlling it and ensuring its goals align with human interests. Interestingly, SSI prioritizes privacy and security, requiring employees to deposit their phones in a 'Faraday' box to block Wi-Fi and cellular signals, ensuring the secrecy of the information handled within the company. So far, SSI has not launched any product for public use, and it does not seem to be in a hurry to do so. Instead, the company is focused on developing its AI in a secure and safe environment, with undisclosed plans to launch any commercial product in the near future.
Original language: ar
Publish date: March 12, 2025 09:00 PM
Source:[freeposts.net](https://freeposts.net/archives/116032)

**The Rise of Superintelligence: A New Era for the Economy**
A recent note, 'Superintelligence Strategy', has warned of the potential consequences of a superintelligence or AGI (artificial general intelligence) takeover. The authors, Eric Schmidt, Alexandr Wang, and Dan Hendrycks, predict that AGI will arrive within 24-36 months, driven by the laws of scale, which suggest that increased computing power, data, and model complexity will lead to greater AI progress. The note's authors argue that the development of AGI will have significant economic and societal implications, including the potential for job displacement and a shift towards an economy of abundance. They also suggest that governments and investors are already preparing for this shift, with the US government, for example, planning to develop strategies to mitigate the risks of AGI. The authors conclude that measuring the capacity of AGI to innovate is crucial, as it could either accelerate technological progress and improve material satisfaction with fewer resources, or lead to a significant shift in societal structures.
Original language: fr
Publish date: March 09, 2025 07:36 AM
Source:[LExpress.fr](https://www.lexpress.fr/economie/high-tech/lintelligence-artificielle-generale-moteur-dune-nouvelle-ere-economique-KJ2TODGOPVHUHI67Y62OSEAJIE/)

