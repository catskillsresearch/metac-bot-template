Here are the relevant news articles:

**How lawmakers are regulating real-world AI in 2025**
Lawmakers are struggling to regulate artificial intelligence due to the rapid pace of technological advancements. Pennsylvania state Rep. Napoleon J. Nelson emphasized the need for lawmakers to 'get it right' rather than 'chase headlines' and to craft 'reactive' legislation to the tech. Wilmington Councilmember James Spadola suggested letting the market handle the tech and dealing with negative ramifications later. Companies are setting their own guardrails in the absence of formal regulation, according to John Hopkins-Gillespie, director of policy at Trustible AI. The panelists agreed on the need for stronger collaboration between tech companies, policymakers, and communities, including education and relationship-building between constituents and elected officials. AI regulation is a waiting game, with the policy bottleneck being political rather than technical.
Original language: en
Publish date: June 02, 2025 10:30 AM
Source:[Technical.ly](https://technical.ly/civic-news/ai-regulation-lawmakers-builders-2025/)

**The Environmental Impact of AI-Generated Images: A Hidden Cost**
The use of artificial intelligence (AI) to generate images, such as those inspired by Studio Ghibli, has a significant environmental impact. The generation of these images requires large amounts of water to cool the data centers that process these requests. According to a study by the University of Colorado Riverside and the University of Texas Arlington, each image generated by AI can consume between 2 and 5 liters of water. This consumption, although invisible to the end user, represents a significant load on water resources, especially in regions with water crises. To generate an image in the style of Ghibli, approximately 3.45 liters of water is required, equivalent to 17 glasses of drinking water. The impact of the rise of Ghibli-style images According to data from the MIT Technology Review, the water consumption of data centers has increased by 30% in the last five years due to the popularity of AI models. The combination of a growing demand and a lack of specific regulations on water consumption in the technology industry poses serious environmental challenges that must be addressed immediately. Sustainable alternatives to reduce the impact Image made in ChatGPT. Image made for previous news. No new resource was consumed. In 2024, the US Environmental Protection Agency (EPA) proposed regulations to regulate water consumption in data centers. Companies like Google and Microsoft have also announced commitments to improve the efficiency of their facilities and reduce their water footprint by 30% by 2030. Responsible use of AI: recommendations for users According to a report by the United Nations, the technology sector must work together with governments to develop regulations that balance innovation with environmental protection. The dialogue between companies, scientists, and politicians will be key to ensuring that AI continues to evolve without compromising natural resources. The future of AI and sustainability Regulation and innovation will play a crucial role in the sustainability of AI. Initiatives like the 'AI for Good' of the UN aim to promote the responsible development of these technologies, ensuring that their growth does not compromise the ecological balance. 
Original language: es
Publish date: June 02, 2025 10:21 AM
Source:[datamarca.com](https://datamarca.com/2025/04/cuanta-agua-consume-la-ia-al-generar-imagenes-estilo-ghibli-con-chatgpt/)

**Global AI Model Risk Management Market Analysis 2025-2030: Growth Drivers, Challenges, And Opportunities**
The AI Model Risk Management Market Report by The Business Research Company forecasts the market size to reach $12.96 billion by 2029, with a compound annual growth rate (CAGR) of 16.0%. The market is driven by factors such as increased regulatory scrutiny, intensified oversight by executive boards, and the growing awareness of cyber security threats. The report highlights the importance of AI model risk management in dealing with cybersecurity threats, citing the example of the UK Department for Digital, Culture, Media, and Sport's report that 39% of UK businesses fell victim to a cyber-attack in the previous year. The report also mentions the top competitors in the AI model risk management market, including Amazon.com Inc., Google LLC, and Microsoft Corporation. The report emphasizes the creation of cutting-edge solutions, such as sophisticated AI models, to secure a competitive advantage. For example, Zendata introduced an enhanced AI model and data usage scanning platform in July 2024. The report also covers the regions becoming hubs for AI model risk management market innovation, with North America being the largest region in 2024 and Asia-Pacific expected to be the fastest-growing region in the forecast period.
Original language: en
Publish date: June 02, 2025 09:46 AM
Source:[openPR.com - Open Public Relations Free of Charge](https://www.openpr.com/news/4046555/global-ai-model-risk-management-market-analysis-2025-2030)

**Public Comment on CCPA Updates, Cyber, Risk, ADMT, and Insurance Regulations**
The U.S. Chamber of Commerce has submitted comments on the California Privacy Protection Agency's (CPPA) proposed rulemaking on CCPA updates, cyber, risk, ADMT, and insurance regulations. The Chamber supports privacy protections but is concerned that the Proposed Rules exceed the CPPA's statutory authority and will harm economic growth and innovation. The Chamber recommends discussions to ensure alignment between proposed state AI legislation and this rulemaking, and suggests striking certain language related to risk assessments and ADMT. The Chamber also expresses concerns about the scope of ADMT regulation, notification requirements, and pre-use notice requirements, and recommends clarifying certain definitions and providing a longer compliance timeline.
Original language: en
Publish date: June 02, 2025 01:57 AM
Source:[U.S. Chamber of Commerce](https://www.uschamber.com/technology/public-comment-on-ccpa-updates-cyber-risk-admt-and-insurance-regulations)

**Elon Musk Pushes for Autonomous Vehicle Legislation in the US**
Despite stepping down as a presidential advisor to Donald Trump and head of the 'Department of Government Efficiency', Elon Musk is still a major player in Washington's decision-making circles. According to a report by Bloomberg, citing informed sources, Musk is directly communicating with several members of the US Congress to push for legislation related to autonomous vehicles. Musk's efforts are focused on supporting the 'Autonomous Vehicle Acceleration Act' bill, which aims to pave the way for widespread use of self-driving cars in the US by removing current legislative and regulatory barriers. Musk has bet heavily on Tesla's future through the development of artificial intelligence, robots, and autonomous vehicles. He has linked the company's market value to its ability to reach commercial maturity in this field. Tesla is expected to launch a small, local robotaxi service in Austin, Texas, in July, using 'geofencing' technology that restricts the vehicle's movement within a specific area. The company also has a future plan to produce fully electric, self-driving cars called Cybercabs, which will not have a steering wheel or pedals. However, these ambitious plans are hindered by the lack of a clear federal regulatory framework in the US that allows for the widespread use of this type of vehicle. Data from the National Highway Traffic Safety Administration (NHTSA) shows that 80% of accidents related to autonomous vehicles have been caused by unexpected human intervention or software glitches, highlighting the need for flexible yet strict regulation. McKinsey & Company estimates that the autonomous vehicle market could reach over $300 billion by 2035, and is expected to revolutionize transportation, logistics, and urban mobility. This could put the US at a disadvantage compared to countries like China and South Korea, which have made significant strides in developing regulatory frameworks and testing these technologies. Musk believes that delaying federal legislation could put the US at a loss of global leadership and affect Tesla's chances of dominating the future competitive market.
Original language: ar
Publish date: June 01, 2025 07:44 AM
Source:[Alghad](https://alghad.com/story/2021945)

**1 Million AI Professionals Required By 2026 In India ! Aims For $35 Trillion Economy : Report**
According to a government-backed report, India is expected to require one million Artificial Intelligence (AI) professionals by 2026. This surge is driven by a 50% growth in AI-related disciplines such as Machine Learning, Data Science, Cybersecurity, Cloud Computing, and Blockchain. The report highlights AI's central role in India's goal of becoming a $35 trillion economy by 2047, with engineering education rapidly transforming to meet industry demand.
Original language: en
Publish date: June 01, 2025 05:32 AM
Source:[TimesNow](https://www.timesnownews.com/business-economy/industry/1-million-ai-professionals-required-by-2026-in-india-aims-for-35-trillion-economy-report-article-151766358)

**The Double-Edged Sword of AI in Cybersecurity: Experts Weigh In at Forum InCyber 2024**
Experts from various cybersecurity companies gathered at the Forum InCyber 2024 to discuss the impact of Artificial Intelligence (AI) on the industry. Benoit Grunemwald, ESET, stated that AI is a double-edged sword that multiplies the capabilities of both attackers and defenders. The panelists emphasized the importance of adopting a holistic approach to cybersecurity, integrating AI into their strategies, and prioritizing prevention over reaction. They also highlighted the need for education and awareness among employees, the importance of data observability, and the role of AI in simplifying and enhancing cybersecurity actions. Additionally, they discussed the challenges posed by the increasing sophistication of cyber threats and the need for a proactive defense strategy. The experts agreed that the future of cybersecurity will be shaped by the integration of AI, machine learning, and human expertise.
Original language: fr
Publish date: June 01, 2025 12:00 AM
Source:[globalsecuritymag.fr](https://www.globalsecuritymag.fr/benoit-grunemwald-eset-la-composante-ia-est-une-lame-a-double-tranchant-qui.html)

**ChatGPT, China, and the Global Battle for AI Dominance**
China's AI development has been rapidly advancing, with the country surpassing the United States in the sheer volume of AI research publications. Chinese researchers published over 155,000 AI papers in 2022, far more than the U.S. (81,000) or all EU countries combined (101,000). China now accounts for nearly 40% of global AI research publications. However, China's AI sector remains critically dependent on foreign technology in key domains, such as advanced semiconductor chips and equipment required to train and run cutting-edge AI models. The U.S. has increasingly turned to technological sanctions to slow China's progress by cutting off its access to the highest-end AI hardware. The U.S. has progressively tightened export controls to restrict China's access to semiconductors, AI software, and the equipment used to manufacture them. China's leaders view AI as vital to the nation's future and are investing heavily to become a global leader in the field. Grand national strategies back China's ambitions in AI, with the goal of becoming the world leader in AI by 2030. However, the social impacts of AI depend heavily on its application, and authoritarian implementations of AI, such as invasive mass surveillance, raise significant international concerns. The U.S. and other leading tech powers must work closely to develop standard rules and norms that restrict the hostile or dangerous use of advanced technologies, pushing for a governance regime that enshrines principles of human oversight, transparency, and accountability in the cyberspace.
Original language: en
Publish date: May 26, 2025 12:00 AM
Source:[theowp.org](https://theowp.org/reports/chatgpt-china-and-the-global-battle-for-ai-dominance/)

**House Republicans Introduce Bill to Block State AI Rules Until 2035, Intensifying Partisan Divide Over Regulation - Tekedia**
House Republicans have introduced a bill that would block state AI rules until 2035, sparking a partisan divide over regulation. The bill, added to a proposed federal budget bill, would prohibit states from enacting or enforcing laws that regulate AI systems or automated decision-making technologies, unless they facilitate deployment or operation. This would invalidate state-level laws aimed at curbing algorithmic bias and discrimination, and prevent states from introducing new rules until at least 2035. Supporters, mostly Republicans, argue that federal preemption is necessary to ensure a consistent, business-friendly national approach that allows tech firms to innovate without being slowed down by state legislation. However, Democrats have pushed for stronger consumer protections, transparency, and bias mitigation mechanisms, and several states have already moved to impose guardrails. If the bill passes, it would create a regulatory void at a time when AI is increasingly embedded in housing, hiring, healthcare, and policing decisions. Elon Musk has criticized what he calls 'left-wing bias' in AI models, accusing OpenAI's ChatGPT and Google's Gemini of being 'woke' and serving a 'leftist agenda.' Democrats argue that AI systems can replicate and amplify societal biases unless regulators step in. The battle is far from over, as the measure could run into resistance in the Senate, where Democrats hold a slim majority.
Original language: en
Publish date: May 19, 2025 02:32 PM
Source:[tekedia.com](https://www.tekedia.com/house-republicans-introduce-bill-to-block-state-ai-rules-until-2035-intensifying-partisan-divide-over-regulation/)

**Italy Needs to Close the AI Gap with the US**
The gap between the EU and the US in Artificial Intelligence (AI) is not due to a lack of skills, but rather due to different regulatory and business structures, according to Antonio Calegari, director of the Ai4Industry institute. At the Stati Generali dell'Innovazione 2025 event in Parma, Calegari emphasized the need for Italy to move quickly to take advantage of the AI revolution, which is producing rapid and widespread changes. To achieve this, the country needs to focus on education, with the goal of becoming a university oriented towards AI and cybersecurity by 2030, as explained by Silvana Castano, pro-rector of the State University of Milan. Maria Laura Cosimi, vice president of Rete ITS Italy, added that 70% of jobs in the EU will require advanced digital skills in the near future. Giuseppe Mayer, CEO of Talent Garden Italia, noted that many companies have started the AI adoption process but are getting stuck, and that the key to overcoming this hurdle is education and understanding how AI can be applied within their businesses. 'Fino a 3 anni fa l'AI non si capiva bene cosa fosse, poi è subentrata la paura, adesso siamo nella fase del purgatorio' ('Until 3 years ago, AI was not well understood, then fear took over, now we are in the purgatory phase'), Mayer said. 'Quel che serve per superare il limbo è proprio la formazione. Concentrandoci su un concetto: cosa può fare questa tecnologia, in continua evoluzione, dentro la mia azienda?' ('What is needed to overcome the limbo is precisely education. Focusing on a concept: what can this technology, in continuous evolution, do within my company?').
Original language: it
Publish date: May 13, 2025 01:40 PM
Source:[Il Sole 24 ORE](https://www.ilsole24ore.com/art/intelligenza-artificiale-imprese-servono-piu-professionisti-AHHnEnj)

**OpenAI CEO Sam Altman and other U.S. tech leaders testify to Congress on AI competition with China**
OpenAI CEO Sam Altman and executives from Microsoft and AMD testified before Congress about the opportunities and risks of artificial intelligence. Altman stated that AI has the potential to be 'at least as big as the internet, maybe bigger' and urged lawmakers to invest in infrastructure to support its development. The witnesses unanimously called for streamlined policy for AI-related projects and fundraising. Senators expressed concerns over cybersecurity, data privacy, and AI's ability to create misleading content. Altman warned against export controls that could push other countries towards China's AI technology, saying that the US needs to have its technology adopted globally to maintain its influence. He also cautioned against a patchwork regulatory framework for AI, advocating for a single, light-touch federal framework. The hearing highlighted the trade rivalry between the US and China, with the US imposing export controls on AI chips and China aiming to lead the world in AI by 2030.
Original language: en
Publish date: May 09, 2025 03:26 AM
Source:[The Hindu](https://www.thehindu.com/sci-tech/technology/openai-ceo-sam-altman-and-other-us-tech-leaders-testify-to-congress-on-ai-competition-with-china/article69555902.ece)

**US lawmakers fear AI data centres will drive up residents' power bills**
US lawmakers are concerned that the growing demand for data centres, driven by artificial intelligence, will lead to increased electricity costs for residents. New Jersey state Sen. Bob Smith has authored a bill that would require new AI data centres to use clean energy sources, while other states are considering similar measures to prevent the costs of generating electricity for data centres from being spread to household customers. Industry leaders argue that data centres are crucial for the digital society and create tax revenue and jobs, but some lawmakers are concerned that the immense energy demands they create will derail climate goals and drive up utility bills. A study in Virginia found that unconstrained demand from data centres would drive up energy usage 183% by 2040, while a new rule in Georgia requires data centres to cover the costs of serving them. Consumer advocates say more states should rescind their incentives for data centres, as many don't bring in enough tax revenue to cover their tax breaks. 'You get good and bad with the data centres, but I just want to make sure they pay their way,' said Georgia state Sen. Chuck Hufstetler.
Original language: en
Publish date: April 17, 2025 09:02 AM
Source:[The Star ](https://www.thestar.com.my/tech/tech-news/2025/04/17/us-lawmakers-fear-ai-data-centres-will-drive-up-residents-power-bills)

**Technology & Digital round-up: April 2025**
The latest edition of the Technology & Digital round-up discusses the ICO's measures to drive economic growth, new data legislation, and significant guidance on migrating to post-quantum cryptography. The ICO has introduced a statutory code of practice for AI and new guidance on international data transfers. The Data (Use and Access) Bill is expected to pass in the coming weeks, removing the general restriction on automated decision-making with a legal or similarly significant effect. However, this has raised concerns about the UK's data adequacy status. The UK's National Cyber Security Centre has unveiled a roadmap for organisations to migrate to post-quantum cryptography by 2035, setting out a three-phase timeline for transition. Luke Jackson, Director, Commercial, notes, 'In this edition of the Technology & Digital round-up we look at the ICO's measures to drive economic growth, imminent new data legislation and significant guidance on migrating to post-quantum cryptography.' 
Original language: en
Publish date: April 02, 2025 06:38 AM
Source:[Lexology](https://www.lexology.com/library/detail.aspx?g=b2dc6b62-e7b4-465a-ba17-e0de08e40457)

**Proskauer on Privacy: 2024 Reflections & 2025 Predictions**
2024 was a significant year for privacy law, with new state legislation and high-stakes litigation reshaping the landscape. Despite attempts to pass comprehensive federal privacy legislation, the American Privacy Rights Act (APRA) did not pass the 118th Congress. The Federal Trade Commission (FTC) prioritized safeguarding sensitive data, focusing on location tracking, health data, children's privacy, and cybersecurity. The FTC secured key settlements, banning the sale of sensitive location data without consent or deidentification, and filed a Children's Online Privacy Protection Act (COPPA) action against TikTok. State-level enforcement also intensified, with California, Texas, and New Hampshire leading major efforts. In 2025, several state privacy laws have recently gone into effect, and more are set to take effect later in the year. Businesses can expect heightened scrutiny on algorithmic transparency, biometric protections, and generative AI. Companies in health, finance, and technology should remain vigilant as regulators push for stricter accountability. Compliance challenges and rising operational costs are likely, but organizations that proactively audit data-sharing practices, update privacy policies, and ensure AI compliance will be equipped to navigate the evolving regulatory landscape and reduce overall legal risks.
Original language: en
Publish date: March 17, 2025 12:00 AM
Source:[The National Law Review - A Free To Use Nationwide Database of Legal Publications](https://natlawreview.com/article/proskauer-privacy-2024-reflections-2025-predictions)

**Proposed HIPAA Security Rule Requires AI Governance**
In 2024, the U.S. experienced the worst year for healthcare data breaches, with 53% of the population's records involved. To combat this, the Department of Health and Human Services (HHS) issued a Notice of Proposed Rulemaking (NPRM) to modify the HIPAA Security Rule, which includes addressing artificial intelligence (AI) systems for the first time. The proposed modifications aim to better protect electronic protected health information (ePHI) and ensure AI systems properly secure ePHI. Regulated entities can prepare for compliance by implementing a robust AI governance program, which includes managing AI risks, securing ePHI in AI training data, prediction models, and algorithm data, and addressing 'offensive AI' threats. 'The growth of AI has led to the concern of mass-scale cyberattacks,' said HHS, 'and it is crucial for regulated entities to consider how AI will use and maintain ePHI to ensure it is being properly secured.'
Original language: en
Publish date: March 12, 2025 05:19 PM
Source:[JD Supra](https://www.jdsupra.com/legalnews/proposed-hipaa-security-rule-requires-4379606/)

**The BR Privacy & Security Download: March 2025**
Several updates on AI and data privacy laws have been made in the US and EU. In the US, the Virginia legislature passed the High-Risk Artificial Intelligence Developer and Deployer Act, which requires developers to use reasonable care to prevent algorithmic discrimination and provide detailed documentation on an AI system's purpose, limitations, and risk mitigation measures. The Connecticut Senate introduced a bill to establish regulations for the development, integration, and deployment of high-risk AI systems. New York Governor Kathy Hochul signed several bills expanding compliance obligations for social media platforms, debt collectors, and dating applications. California reintroduced a bill requiring browsers and mobile operating systems to provide a setting that enables a consumer to send an opt-out preference signal to businesses with which the consumer interacts. In the EU, the first EU AI Act provisions became effective, prohibiting certain types of AI systems deemed to pose an unacceptable risk and rules on AI literacy. A coalition of business groups opposed the proposed updates to the HIPAA Security Rule, arguing that it would impose great financial burdens on the healthcare sector. Amazon is facing a class action lawsuit alleging violations of Washington's My Health My Data Act. NetChoice filed a complaint in federal court in Maryland challenging the Maryland Age-Appropriate Design Code Act as violating the First Amendment. Kochava settled a class action lawsuit alleging it collected and sold precise geolocation data of consumers without their consent. The US District Court for the Western District of Texas granted a preliminary injunction blocking enforcement of Texas' Securing Children Online through Parental Empowerment Act. The California Attorney General agreed to narrow the enforcement of certain parts of AB 587, a social media law. Arkansas Attorney General Tim Griffin sued General Motors and its subsidiary OnStar for allegedly deceiving Arkansans and selling data collected through OnStar from more than 100,000 Arkansas drivers' vehicles to third parties. Health Net and its parent company, Centene Corp., settled with the United States Department of Justice for allegations that Health Net falsely certified compliance with cybersecurity requirements under a U.S. Department of Defense contract. Warby Parker was fined $1.5 million for HIPAA violations. The California Privacy Protection Agency announced that it is seeking a $46,000 penalty against Jerico Pictures, Inc. for allegedly failing to register and pay an annual fee as required by the California Delete Act.
Original language: en
Publish date: March 06, 2025 07:45 PM
Source:[JD Supra](https://www.jdsupra.com/legalnews/the-br-privacy-security-download-march-1996675/)

**Life Science - New Technology-Focused Regulations Affecting 2025 and Beyond**
The life science sector is facing significant changes with the introduction of new technology-focused regulations from 2025. Our experts at Lindahl have analyzed the upcoming requirements for cybersecurity, AI systems, and e-health data, affecting everything from research companies to medical device manufacturers. Here is an overview of the most important regulations and their implications for the industry. The Cybersecurity Act (NIS 2 Directive) will require medium-sized and larger companies to implement new cybersecurity measures, including increased responsibility for the board of directors. The Swedish Cybersecurity Act is expected to be implemented in the third quarter of 2025. The Data Act will impose extensive requirements on connected products and services, including design and manufacturing of products, as well as availability of product data. The AI Regulation will require AI systems that are or are part of medical devices, including in-vitro products, to meet extensive requirements, particularly for high-risk systems. The Cyber Resilience Act will require cybersecurity measures for software or hardware products with digital elements, excluding medical devices. The e-Health Data Regulation will introduce new rules for primary and secondary use of e-health data, including access and control of e-health data in the healthcare sector, and create opportunities for secondary use of health data for research, health apps, and electronic patient records. The regulations will come into effect successively from 2025-02-01 to 2027-08-01, 2027-12-11, and 2027-2037, respectively.
Original language: sv
Publish date: February 26, 2025 12:00 AM
Source:[lexology.com](https://www.lexology.com/library/detail.aspx?g=e87ee6e3-fc9c-4975-ab21-66b378ffc9b1)

