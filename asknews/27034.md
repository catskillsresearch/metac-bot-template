Here are the relevant news articles:

**Meta-Aussteigerin Alexis Crews: When America Fails, Europe Must Step In**
The US is currently debating a law that could exempt AI from any government control. This moment is a strategic turning point for European politics, as it presents an opportunity for the EU to collaborate with the US to regulate AI and ensure that essential guidelines remain in place, even if American government agencies and institutions fail. As the article states, 'the world cannot afford to wait a decade while the US develops unregulated AI technology.'
Original language: de
Publish date: June 02, 2025 11:52 AM
Source:[Süddeutsche Zeitung](https://www.sueddeutsche.de/kultur/europa-ki-regulierung-zusammenarbeit-usa-alexis-crews-li.3261398)

**How lawmakers are regulating real-world AI in 2025**
Lawmakers are struggling to regulate artificial intelligence due to the rapid pace of technological advancements. Pennsylvania state Rep. Napoleon J. Nelson emphasized the need for lawmakers to 'get it right' rather than 'chase headlines' and to craft 'reactive' legislation to the tech. Wilmington Councilmember James Spadola suggested letting the market handle the tech and dealing with negative ramifications later. Companies are setting their own guardrails in the absence of formal regulation, according to John Hopkins-Gillespie, director of policy at Trustible AI. The panelists agreed on the need for stronger collaboration between tech companies, policymakers, and communities, including education and relationship-building between constituents and elected officials. AI regulation is a waiting game, with the policy bottleneck being political rather than technical.
Original language: en
Publish date: June 02, 2025 10:30 AM
Source:[Technical.ly](https://technical.ly/civic-news/ai-regulation-lawmakers-builders-2025/)

**Why AI 'Brains' Can't Succeed Without Blockchain Wallets**
The integration of blockchain-enabled smart contracts and AI 'brains' is poised to revolutionize the way we conduct business. With the ability to read contract code, reason about changing market conditions, and rewrite or trigger clauses in real time, the promise of 'automated legal trust' becomes a reality. Early pilots on Ethereum L2s, Fetch.ai side-chains, and zero-knowledge rails are already letting AI agents renegotiate freight rates and energy swaps in real time. However, the new internet requires a payment system that can handle micro-units of dollars, which is where blockchain-native dollars come in. These regulated, 1:1-backed stablecoins can be subdivided into 10-18 decimal places at near-zero marginal cost, allowing for fast and efficient transactions. The US may finally be ready to treat digital asset transactions less like tradable securities and more like digital commodities, with the House's newly introduced Digital Asset Market Clarity Act splitting oversight between the CFTC and the SEC. If enacted, this legislation will align US policy with the EU's MiCA and Japan's updated Payment Services Act, reducing the patchwork friction that pushed innovators offshore.
Original language: en
Publish date: June 01, 2025 04:12 PM
Source:[Medium.com](https://medium.com/lansaar/why-ai-brains-can-t-succeed-without-blockchain-wallets-ab6e591ee663)

**AI Evolution Spurs Urgent Calls to Regulate Killer Robots**
The use of AI-driven drones in warfare is raising deep ethical questions about autonomy in combat. The UN and non-governmental organisations are calling for international regulation of Lethal Autonomous Weapons (LAWS) to avoid a near-future where machines dictate life-and-death choices. Human Rights Watch has expressed concerns about 'digital dehumanisation,' where AI makes life-altering decisions on matters affecting humans. Advocates for AI-driven warfare argue that machines can improve every day at identifying threats, but critics point to the technology's flaws and biases. Nicole Van Rooijen, Executive Director of Stop Killer Robots, says that the use of LAWS would make it difficult to ascertain responsibility for war crimes and other atrocities. The UN is optimistic that the international community is inching towards a common understanding on key issues, with at least 120 countries supporting the call to negotiate a new international law on autonomous weapons systems. 'When it comes to war, someone has to be held accountable,' says Ms. Nakamitsu from the UN Office for Disarmament Affairs.
Original language: en
Publish date: June 01, 2025 03:10 PM
Source:[miragenews.com](https://www.miragenews.com/ai-evolution-spurs-urgent-calls-to-regulate-1470161/)

**Meta's chief AI scientist says all countries should contribute data to a shared open-source AI model**
Meta's chief AI scientist, Yann LeCun, advocates for a shared open-source AI model where countries contribute data from their own data centers. This would create a repository of human knowledge, larger than what any one entity can handle. LeCun emphasizes that countries must ensure they are not 'impeding open source platforms' and instead favor them. OpenAI CEO Sam Altman also stresses the need for international regulation of frontier AI systems, which he believes could cause significant global harm. Altman suggests an international agency should oversee the most powerful systems and ensure reasonable safety testing.
Original language: en
Publish date: May 31, 2025 09:40 PM
Source:[Business Insider](https://www.businessinsider.com/meta-yann-lecun-shared-open-source-ai-model-2025-5)

**Brazilian Experts Warn Congress about AI's Environmental and Technological Impasse**
Experts have warned the Brazilian Congress about the environmental and technological impasse caused by the rapid growth of artificial intelligence (AI). The development and research of AI consume a lot of energy, and experts believe that the regulation of data centers will contribute to the development of the economy and the advancement of AI in all sectors. Brazil has the potential to become a leader in the field of AI, but it needs to address the challenges of energy consumption, cybersecurity, and data protection. The proposed law (PL 3.018/2024) aims to establish norms for the operation of AI data centers, focusing on energy efficiency, environmental sustainability, and responsible use of technology. Experts believe that the regulation of data centers will create jobs, stimulate innovation, and attract foreign investment. They also emphasize the importance of using renewable energy sources, such as wind and solar power, to power data centers. According to Elbia Gannoum, president of the Brazilian Wind Energy Association, for every R$ 1 invested in wind energy in Brazil, the country's GDP increases by R$ 3. The experts also highlighted the importance of data protection and cybersecurity, citing the need for a stable and clear regulatory framework to ensure the security of data and the protection of individuals' rights. The proposed law aims to address these challenges and promote the development of AI in Brazil.
Original language: pt
Publish date: May 30, 2025 10:29 PM
Source:[lapadalapada.com.br](https://lapadalapada.com.br/2025/05/30/especialistas-alertam-congresso-sobre-impasse-ambiental-com-avanco-da-ia/)

**Rep. Beyer Hopeful About the Future of AI Regulation**
Rep. Don Beyer, D-Va., is hopeful that the 119th Congress will pass meaningful AI legislation despite the slow start. He points to the House AI Task Force's comprehensive report, which outlined a proposed Federal regulatory framework for AI and made over 60 key findings and more than 80 recommendations. Rep. Beyer said, 'The hope was that we built a base, a foundation, that future Congresses could build upon.' He also mentioned that some 'wildly bipartisan' pieces of legislation, such as the Creating Resources for Every American To Experiment with AI Act (CREATE AI Act), have been reintroduced and are awaiting committee review. Rep. Beyer, who is pursuing a master's degree in machine learning at George Mason University, believes that a subset of about 30 House lawmakers 'dive deep on AI' and can help craft legislation, while the rest of the Congress can build upon their work.
Original language: en
Publish date: May 28, 2025 12:00 AM
Source:[meritalk.com](https://meritalk.com/articles/rep-beyer-hopeful-about-the-future-of-ai-regulation/)

**IP Rights and the Wild West Landscape of AI | IPWatchdog**
Allison Gaul, an expert in IP rights, discussed the challenges of regulating AI development in a rapidly changing landscape. She identified three key areas of concern: data control, open source, and the speed of AI development. Gaul emphasized the importance of data ownership and use rights, citing the need for clear regulations to protect users' data. She also noted the proliferation of companies releasing AI models as open source, but not providing the necessary training data or weights. Gaul predicted that as larger AI companies face increasing scrutiny, users will turn to smaller, specialized tools that operate within specific niches. This shift, she believes, will alleviate some of the challenges in managing licensing and attribution for different types of assets. Gaul also discussed fair use and the importance of ethics in AI development and use, including the need for AI companies to provide better guidance on prompting AI tools. 
Original language: en
Publish date: May 19, 2025 02:07 PM
Source:[ipwatchdog.com](https://ipwatchdog.com/2025/05/19/ip-rights-wild-west-ai/id=188973/)

**US Reorients AI Strategy to Counter China, Prioritizing Innovation Over Regulation**
The US has reoriented its strategy towards artificial intelligence (AI), shifting from focusing on regulating risks to leading a technological race against China. This change in approach began in May 2025, with the US government prioritizing innovation over regulation. The new strategy aims to maintain US leadership in AI through increased investments in infrastructure, energy, and exports, as well as fewer regulatory restrictions. This reorientation is crucial for several reasons, including economic advantage, national security, technological innovation, and global influence. If the US does not prioritize this technological race, it could lead to severe consequences, including loss of economic leadership, security risks, talent flight, and technological dependence. The current moment for this reorientation is driven by Chinese advancements, political changes, and pressure from businesses. The reorientation involves multiple actors, including the US government, tech companies, the private sector, academia, and international allies. The advantages of this new strategy include accelerated innovation, economic growth, strategic advantage, and talent attraction, but also pose risks such as ethical concerns, global polarization, inequality, and environmental impact. Mexico could benefit from this new strategy, with opportunities for growth in the semiconductor industry, attracting foreign investment, and strengthening its AI ecosystem. However, there are also challenges and risks, including dependence on Chinese technology, regulatory hurdles, and commercial tensions. Ultimately, the US must balance speed with responsibility, investing in education, ethical regulation, and international collaboration to make this strategy successful.
Original language: es
Publish date: May 15, 2025 12:17 PM
Source:[ruizhealytimes.com](https://ruizhealytimes.com/ciencia-y-tecnologia/ee-uu-reorienta-su-estrategia-de-ia-la-carrera-geopolitica-contra-china/)

**Sam Altman's Shift: From Advocating Regulation to Warning Against It**
Sam Altman, the CEO of OpenAI, has changed his stance on regulating AI. In 2023, he recommended creating an agency to license AI technology for safety, but now he says that requiring government approval for powerful AI software would be 'catastrophic' for the US's leadership in AI development. The Washington Post notes that the previous warnings about AI posing an 'existential risk' to humanity and calls for rapid, preemptive regulation of the new technology have been replaced by a consensus among leading companies and officials in the new Trump administration that the US should give companies complete freedom to develop AI quickly, allowing them to benefit from it and maintain the country's advantage over China. 'To lead in AI, the United States cannot allow regulation, even supposedly beneficial, to strangle innovation and implementation,' said Senator Ted Cruz, chairman of the Senate Committee on Commerce, Science, and Transportation, at the beginning of the hearings in the US Congress. The Paris AI Summit, held this year, showed a clear change in attitude towards AI regulation among governments and the tech industry. The final communique of the summit called on countries and companies to accelerate the development of more intelligent AI, without emphasizing any risks. Vice President JD Vance criticized attempts to regulate the technology. 'We believe that excessive regulation of the AI sector can kill the transformative industry at its inception, and we will do everything to promote AI policies that promote growth,' Vance said. 'The future of AI will not be achieved at the expense of hand-wringing about safety.' Max Tegmark, a professor of AI at MIT and president of the Future of Life Institute, a non-profit organization that studies the potential risk of superintelligent AI, criticized the lack of AI regulation in the United States. 'Even a sandwich shop across the street from OpenAI or Anthropic, or another company, must ensure compliance with safety standards for their kitchen before selling even one sandwich,' Tegmark said. 'But if [AI companies] want to release superintelligence tomorrow, they are free to do so.'
Original language: ru
Publish date: May 09, 2025 11:46 AM
Source:[3DNews - Daily Digital Digest](https://3dnews.ru/1122566/sem-altman-pereobulsya-i-teper-utvergdaet-chto-gosregulirovanie-ii-postavit-krest-na-liderstve-ssha)

**AI execs used to beg for regulation. Not anymore.**
The tech industry's attitude towards AI regulation has undergone a significant shift. OpenAI CEO Sam Altman, who previously advocated for regulation, now warns that requiring government approval to release powerful AI software would be 'disastrous' for the US. This change in tone is reflected in the new Trump administration's stance on AI, which prioritizes freeing companies to move faster and reap economic benefits. Critics warn that AI technology is causing harms to individuals and society, and that the industry's approach has enabled a 'bait and switch' where executives pitch regulation around concepts like self-replicating AI while stoking fears of national security concerns. Researchers continue to research potential risks of AI, hoping to push governments and companies to reengage with the idea of regulating the technology. 'If there's a sandwich shop across the street from OpenAI or Anthropic or one of the other companies, before they can sell even one sandwich they have to meet the safety standards for their kitchen,' said Max Tegmark, an AI professor at MIT. 'If [the AI companies] want to release super intelligence tomorrow they're free to do so.'
Original language: en
Publish date: May 08, 2025 09:38 PM
Source:[Washington Post](https://www.washingtonpost.com/technology/2025/05/08/altman-congress-openai-regulation/)

**US Tech Companies Warn of China's AI Advancements**
Major American technology companies have expressed concerns about the US losing its lead in artificial intelligence, as China rapidly closes the gap. OpenAI has warned that the Chinese government-backed 'DeepSeek R1' model could be used to influence the global development of AI, and that Chinese laws may force it to comply with government orders, posing a threat to US cybersecurity. The company has also announced new tools for creating AI agents, but faces challenges in launching its GPT-4.5 model due to a chip shortage. Baidu has launched two new models, 'Ernie X1' and 'Ernie 4.5', which are cheaper and more efficient than their Western counterparts. These prices put pressure on American companies, with Bernstein Research reporting that 'DeepSeek R1' and 'V3' are sold at prices 20-40 times lower than their American counterparts. Baidu has also adopted an 'open-source' strategy, allowing developers worldwide to use its software, which has contributed to its rapid spread. Investors and developers have already begun testing the new Chinese models, with investor 'Alvin Fu' describing their performance as 'impressive' after extensive testing. The US companies are concerned about the security and economic risks posed by China's AI advancements. OpenAI has warned that Chinese laws may be used to force 'DeepSeek' to perform cyber attacks or influence sensitive infrastructure. Anthropic has focused on the biological risks, suggesting that AI could be used to develop biological weapons. It has called for stricter controls on the export of AI chips, fearing that China could use them to enhance its progress. Google has taken a more cautious approach, acknowledging the security risks but warning that strict controls on AI technology exports could weaken American companies' ability to compete globally. The US companies agree that the government needs to invest heavily in infrastructure to keep up with the competition. Anthropic has warned that training a single advanced AI model could require the energy consumption of a small city by 2027, and has proposed building 50 gigawatts of dedicated AI power by 2027. OpenAI has described the competition with China as a 'battle between democratic and government-controlled AI', and has called for support for the free market to boost American superiority. Google has suggested increasing federal research funding and streamlining government contracts for companies working in the field. The companies have called for a unified federal government framework to regulate the AI sector, rather than a patchwork of state laws. OpenAI has proposed a system of control run by the US Department of Commerce, allowing the sale of AI technologies to democratic countries while imposing restrictions on authoritarian countries. Anthropic has called for stricter controls on the export of AI devices and training data to prevent China from gaining a strategic advantage. Google has emphasized the importance of protecting intellectual property rights, warning that strict controls on copyright could put American companies at a disadvantage compared to their Chinese competitors.
Original language: ar
Publish date: March 25, 2025 06:00 AM
Source:[elbalad.news](https://www.elbalad.news/6523789)

**China's AI Companies Release Powerful AI Models as Open-Source to Avoid US Regulations**
China's AI companies, such as DeepSeek, are releasing powerful AI models as open-source, which is seen as a way to avoid American regulations. According to the Financial Times, this move is not just about making AI more accessible, but also about bypassing American regulations and using the global talent pool to improve the models. By making AI models open-source, China's companies can avoid the restrictions imposed by the US government, which views open-source AI as a security risk. The US Congress has even proposed a bill to ban the use of DeepSeek's AI on government devices due to national security concerns. The Financial Times notes that this move by China's AI companies is a strategic response to the tightening of regulations in the US, particularly under the Trump administration, which has strengthened export controls on US chip and AI technology. By flooding the market with free AI models, China's companies aim to make the US's proprietary models less competitive. However, this approach also carries risks, as it may lead to a decline in revenue for Chinese companies. Additionally, the Chinese government may impose stricter regulations on AI to control misinformation and enforce national policies, which could limit the duration of this open-source approach.
Original language: ja
Publish date: March 23, 2025 10:00 PM
Source:[GIGAZINE](https://gigazine.net/news/20250324-why-china-flooding-powerful-ai/)

**Hugging Face submits open-source blueprint, challenging Big Tech in White House AI policy fight**
Hugging Face has submitted its recommendations for the White House AI Action Plan, arguing that open-source and collaborative AI development can be America's strongest competitive advantage. The company highlights recent breakthroughs in open-source models, such as OlympicCoder and OLMo 2, which outperform closed commercial systems at a fraction of the cost. Hugging Face's submission emphasizes the importance of democratizing AI technology, investing in research infrastructure, and supporting more efficient models that can run on limited resources. The company also argues that open and transparent AI systems may be more secure in critical applications. This approach stands in contrast to those from commercial AI leaders like OpenAI, which has lobbied for light-touch regulation and 'the freedom to innovate in the national interest.' 
Original language: en
Publish date: March 19, 2025 10:48 PM
Source:[VentureBeat](https://venturebeat.com/ai/hugging-face-submits-open-source-blueprint-challenging-big-tech-in-white-house-ai-policy-fight/)

**The AI Future Is Here**
The release of DeepSeek's open-source chatbot has democratized access to machine intelligence, allowing anyone with an idea and an internet connection to harness its power. This shift is likely to accelerate AI's integration into various aspects of life, from solving traffic snarls to rewriting scientific discovery rules. However, AI's limitations, such as its inability to achieve higher reasoning or memory, and its potential to replicate human biases, pose significant challenges. The industry must address its energy and water demands, and market regulation is crucial to ensure that technological innovation leads to societal well-being. As Nobel Prize-winning economist Joseph E. Stiglitz notes, 'it will be up to us to determine whether AI transforms human civilization for good or ill.' 
Original language: en
Publish date: March 04, 2025 02:08 PM
Source:[Scientific American](https://www.scientificamerican.com/article/the-ai-future-is-here/)

**Global Leaders Debate AI Regulation at Paris Summit**
Global leaders gathered at the Paris AI Summit to discuss new regulations for mitigating risks, ensuring equitable access, and promoting responsible development of AI technology. The competition between the US, China, and the EU emerged as a central theme of the meeting. French President Emmanuel Macron emphasized the importance of regulating AI without stifling innovation: 'The summit comes at a time when many are seeking to position themselves in the international competition. It's about setting the rules of the game. AI cannot be the Wild West,' he said. The differences in AI regulation between the US, China, and the EU became apparent, with Washington and Beijing opting for more flexible approaches, while the EU strengthened its regulatory framework with the 2024 AI Law, imposing strict requirements for development and commercialization. Macron warned about the risks of unbalanced regulation: 'There is a risk that some countries will decide not to have norms around AI and that's dangerous. But there is also a risk of being left behind if Europe imposes too many rules on itself. We should not be afraid of innovation,' he stressed. In contrast, US President Donald Trump pushed for a deregulation strategy, aiming to make the US the 'world capital of AI.' His administration revoked an executive order signed by Joe Biden in 2023, which required security tests before launching new AI models. China, on the other hand, is strengthening its presence in the sector, promoting more accessible AI models. The appearance of DeepSeek-R1, a low-cost Chinese AI model, raised concerns in the industry. Mario Krenn, director of the Max Planck Institute's Artificial Intelligence Laboratory, explained that 'an experiment that cost more than 300 pounds with OpenAI can now be done for less than 10 dollars. This is a drastic difference that will influence the future adoption of the Chinese algorithm.' The international debate continues, with divided opinions on how to balance innovation and security. Brian Chen, director of policy at Data & Society, warned that 'the most concerning thing is that there are pressures from various countries to weaken the few existing protections against AI threats in the world.'
Original language: es
Publish date: February 15, 2025 06:30 PM
Source:[mypress.mx](https://www.mypress.mx/tecnologia/lideres-globales-debaten-regulacion-de-la-ia-en-la-cumbre-de-paris-13978)

**US Resists EU Regulation of AI, Despite Growing Concerns**
The United States is the most advanced country in artificial intelligence, with a growing number of companies specializing in this technology. However, the US government is not interested in regulating AI, as stated by Vice President J.D. Vance, who attended the Paris AI Summit. The Trump administration has repealed the 2023 Executive Order that regulated AI, which required companies to report to the government on AI development and created a voluntary code of conduct. The US wants the EU to leave its AI companies alone, as stated by the Trump administration, which sees regulation as a threat to its leadership in the field. Meanwhile, major tech companies like Amazon, Google, and Microsoft are investing heavily in AI, with plans to spend over $320 billion in 2025 and the next few months.
Original language: es
Publish date: February 13, 2025 08:05 AM
Source:[Mundo Deportivo](https://www.mundodeportivo.com/urbantecno/tecnologia/el-trumpismo-continua-su-ofensiva-tecnologica-en-europa-el-nuevo-presidente-quiere-que-la-ue-deje-en-paz-a-sus-empresas)

**Regulation of Artificial Intelligence: A Patchwork of Laws Around the World**
The regulation of artificial intelligence (AI) is a patchwork of laws around the world, from the 'Wild West' of the US to the complex regulatory framework of the European Union. A tour of the main laws, ahead of the AI summit in Paris on February 10-11. In the US, Donald Trump canceled the security decree on AI taken by his predecessor Joe Biden in October 2023, which set certain safeguards. The decree required companies in the sector to transmit test results to the government if their projects posed a risk to national security. Now, the US tech giants, who are leading the charge in generative AI thanks to companies like OpenAI, the creator of ChatGPT, face a much more moderate regulatory approach, even if some data protection restrictions still exist. 'They've put their cowboy hat back on, it's total Wild West,' notes Yaël Cohen-Hadria, digital specialist lawyer for the French firm EY, who expects these giants to 'dive in headfirst.' In China, the first measures on AI-generated content were introduced in August 2023. They require providers to identify and prevent discrimination based on sex, age, and ethnic group. Their software must not create content spreading 'false and harmful information' or use personal information without consent. They must respect intellectual property rights and follow censorship regulations imposing conformity to 'fundamental socialist values' and not threatening national security. DeepSeek R1, the new Chinese frugal but powerful model that stunned the tech world last week, sticks to the Party line when asked about President Xi Jinping or the repression of the 1989 pro-democracy demonstrations on Tiananmen Square. But, the government will likely 'reserve strong exceptions' for its own rules, predicts Yaël Cohen-Hadria. In the EU, the Union has adopted its AI Act, the most comprehensive law on this technology in the world. By contrast with the US and China, the EU places 'respect for the citizen's life at the heart of its regulation,' notes the digital law specialist. It will apply mainly from 2026, but some provisions have become binding this Sunday. Although rare, bans concern applications contrary to European values, such as citizen rating or mass surveillance systems used in China. The law adopts a 'risk-based' approach: systems with limited risk will be subject to light transparency obligations, while high-risk systems, used for example in critical infrastructure, education, human resources, or law enforcement, will be subject to strengthened requirements. These include, for example, human control over the machine, technical documentation, or a risk management system. Specific rules will apply to generative AI to ensure the quality of the data used in developing algorithms and respect for copyright. Artificially generated sounds, images, and texts must clearly be identified to avoid opinion manipulation. In India, which co-organized the summit in France, there is a law on personal data but no specific text on AI. New Delhi is aware of the value of its technology sector and 'if they make a law, it will be because it will bring them something economically,' estimates Yaël Cohen-Hadria. In January 2024, the government was criticized by many sector actors when the Ministry of Communication submitted the idea that companies should obtain permission from the authorities before deploying 'unreliable' or 'testing' AI models, before backing down. In the UK, the Prime Minister intends to follow his 'own path,' with the motto 'test and understand AI before regulating it.' Keir Starmer wants to make the UK a laboratory and hopes to distinguish itself from the EU regulatory framework to attract companies. The Labour Party believes that their Conservative predecessors have overemphasized the dangers at the expense of the benefits of this technology. The current government has hinted at its position, proposing to allow AI to use creative content, such as music, for 'training' by default, unless the artists explicitly object.
Original language: fr
Publish date: February 10, 2025 01:55 AM
Source:[Ladepeche.fr](https://www.ladepeche.fr/2025/02/09/la-reglementation-de-lintelligence-artificielle-dans-le-monde-12502567.php)

**BEYOND EXPO 2024 | Identifying investment targets in a complex global political and financial landscape · TechNode**
The Global Investment Summit at BEYOND EXPO 2024 in Macao brought together global investment leaders to discuss the future of investment in a complex financial landscape. Artificial Intelligence (AI) was a major focus, with investors sharing how it is revolutionizing investment paradigms and impacting the expansion of AI companies and global data governance. David Beckham emphasized the importance of authenticity in business, saying, 'I’ve always thought that the best businesses that we have are the authentic ones.' Investors such as Harry Man and Lu Zhang discussed the shift in investment strategies in the AI era, aiming to invest in companies with unicorn potential to achieve greater returns through IPOs. However, many AI application companies are currently being overvalued amid the hype. The panelists agreed that AI startups aiming for the global market may need to choose between the Chinese and US markets in the future, due to geopolitical tensions. Despite tensions, global collaboration is still ongoing in areas like open-source AI models and data governance. Investing in emerging markets was also a hot topic, with factors such as political stability, regulations, and investor protections being crucial risks to evaluate. 'So there are actually factors that are more at a political and regulatory level. And then there are also more local cultural practices,' said Akio Tanaka. Overall, a nuanced approach balancing risks and opportunities is needed for investing successfully in emerging markets.
Original language: en
Publish date: June 12, 2024 07:32 AM
Source:[technode.com](https://technode.com/2024/06/12/beyond-expo-2024-identifying-investment-targets-in-a-complex-global-political-and-financial-landscape/)

