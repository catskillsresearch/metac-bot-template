Here's a consistent rationale that incorporates the best of each individual rationale:

The development of an oracle superintelligence before a general superintelligence is influenced by various factors. A key consideration is the current pace of AI research, with slow and steady progress being more likely than sudden breakthroughs or setbacks. The ongoing advancements in AI research, particularly in areas like neural networks and natural language processing, suggest that incremental improvements are possible.

However, it's also important to consider the potential for significant disruptions or breakthroughs in AI development. These could arise from unforeseen technical challenges, regulatory or societal concerns about the risks and implications of AGI, or even breakthroughs in related fields like neuroscience or computer vision. The possibility of another researcher or organization developing a more effective approach to achieving superintelligence also needs to be considered.

Ultimately, the likelihood of an oracle superintelligence being developed before a general superintelligence depends on a combination of these factors, including the continued progress of Ilya Sutskever's Safe Superintelligence project, the development and launch of new AI technologies, and societal responses to the potential implications of AGI.

### Probability: 60%