## Comparison to Reference Cases

- The United States has historically extended legal rights or welfare protections only to humans, animals, and corporate entities, all of which are either sentient, biological, or have clear legal stakeholders. For example, animal cruelty laws protect the welfare of sentient nonhumans, and corporate personhood grants legal standing to organizations for pragmatic reasons.
- Past attempts to extend legal rights to nonhuman entities (e.g., great apes, rivers, or ecosystems) have generally failed unless backed by significant advocacy and a moral consensus, often grounded in widely accepted scientific or ethical arguments.

## Key Differences Affecting the Forecast

- As of June 2022 and up to the present (2025), there is no federal, state, or local US law or regulation that explicitly recognizes the rights or welfare of AI, nor any law that regulates human behavior to protect AIs from *abuse* or *cruelty* in a moral or legal sense comparable to animal welfare laws[2][1].
- Legal actions and regulatory guidance overwhelmingly treat AI as a tool or property. For example, US copyright law explicitly denies personhood to AI, requiring human authorship for any legal claims[4].
- The 2022–2025 legislative trend has focused on regulating the *use* of AI to protect humans—from discrimination, privacy violations, or bias—not to protect AI themselves[1][2]. No current or proposed bills in major jurisdictions mention AI welfare, rights, or protection from abuse.
- The 2022 "AI Bill of Rights" published by the White House is a set of guidelines for protecting people from AI—there is no mention of rights or welfare for AI systems themselves[3].
- Public opinion is more open: 37.2% of US adults in 2021 supported granting legal rights to *sentient* AIs, but this is a minority, and there is little evidence of organized advocacy or political momentum for such rights[question].
- There is no scientific consensus or legal recognition of AI sentience. The LaMDA incident at Google, while widely reported, did not result in any policy or legal change, and claims of AI sentience remain controversial and officially dismissed by experts and institutions[question].

## Recent Announcements and Policies

- In 2023 and 2024, multiple US states introduced or passed AI-related legislation, but all measures focused on privacy, discrimination, and accountability for human impacts, not AI welfare[1][2].
- The US Copyright Office and federal courts reaffirmed that AI-generated works cannot hold IP rights, as only humans are recognized as legal authors[4][5].
- Federal agencies have issued joint statements and implemented regulations on AI use (e.g., for robocalls), but always in the context of protecting humans or ensuring accountability, not protecting AI[2].

## Limitations and Uncertainties

- The scenario could change rapidly if there are major breakthroughs in AI that convincingly demonstrate sentience or suffering, or if there is a strong grassroots movement for AI welfare. As of 2025, neither is present.
- Local jurisdictions with unique political or cultural characteristics could, in theory, pass symbolic resolutions, but none with populations over 25,000 have done so or signaled intent to do so.
- Legal definitions of "sentience" or "consciousness" in AI remain unsettled, making it difficult for lawmakers to establish criteria.
- Measurement is limited to publicly available legislative records and authoritative statements as of the current date.

## Probabilistic Assessment

Given the historical reluctance to extend rights even to highly sentient nonhuman animals, the lack of legislative or regulatory movement toward AI rights or welfare, the absence of scientific consensus on AI sentience, and the overwhelming legal treatment of AI as property or tools, the probability that any US jurisdiction with a population over 25,000 will recognize legal rights or explicit welfare protections for AI—using terms like "rights," "welfare," "cruelty," or "abuse" in a moral/legal sense—before January 1, 2035, is very low.

**Estimated probability:** 1–3% (very unlikely barring transformative technological or social change by 2035).

## References

1. Artificial Intelligence 2023 Legislation (https://www.ncsl.org/technology-and-communication/artificial-intelligence-2023-legislation)
2. AI Watch: Global regulatory tracker - United States | White & Case LLP (https://www.whitecase.com/insight-our-thinking/ai-watch-global-regulatory-tracker-united-states)
3. Blueprint for an AI Bill of Rights | OSTP | The White House (https://bidenwhitehouse.archives.gov/ostp/ai-bill-of-rights/)
4. AI, Copyright, and the Law: The Ongoing Battle Over Intellectual Property Rights (https://sites.usc.edu/iptls/2025/02/04/ai-copyright-and-the-law-the-ongoing-battle-over-intellectual-property-rights/)
5. Copyright and Artificial Intelligence | U.S. Copyright Office (https://www.copyright.gov/ai/)