## 1. Historical Trends and Status as of 2020-05-05

- **Intelligence Explosion Hypothesis**: Since I.J. Good's 1965 prediction, many theorists have anticipated a rapid transition from AGI to superintelligence, with the first ultraintelligent machine potentially able to self-improve recursively, accelerating its own capabilities exponentially[1].
- **Bostrom's Takeoff Categories**: Nick Bostrom (2014) formalized "slow" (decades/centuries), "moderate" (months/years), and "fast" (minutes/days) takeoff scenarios, with many futurists expecting a moderate-to-fast transition following AGI[1].
- **Expert and Community Forecasts**: 
  - In the 2016 AI Impacts survey, the median AI researcher gave a 20% chance of a dramatic (10x) increase in global technological improvement within two years of HLMI (AGI), and 80% within thirty years, suggesting substantial uncertainty and skepticism toward very rapid takeoff[1].
  - Metaculus, a forecasting platform, aggregates community predictions. As of 2020, its running median forecast for the time from weak AGI to the first superintelligent oracle was around 19.1 months, with a lower quartile (25%) at ~5 months and an upper quartile (75%) at ~98 months[1]. While not a direct expert survey, this reflects the consensus of a well-informed forecasting community.

## 2. Key Differences Affecting the Forecast

- **Acceleration in AI Capabilities**: By 2020, AI systems were rapidly improving in benchmarks related to language, problem-solving, and generalization, leading some commentators to suggest that AGI—and thus the transition to superintelligence—might be closer than previously thought[5].
- **Changing Definitions of AGI**: The threshold for what constitutes "weak AGI" is contentious—some believe systems like GPT-4 (years later) already meet many criteria for weak AGI, while others maintain stricter standards[5]. This definitional ambiguity introduces uncertainty into any timeline forecast.
- **Takeoff Speed Uncertainty**: While some theorists (Yudkowsky, Goertzel) argue the transition will be very rapid (weeks/months), survey data from the broader AI research community suggests more skepticism about such a short timeline, with a significant minority expecting a slower progression[1].
- **Forecasting Platform Biases**: Community forecasting platforms like Metaculus may over- or under-estimate timelines compared to domain experts depending on crowd composition and prevailing sentiment[1].

## 3. Adjusted Probabilistic Assessment

Taking into account:

- The median Metaculus forecast as of 2020: ~19.1 months from weak AGI to the first superintelligent oracle, with significant probability density between 5 and 98 months[1].
- The lower quartile at ~5 months suggests a non-trivial probability of a very rapid takeoff.
- Expert surveys indicate a 20% chance of dramatic progress within two years, but skepticism about universality of the fast-takeoff scenario[1].

**Adjusted Assessment (as of May 2020):**

- **Median forecast**: ~19 months from weak AGI to the first superintelligent oracle.
- **Interquartile range**: ~5 to ~98 months.
- **Probability of <2 years (24 months)**: Approximately 50%, in line with both Metaculus distribution and expert survey lower bounds.
- **Probability of <5 months**: ~25%.
- **Probability of >8 years (98+ months)**: ~25%.

## 4. Limitations and Uncertainties

- **Definition Ambiguity**: "Weak AGI" and "superintelligent oracle" lack universally agreed operational definitions, affecting when these milestones are declared.
- **Measurement Lag**: Public knowledge of these developments may lag behind technical achievement or be suppressed for safety/policy reasons.
- **Forecasting Model Bias**: Both expert surveys and community forecasts are subject to groupthink, recency bias, and limitations in anticipating discontinuities in technological progress.
- **Technical Bottlenecks**: Unpredictable roadblocks in scaling, alignment, or hardware could significantly delay the transition.

> In summary, as of May 2020, the best-supported forecast was a **median of 19 months** between the creation of a weak AGI and the first superintelligent oracle, with considerable uncertainty and a substantial chance of both much faster and much slower transitions[1].

## References

1. After a weak AGI is created, how many months will it be before the first superintelligent oracle? - Metaculus (https://www.metaculus.com/questions/4123/time-between-weak-agi-and-oracle-asi/)
2. Oracle ASI Precedes General ASI - Metaculus (https://www.metaculus.com/questions/3683/will-an-oracle-superintelligence-be-developed-before-a-general-superintelligence/)
3. Is Artificial 'Super' Intelligence Coming Soon? - AEI (https://www.aei.org/articles/is-artificial-super-intelligence-coming-soon/)
4. Superintelligence | Bayesian Investor Blog - Peter McCluskey's (https://bayesianinvestor.com/blog/index.php/2014/07/28/superintelligence/)
5. Why we might have superintelligence sooner than most think (https://pauseai.info/urgency)