## 1. Key Historical Trends and Current Status

- **Progress in Formal Mathematical Reasoning:** Recent years have seen a surge in research and development of AI systems for formal mathematical reasoning, including autoformalization (translating informal proofs to formal code) and theorem proving. The field nearly doubled its publication output in 2023, signaling rapid innovation[1].
- **State-of-the-Art Systems:** As of early 2025, systems like LeanProgress leverage large proof corpora and neural models to assist in theorem proving. However, LeanProgress achieves a best-case accuracy of 75.1% in predicting proof progress, with overall proof generation and verification rates well below the required 90% thresholdâ€”especially for longer, more complex proofs typical of top journal articles[5].
- **Expert Sentiment:** Leading mathematicians and AI researchers, including Fields Medalists, express that AI is approaching the ability to formalize "an awful lot of human mathematics." Some, like Borcherds and Tao, anticipate that significant progress in AI-assisted formalization could occur within about five years from late 2024, but this is viewed more as a transformation in workflow rather than full automation at the 90% success rate for arbitrary journal proofs[2].

## 2. Key Differences Affecting the Forecast

- **Complexity and Length of Proofs:** Current AI systems perform well on short, structured proofs but face substantial challenges with the complexity, length, and informal reasoning styles found in high-level mathematics journals[5].
- **Hallucination and Robustness:** Large Language Models (LLMs) still struggle with hallucinations and errors in translation from natural language to formal code. Although verification with tools like Lean can catch errors, this leads to incomplete or failed formalizations[5].
- **Lack of Universality:** No current AI system can reliably handle arbitrary proofs from any journal in the top 15 according to Scimago, as required by the resolution criteria. Demonstrations remain domain- or dataset-specific, not general-purpose[1][5].
- **Human-in-the-Loop vs. Full Automation:** Many promising systems require expert guidance or iterative correction, falling short of the requirement for fully automated conversion at high reliability[2].

## 3. Adjusted Probabilistic Assessment

Given:
- The rapid but still incomplete trajectory of AI in autoformalization,
- The current performance gap (well below 90% for arbitrary proofs),
- Expert assessments projecting substantial progress but not guaranteeing general, universal deployment by 2030,
- The inflection point of the field, balanced by persistent challenges in generalization, robustness, and natural language understanding,

**It is unlikely (probability estimate: 25-35%) that, before January 1st, 2030, an AI will be able to automatically convert arbitrary proofs from top mathematical journals into formally verified code at a 90% success rate as specified.**

## 4. Limitations and Uncertainties

- **Measurement Difficulty:** "Arbitrary" coverage is hard to measure, as journals contain highly varied proof styles, notation, and implicit reasoning.
- **Rapid Field Evolution:** Significant breakthroughs or unforeseen advances could shift the probability within the forecast window.
- **Verification Standards:** The requirement for full formal verification by proof assistants sets a high bar, above current capabilities, and may remain a bottleneck even if translation improves.

## References

1. Formal Mathematical Reasoning: A New Frontier in AI (https://arxiv.org/html/2412.16075v1)
2. AI and the future of Math: Interviews with Top Mathematicians (https://epoch.ai/frontiermath/expert-perspectives)
5. LeanProgress: Guiding Search for Neural Theorem Proving via Proof Progress Prediction (https://arxiv.org/html/2502.17925v2)