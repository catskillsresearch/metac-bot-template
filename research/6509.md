# Forecasting the AI Control Problem vs. Weak AGI Resolution

As of February 17, 2021, the question of whether the AI control problem will be solved before the creation of "weak" Artificial General Intelligence requires analysis of the current state of both AI alignment research and AGI development progress.

## Current Status of AI Alignment Research (as of Feb 2021)

The AI control problem remains an active area of research with limited concrete progress as of early 2021. Major research organizations including the Machine Intelligence Research Institute (MIRI), the Future of Life Institute (FLI), and the Center for Human-Compatible AI (CHAI) are working on theoretical frameworks, but no consensus solution exists.

Key approaches to the control problem as of 2021 include:

- **Value alignment**: Ensuring AI systems adopt and maintain human-compatible values
- **Capability control**: Limiting AI systems' ability to cause harm through containment or incentive structures
- **Interpretability research**: Making AI decision-making processes transparent and understandable

## Current Status of AGI Development (as of Feb 2021)

Progress toward weak AGI continues with significant advances in language models, but substantial gaps remain in meeting the specified criteria:

- **Turing Test capability**: GPT-3 (released in 2020) shows impressive conversational abilities but falls short of reliably passing formal Turing tests
- **Winograd Schema Challenge**: State-of-the-art models in early 2021 have not reached the 90% threshold on robust versions
- **Mathematics SAT performance**: Current AI systems show promising results on mathematical reasoning but not at the 75th percentile level across all SAT math content
- **Atari game mastery**: While AI has mastered many Atari games, Montezuma's Revenge remains challenging due to its sparse reward structure

## Comparative Timeline Analysis

Several factors suggest the control problem may remain unsolved when weak AGI arrives:

1. Research asymmetry: Commercial incentives strongly favor AGI capability development over safety research
2. Verification challenge: Proving a control solution works is inherently more difficult than demonstrating AGI capabilities
3. Historical precedent: Safety solutions in other technological domains have typically lagged behind capability development

## Key Uncertainties

1. The possibility of conceptual breakthroughs in alignment theory
2. Whether weak AGI development will plateau or accelerate
3. Potential shifts in research funding priorities toward safety

## Forecast Limitations

This forecast is constrained by several factors:

1. The definition of "solved" for the control problem lacks precise criteria
2. Disagreement among experts about the nature and difficulty of the control problem
3. The unpredictable nature of research breakthroughs in both AGI and alignment

Given the current trajectories as of February 2021, there appears to be a higher probability that weak AGI will be developed before the control problem is solved, though significant uncertainty remains.