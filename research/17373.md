# Forecasting U.S. Legislation on AI Cybersecurity Before 2026

As of June 7, 2023, the landscape for U.S. legislation requiring cybersecurity measures around AI models shows early signs of development, though comprehensive federal legislation specifically targeting powerful AI models remains in nascent stages.

## Current Legislative Landscape

As of June 7, 2023, there is limited federal legislative activity specifically addressing cybersecurity requirements for powerful AI models. The most relevant piece of legislation introduced is H.R.1718, the "AI for National Security Act," which was introduced in the House on March 22, 2023[4]. This bill focuses on Department of Defense policy related to enterprise-wide procurement of cyber data products and services, including provisions for "artificial intelligence-based endpoint security that prevents cyber-attacks"[4]. However, this bill:

1. Is narrowly focused on DoD applications rather than broadly applicable to all powerful AI models
2. Has only been introduced and referred to the House Committee on Armed Services
3. Has not progressed further in the legislative process

The bill represents an initial recognition of AI security concerns within the defense context but does not constitute the comprehensive cybersecurity legislation for powerful AI models described in the resolution criteria.

## Factors Affecting Probability of Passage

Several factors will likely influence whether comprehensive AI cybersecurity legislation passes before the end of 2025:

**Accelerating Timeline:** The rapid development of AI capabilities may create pressure for regulatory action. As more powerful models emerge, security concerns will likely intensify, potentially accelerating legislative responses.

**Bipartisan Interest:** AI regulation has shown signs of bipartisan interest, with both parties expressing concerns about various aspects of AI development. Security concerns specifically may generate broader consensus than other regulatory approaches.

**Implementation Challenges:** Defining what constitutes a "powerful" AI model presents technical and legal challenges that could slow the legislative process. Lawmakers will need to establish meaningful thresholds and requirements that can be effectively implemented.

**Industry Resistance vs. Cooperation:** The stance of leading AI labs toward regulation will significantly impact the likelihood of passage. Industry may prefer voluntary standards to mandatory requirements, though some companies may welcome clear regulatory frameworks.

## Probabilistic Assessment

Based on the limited information available as of June 7, 2023, I estimate:

- **40-50% probability** that the U.S. will pass legislation requiring cybersecurity around powerful AI models before 2026.

This assessment reflects:
- The existence of early legislative interest in AI security (as evidenced by H.R.1718)
- The significant time remaining before the December 31, 2025 deadline
- The increasing public and policy attention to AI risks
- The complexity of drafting and passing comprehensive legislation on emerging technologies

## Key Uncertainties

Several factors could significantly shift this probability:
- Major AI security incidents could dramatically accelerate legislative action
- Changes in congressional control following the 2024 elections
- Evolution of technical standards and industry best practices
- International regulatory developments that might influence U.S. approaches

## References

[4] H.R.1718 - AI for National Security Act, 118th Congress (2023-2024). Introduced in House on March 22, 2023.